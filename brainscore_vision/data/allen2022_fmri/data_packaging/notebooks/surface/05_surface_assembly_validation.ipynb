{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 - Assembly Validation (Surface)\n",
    "\n",
    "Validate that the Brain-Score surface assemblies contain correct values by tracing\n",
    "the full preprocessing chain from raw NSD fsaverage MGH betas.\n",
    "\n",
    "**Sections:**\n",
    "1. Vertex-level spot check: reproduce global z-score from NB02, compare with assembly\n",
    "2. End-to-end raw data bypass: reproduce V4 from raw MGH for subj01\n",
    "3. Standalone ridge regression: compare sklearn RidgeCV with benchmark output\n",
    "\n",
    "**Environment:** `conda activate vision-2026`\n",
    "\n",
    "**Requires:** External drive `/Volumes/Hagibis/nsd` mounted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NSD root: /Volumes/Hagibis/nsd\n",
      "Train: 412, Test: 103\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/kartik/Brain-Score 2026/vision')\n",
    "sys.path.insert(0, '/Users/kartik/Brain-Score 2026/core')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import nibabel as nib\n",
    "import scipy.io\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "NSD_ROOT = Path('/Volumes/Hagibis/nsd')\n",
    "FSAVG_LABELS = NSD_ROOT / 'fsaverage_labels'\n",
    "ASSEMBLY_DIR = NSD_ROOT / 'assemblies'\n",
    "BRAINSCORE_DIR = NSD_ROOT / 'brainscore_surface'\n",
    "\n",
    "REGIONS = ['V1', 'V2', 'V4', 'IT']\n",
    "SUBJECT_LIST = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "SESSIONS_PER_SUBJECT = {1: 40, 2: 40, 3: 32, 4: 30, 5: 40, 6: 32, 7: 40, 8: 30}\n",
    "TRIALS_PER_SESSION = 750\n",
    "N_FSAVG_VERTICES = 163842\n",
    "VARIANT = '_8subj'\n",
    "\n",
    "# ROI definitions (same as NB02)\n",
    "REGION_TO_KASTNER = {'V1': [1, 2], 'V2': [3, 4], 'V4': [7]}\n",
    "STREAMS_VENTRAL_LABEL = 5\n",
    "\n",
    "# Train/test split\n",
    "split_df = pd.read_csv(ASSEMBLY_DIR / f'train_test_split{VARIANT}.csv')\n",
    "train_ids = set(split_df.loc[split_df['split'] == 'train', 'stimulus_id'])\n",
    "test_ids = set(split_df.loc[split_df['split'] == 'test', 'stimulus_id'])\n",
    "\n",
    "assert NSD_ROOT.exists(), 'External drive not mounted'\n",
    "print(f'NSD root: {NSD_ROOT}')\n",
    "print(f'Train: {len(train_ids)}, Test: {len(test_ids)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Vertex-Level Spot Check\n",
    "\n",
    "Validate the NB03 packaging step by reproducing the global z-score from NB02 data\n",
    "and comparing with the Brain-Score surface assembly values.\n",
    "\n",
    "**Preprocessing chain being validated:**\n",
    "```\n",
    "NB02 assembly (session z-scored, rep-averaged, 1000 images)\n",
    "  -> filter to 515 complete images (min_reps >= 3)\n",
    "  -> global z-score (per subject, per region, stats from 515 images)\n",
    "  -> NaN fill (0.0)\n",
    "  -> split into train/test\n",
    "  -> Brain-Score assembly\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brain-Score train: (412, 221168, 1)\n",
      "Brain-Score test:  (309, 221168, 1)\n",
      "Train coords: ['stimulus_id', 'nsd_id', 'neuroid_id', 'subject', 'hemisphere', 'vertex_index', 'region', 'nc_testset', 'time_bin_start', 'time_bin_end']\n",
      "Test coords:  ['stimulus_id', 'nsd_id', 'repetition', 'neuroid_id', 'subject', 'hemisphere', 'vertex_index', 'region', 'nc_testset', 'time_bin_start', 'time_bin_end']\n"
     ]
    }
   ],
   "source": [
    "# Load Brain-Score packaged surface assemblies (NB03 output)\n",
    "bs_train = xr.open_dataarray(str(BRAINSCORE_DIR / f'Allen2022_fmri_surface_train{VARIANT}.nc'))\n",
    "bs_test = xr.open_dataarray(str(BRAINSCORE_DIR / f'Allen2022_fmri_surface_test{VARIANT}.nc'))\n",
    "bs_train.load()\n",
    "bs_test.load()\n",
    "\n",
    "print(f'Brain-Score train: {bs_train.shape}')\n",
    "print(f'Brain-Score test:  {bs_test.shape}')\n",
    "print(f'Train coords: {list(bs_train.coords)}')\n",
    "print(f'Test coords:  {list(bs_test.coords)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB02 V4: (1000, 7312)\n",
      "NB02 V4 (515 complete): (515, 7312)\n",
      "Train: 412, Test: 103\n"
     ]
    }
   ],
   "source": [
    "# Load NB02 assembly for V4 and reproduce global z-score\n",
    "nb02_v4 = xr.open_dataarray(str(ASSEMBLY_DIR / f'Allen2022_surface.V4{VARIANT}.nc'))\n",
    "nb02_v4.load()\n",
    "print(f'NB02 V4: {nb02_v4.shape}')  # (1000, 7312)\n",
    "\n",
    "# Filter to 515 complete images (min_reps >= 3), same as NB03\n",
    "min_reps = nb02_v4.coords['min_reps_across_subjects'].values\n",
    "complete_mask = min_reps >= 3\n",
    "nb02_v4_515 = nb02_v4.isel(presentation=complete_mask)\n",
    "print(f'NB02 V4 (515 complete): {nb02_v4_515.shape}')\n",
    "\n",
    "# Build train/test masks over the 515 images\n",
    "nb02_stimulus_ids = nb02_v4_515.coords['stimulus_id'].values\n",
    "train_mask_515 = np.array([sid in train_ids for sid in nb02_stimulus_ids])\n",
    "test_mask_515 = np.array([sid in test_ids for sid in nb02_stimulus_ids])\n",
    "print(f'Train: {train_mask_515.sum()}, Test: {test_mask_515.sum()}')\n",
    "assert train_mask_515.sum() == 412\n",
    "assert test_mask_515.sum() == 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN filled: 0\n",
      "Reproduced train: (412, 7312)\n",
      "Reproduced test:  (103, 7312)\n"
     ]
    }
   ],
   "source": [
    "# Reproduce global z-score for V4 (matching NB03 cell-7)\n",
    "reproduced_data = nb02_v4_515.values.copy()  # (515, 7312)\n",
    "subjects_v4 = nb02_v4_515.coords['subject'].values\n",
    "\n",
    "for subj_label in [f'subj{s:02d}' for s in SUBJECT_LIST]:\n",
    "    subj_mask = subjects_v4 == subj_label\n",
    "    subj_data = reproduced_data[:, subj_mask]\n",
    "    mean = np.nanmean(subj_data, axis=0, keepdims=True)\n",
    "    std = np.nanstd(subj_data, axis=0, keepdims=True)\n",
    "    std[std == 0] = 1.0\n",
    "    reproduced_data[:, subj_mask] = (subj_data - mean) / std\n",
    "\n",
    "# Fill NaN with 0.0 (same as NB03)\n",
    "n_nan_filled = np.isnan(reproduced_data).sum()\n",
    "reproduced_data = np.nan_to_num(reproduced_data, nan=0.0)\n",
    "print(f'NaN filled: {n_nan_filled}')\n",
    "\n",
    "reproduced_train = reproduced_data[train_mask_515]  # (412, 7312)\n",
    "reproduced_test = reproduced_data[test_mask_515]    # (103, 7312)\n",
    "print(f'Reproduced train: {reproduced_train.shape}')\n",
    "print(f'Reproduced test:  {reproduced_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NB02 -> Filter -> Global Z-Score -> Brain-Score Train (V4) ===\n",
      "Max absolute difference:  0.00e+00\n",
      "Mean absolute difference: 0.00e+00\n",
      "Correlation:              1.0000000000\n",
      "Match: PASS\n",
      "\n",
      "=== Test (averaged reps, V4) ===\n",
      "Max absolute difference: 9.54e-07\n",
      "Match: PASS\n"
     ]
    }
   ],
   "source": [
    "# Compare reproduced values with Brain-Score train assembly (V4 neuroids only)\n",
    "v4_neuroid_mask = bs_train.coords['region'].values == 'V4'\n",
    "bs_train_v4 = bs_train.values[:, v4_neuroid_mask, 0]  # (412, 7312)\n",
    "\n",
    "max_diff = np.max(np.abs(reproduced_train - bs_train_v4))\n",
    "mean_diff = np.mean(np.abs(reproduced_train - bs_train_v4))\n",
    "r = np.corrcoef(reproduced_train.ravel(), bs_train_v4.ravel())[0, 1]\n",
    "\n",
    "print('=== NB02 -> Filter -> Global Z-Score -> Brain-Score Train (V4) ===')\n",
    "print(f'Max absolute difference:  {max_diff:.2e}')\n",
    "print(f'Mean absolute difference: {mean_diff:.2e}')\n",
    "print(f'Correlation:              {r:.10f}')\n",
    "print(f'Match: {\"PASS\" if max_diff < 1e-5 else \"FAIL\"}')\n",
    "assert max_diff < 1e-5, f'Train V4 mismatch: max_diff={max_diff}'\n",
    "\n",
    "# Compare test (averaged reps -- average the 3 reps in Brain-Score test)\n",
    "bs_test_v4_all = bs_test.values[:, v4_neuroid_mask, 0]  # (309, 7312)\n",
    "n_test = len(test_ids)\n",
    "bs_test_v4_avg = bs_test_v4_all.reshape(n_test, 3, -1).mean(axis=1)  # (103, 7312)\n",
    "\n",
    "max_diff_test = np.max(np.abs(reproduced_test - bs_test_v4_avg))\n",
    "print(f'\\n=== Test (averaged reps, V4) ===')\n",
    "print(f'Max absolute difference: {max_diff_test:.2e}')\n",
    "print(f'Match: {\"PASS\" if max_diff_test < 1e-5 else \"FAIL\"}')\n",
    "assert max_diff_test < 1e-5, f'Test V4 mismatch: max_diff={max_diff_test}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Vertex-Level Spot Check (V4) ===\n",
      "Subject    Stimulus       Vertex     Reproduced     Assembly         Diff Status\n",
      "----------------------------------------------------------------------------------\n",
      "subj01     nsd_03049      0            0.411551     0.411551     0.00e+00 PASS\n",
      "subj01     nsd_03049      100         -0.756218    -0.756218     0.00e+00 PASS\n",
      "subj04     nsd_37224      2792         2.014114     2.014114     0.00e+00 PASS\n",
      "subj08     nsd_72719      7311        -1.607054    -1.607054     0.00e+00 PASS\n",
      "subj05     nsd_20738      3856         0.167083     0.167083     0.00e+00 PASS\n",
      "\n",
      "All spot checks: PASS\n"
     ]
    }
   ],
   "source": [
    "# Spot check: trace 5 specific (subject, image, vertex) values\n",
    "print('=== Vertex-Level Spot Check (V4) ===')\n",
    "print(f'{\"Subject\":<10} {\"Stimulus\":<14} {\"Vertex\":<8} '\n",
    "      f'{\"Reproduced\":>12} {\"Assembly\":>12} {\"Diff\":>12} {\"Status\"}')\n",
    "print('-' * 82)\n",
    "\n",
    "v4_subjects = bs_train.coords['subject'].values[v4_neuroid_mask]\n",
    "train_stim_ids = bs_train.coords['stimulus_id'].values\n",
    "\n",
    "spot_checks = [\n",
    "    ('subj01', 0, 0),      # first subject, first train image, first vertex\n",
    "    ('subj01', 0, 100),    # first subject, first train image, vertex 100\n",
    "    ('subj04', 200, 50),   # middle subject, middle image, middle vertex\n",
    "    ('subj08', 411, -1),   # last subject, last train image, last vertex\n",
    "    ('subj05', 100, 200),  # arbitrary\n",
    "]\n",
    "\n",
    "all_pass = True\n",
    "for subj_label, img_idx, vx_idx in spot_checks:\n",
    "    subj_v4_mask = v4_subjects == subj_label\n",
    "    subj_start = np.where(subj_v4_mask)[0][0]\n",
    "    actual_vx_idx = subj_start + (vx_idx % subj_v4_mask.sum())\n",
    "\n",
    "    reproduced_val = reproduced_train[img_idx, actual_vx_idx]\n",
    "    assembly_val = bs_train_v4[img_idx, actual_vx_idx]\n",
    "    diff = abs(reproduced_val - assembly_val)\n",
    "    status = 'PASS' if diff < 1e-6 else 'FAIL'\n",
    "    if status == 'FAIL':\n",
    "        all_pass = False\n",
    "\n",
    "    print(f'{subj_label:<10} {train_stim_ids[img_idx]:<14} {actual_vx_idx:<8} '\n",
    "          f'{reproduced_val:>12.6f} {assembly_val:>12.6f} {diff:>12.2e} {status}')\n",
    "\n",
    "print(f'\\nAll spot checks: {\"PASS\" if all_pass else \"FAIL\"}')\n",
    "assert all_pass, 'Spot check failed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: End-to-End Raw Data Bypass\n",
    "\n",
    "Reproduce V4 betas for subj01 entirely from raw MGH surface files, applying the full\n",
    "preprocessing chain:\n",
    "```\n",
    "Raw MGH betas (float32, per hemisphere, 163842 vertices x 750 trials)\n",
    "  -> Extract V4 vertices (LH Kastner hV4 + RH Kastner hV4)\n",
    "  -> Z-score within session (750 trials per vertex)\n",
    "  -> Collect shared-image trials, average 3 repetitions\n",
    "  -> Global z-score (stats from all 515 averaged images)\n",
    "  -> Compare with Brain-Score assembly\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V4 vertices: LH=410, RH=504, total=914\n",
      "Total images: 515\n"
     ]
    }
   ],
   "source": [
    "# Load fsaverage ROI labels for V4\n",
    "lh_kastner = nib.load(str(FSAVG_LABELS / 'lh.Kastner2015.mgz')).get_fdata().flatten()\n",
    "rh_kastner = nib.load(str(FSAVG_LABELS / 'rh.Kastner2015.mgz')).get_fdata().flatten()\n",
    "\n",
    "v4_lh_mask = lh_kastner == 7  # hV4\n",
    "v4_rh_mask = rh_kastner == 7\n",
    "n_v4_lh = v4_lh_mask.sum()\n",
    "n_v4_rh = v4_rh_mask.sum()\n",
    "n_v4_total = n_v4_lh + n_v4_rh\n",
    "print(f'V4 vertices: LH={n_v4_lh}, RH={n_v4_rh}, total={n_v4_total}')\n",
    "\n",
    "# Trial mapping utilities\n",
    "expdesign = scipy.io.loadmat(str(NSD_ROOT / 'metadata' / 'nsd_expdesign.mat'))\n",
    "masterordering = expdesign['masterordering'].flatten()\n",
    "subjectim = expdesign['subjectim']\n",
    "sharedix = expdesign['sharedix'].flatten()\n",
    "\n",
    "# Build the 515 complete image list (same as NB02/03)\n",
    "all_nsd_ids = sorted(split_df['nsd_id'].values)\n",
    "nsd_id_to_idx = {nsd_id: idx for idx, nsd_id in enumerate(all_nsd_ids)}\n",
    "N_IMAGES = len(all_nsd_ids)\n",
    "print(f'Total images: {N_IMAGES}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shared_trial_info(subj_idx: int, target_nsd_ids: set) -> pd.DataFrame:\n",
    "    \"\"\"Get session/trial mapping for shared images for a given subject.\"\"\"\n",
    "    subj = subj_idx + 1\n",
    "    n_sessions = SESSIONS_PER_SUBJECT[subj]\n",
    "    n_total_trials = n_sessions * TRIALS_PER_SESSION\n",
    "    subj_nsdids = subjectim[subj_idx]\n",
    "    nsdid_to_imgidx = {int(nsd_id): img_idx + 1\n",
    "                       for img_idx, nsd_id in enumerate(subj_nsdids)}\n",
    "\n",
    "    shared_imgidxs = set()\n",
    "    for nsd_id in sharedix:\n",
    "        if int(nsd_id) in nsdid_to_imgidx:\n",
    "            shared_imgidxs.add(nsdid_to_imgidx[int(nsd_id)])\n",
    "\n",
    "    records = []\n",
    "    rep_counter = {}\n",
    "    for trial_idx in range(n_total_trials):\n",
    "        img_idx = masterordering[trial_idx]\n",
    "        if img_idx in shared_imgidxs:\n",
    "            nsd_id = int(subj_nsdids[img_idx - 1] - 1)  # 0-indexed\n",
    "            if nsd_id not in target_nsd_ids:\n",
    "                rep_counter[img_idx] = rep_counter.get(img_idx, 0) + 1\n",
    "                continue\n",
    "            rep = rep_counter.get(img_idx, 0)\n",
    "            rep_counter[img_idx] = rep + 1\n",
    "            session = trial_idx // TRIALS_PER_SESSION + 1\n",
    "            trial_in_session = trial_idx % TRIALS_PER_SESSION\n",
    "            records.append({\n",
    "                'nsd_id': nsd_id, 'rep': rep,\n",
    "                'session': session, 'trial_in_session': trial_in_session,\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj01 V4: 914 vertices\n",
      "Trials for 515 shared images: 1545 (expected 1545)\n",
      "  Session 10/40 (39s)\n",
      "  Session 20/40 (76s)\n",
      "  Session 30/40 (113s)\n",
      "\n",
      "Done in 113s\n",
      "Bypass output: (515, 914)\n"
     ]
    }
   ],
   "source": [
    "# Reproduce V4 betas for subj01 from raw MGH files\n",
    "SUBJ = 1\n",
    "target_nsd_ids = set(all_nsd_ids)\n",
    "\n",
    "trial_info = get_shared_trial_info(SUBJ - 1, target_nsd_ids)\n",
    "print(f'subj{SUBJ:02d} V4: {n_v4_total} vertices')\n",
    "print(f'Trials for {N_IMAGES} shared images: {len(trial_info)} (expected {N_IMAGES * 3})')\n",
    "assert len(trial_info) == N_IMAGES * 3\n",
    "\n",
    "# Extract session-z-scored betas, average across 3 reps\n",
    "per_rep = np.zeros((N_IMAGES, 3, n_v4_total), dtype=np.float32)\n",
    "\n",
    "t0 = time.time()\n",
    "for session in range(1, SESSIONS_PER_SUBJECT[SUBJ] + 1):\n",
    "    session_trials = trial_info[trial_info['session'] == session]\n",
    "    if len(session_trials) == 0:\n",
    "        continue\n",
    "\n",
    "    # Load LH and RH surface betas\n",
    "    lh_path = NSD_ROOT / f'subj{SUBJ:02d}' / 'betas' / f'lh.betas_session{session:02d}.mgh'\n",
    "    rh_path = NSD_ROOT / f'subj{SUBJ:02d}' / 'betas' / f'rh.betas_session{session:02d}.mgh'\n",
    "    lh_betas = nib.load(str(lh_path)).get_fdata().squeeze()  # (163842, 750)\n",
    "    rh_betas = nib.load(str(rh_path)).get_fdata().squeeze()  # (163842, 750)\n",
    "\n",
    "    # Extract V4 vertices: concat LH then RH -> (750, n_v4_total)\n",
    "    roi_betas = np.concatenate([\n",
    "        lh_betas[v4_lh_mask].T,  # (750, n_v4_lh)\n",
    "        rh_betas[v4_rh_mask].T,  # (750, n_v4_rh)\n",
    "    ], axis=1)\n",
    "\n",
    "    # Z-score within session per vertex\n",
    "    mean = roi_betas.mean(axis=0, keepdims=True)\n",
    "    std = roi_betas.std(axis=0, keepdims=True)\n",
    "    std[std == 0] = 1.0\n",
    "    roi_betas = (roi_betas - mean) / std\n",
    "\n",
    "    for _, row in session_trials.iterrows():\n",
    "        img_idx = nsd_id_to_idx[row['nsd_id']]\n",
    "        per_rep[img_idx, row['rep']] = roi_betas[row['trial_in_session']]\n",
    "\n",
    "    del lh_betas, rh_betas\n",
    "    if session % 10 == 0:\n",
    "        print(f'  Session {session}/{SESSIONS_PER_SUBJECT[SUBJ]} ({time.time()-t0:.0f}s)')\n",
    "\n",
    "# Average across repetitions\n",
    "bypass_averaged = per_rep.mean(axis=1)  # (515, n_v4_total)\n",
    "\n",
    "# Global z-score (stats from all 515 averaged images)\n",
    "gz_mean = np.nanmean(bypass_averaged, axis=0)\n",
    "gz_std = np.nanstd(bypass_averaged, axis=0)\n",
    "gz_std[gz_std == 0] = 1.0\n",
    "bypass_final = (bypass_averaged - gz_mean) / gz_std\n",
    "bypass_final = np.nan_to_num(bypass_final, nan=0.0)\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f'\\nDone in {elapsed:.0f}s')\n",
    "print(f'Bypass output: {bypass_final.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== End-to-End Bypass: Raw MGH -> Brain-Score Assembly (subj01, V4) ===\n",
      "Train: max_diff=1.67e-06, mean_diff=1.14e-07 [PASS]\n",
      "Test:  max_diff=2.38e-06, mean_diff=1.23e-07 [PASS]\n",
      "\n",
      "Bypass shape:   (412, 914) train, (103, 914) test\n",
      "Assembly shape: (412, 914) train, (103, 914) test\n",
      "\n",
      "Full preprocessing chain validated for subj01 V4 (surface).\n"
     ]
    }
   ],
   "source": [
    "# Compare bypass result with Brain-Score assembly for subj01 V4\n",
    "\n",
    "# Extract subj01 V4 from Brain-Score train assembly\n",
    "subj01_v4_mask = (bs_train.coords['subject'].values == 'subj01') & \\\n",
    "                 (bs_train.coords['region'].values == 'V4')\n",
    "bs_train_subj01_v4 = bs_train.values[:, subj01_v4_mask, 0]  # (412, n_v4_total)\n",
    "\n",
    "# Extract subj01 V4 from Brain-Score test assembly (average 3 reps)\n",
    "subj01_v4_mask_test = (bs_test.coords['subject'].values == 'subj01') & \\\n",
    "                      (bs_test.coords['region'].values == 'V4')\n",
    "bs_test_subj01_v4 = bs_test.values[:, subj01_v4_mask_test, 0]  # (309, n_v4_total)\n",
    "bs_test_subj01_v4_avg = bs_test_subj01_v4.reshape(len(test_ids), 3, -1).mean(axis=1)\n",
    "\n",
    "# Split bypass into train/test\n",
    "bypass_train = bypass_final[train_mask_515]  # (412, n_v4_total)\n",
    "bypass_test = bypass_final[test_mask_515]    # (103, n_v4_total)\n",
    "\n",
    "# Compare train\n",
    "train_max_diff = np.max(np.abs(bypass_train - bs_train_subj01_v4))\n",
    "train_mean_diff = np.mean(np.abs(bypass_train - bs_train_subj01_v4))\n",
    "\n",
    "# Compare test (averaged reps)\n",
    "test_max_diff = np.max(np.abs(bypass_test - bs_test_subj01_v4_avg))\n",
    "test_mean_diff = np.mean(np.abs(bypass_test - bs_test_subj01_v4_avg))\n",
    "\n",
    "print('=== End-to-End Bypass: Raw MGH -> Brain-Score Assembly (subj01, V4) ===')\n",
    "print(f'Train: max_diff={train_max_diff:.2e}, mean_diff={train_mean_diff:.2e} '\n",
    "      f'[{\"PASS\" if train_max_diff < 1e-5 else \"FAIL\"}]')\n",
    "print(f'Test:  max_diff={test_max_diff:.2e}, mean_diff={test_mean_diff:.2e} '\n",
    "      f'[{\"PASS\" if test_max_diff < 1e-5 else \"FAIL\"}]')\n",
    "\n",
    "assert train_max_diff < 1e-5, f'TRAIN MISMATCH: {train_max_diff}'\n",
    "assert test_max_diff < 1e-5, f'TEST MISMATCH: {test_max_diff}'\n",
    "\n",
    "print(f'\\nBypass shape:   {bypass_train.shape} train, {bypass_test.shape} test')\n",
    "print(f'Assembly shape: {bs_train_subj01_v4.shape} train, {bs_test_subj01_v4_avg.shape} test')\n",
    "print(f'\\nFull preprocessing chain validated for subj01 V4 (surface).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vertex index ordering match: PASS\n",
      "Hemisphere ordering match:   PASS\n",
      "  Assembly: 914 vertices (410 LH + 504 RH)\n",
      "  Bypass:   914 vertices (410 LH + 504 RH)\n"
     ]
    }
   ],
   "source": [
    "# Cross-check: verify vertex ordering matches between bypass and assembly\n",
    "# The assembly stores vertex_index coords -- confirm our extraction order matches\n",
    "\n",
    "assembly_vertex_indices = bs_train.coords['vertex_index'].values[subj01_v4_mask]\n",
    "assembly_hemispheres = bs_train.coords['hemisphere'].values[subj01_v4_mask]\n",
    "\n",
    "# Our bypass extraction order: LH vertices (sorted by index), then RH vertices (sorted by index)\n",
    "lh_indices = np.where(v4_lh_mask)[0]\n",
    "rh_indices = np.where(v4_rh_mask)[0]\n",
    "expected_indices = np.concatenate([lh_indices, rh_indices])\n",
    "expected_hemispheres = np.array(['lh'] * len(lh_indices) + ['rh'] * len(rh_indices))\n",
    "\n",
    "indices_match = np.array_equal(assembly_vertex_indices, expected_indices)\n",
    "hemi_match = np.array_equal(assembly_hemispheres, expected_hemispheres)\n",
    "\n",
    "print(f'Vertex index ordering match: {\"PASS\" if indices_match else \"FAIL\"}')\n",
    "print(f'Hemisphere ordering match:   {\"PASS\" if hemi_match else \"FAIL\"}')\n",
    "print(f'  Assembly: {len(assembly_vertex_indices)} vertices '\n",
    "      f'({(assembly_hemispheres == \"lh\").sum()} LH + {(assembly_hemispheres == \"rh\").sum()} RH)')\n",
    "print(f'  Bypass:   {len(expected_indices)} vertices '\n",
    "      f'({len(lh_indices)} LH + {len(rh_indices)} RH)')\n",
    "\n",
    "assert indices_match, 'Vertex index ordering mismatch'\n",
    "assert hemi_match, 'Hemisphere ordering mismatch'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Standalone Ridge Regression\n",
    "\n",
    "Run sklearn RidgeCV on Brain-Score assembly data for V4 and compare per-subject\n",
    "correlations with the benchmark output from NB04.\n",
    "\n",
    "This validates the benchmark metric code: if our standalone ridge gives similar\n",
    "raw correlations as the benchmark, the `ridge_split` metric is working correctly\n",
    "on our surface assemblies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kartik/Brain-Score 2026/core/brainscore_core/metrics/__init__.py:16: FutureWarning: xarray subclass Score should explicitly define __slots__\n",
      "  class Score(DataAssembly):\n",
      "/opt/anaconda3/envs/nsd-2026/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nsd-2026/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/opt/anaconda3/envs/nsd-2026/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:250: LinAlgWarning: An ill-conditioned matrix detected: slice 0 has rcond = 9.928403699177579e-08.\n",
      "  dual_coef = linalg.solve(K, y, assume_a=\"pos\", overwrite_a=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Score (subject: 1)>\n",
      "array([0.44368672])\n",
      "Coordinates:\n",
      "  * subject  (subject) <U6 'subj01'\n",
      "Attributes:\n",
      "    raw:      <xarray.Score (subject: 1)>\\narray([0.47483057], dtype=float32)...\n",
      "    ceiling:  <xarray.Score ()>\\narray(0.5081605)\\nAttributes:\\n    raw:     ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nsd-2026/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:250: LinAlgWarning: An ill-conditioned matrix detected: slice 0 has rcond = 9.928403699177579e-08.\n",
      "  dual_coef = linalg.solve(K, y, assume_a=\"pos\", overwrite_a=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Score (subject: 1)>\n",
      "array([0.48174151])\n",
      "Coordinates:\n",
      "  * subject  (subject) <U6 'subj02'\n",
      "Attributes:\n",
      "    raw:      <xarray.Score (subject: 1)>\\narray([0.5506409], dtype=float32)\\...\n",
      "    ceiling:  <xarray.Score ()>\\narray(0.62939434)\\nAttributes:\\n    raw:    ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nsd-2026/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:250: LinAlgWarning: An ill-conditioned matrix detected: slice 0 has rcond = 9.928403699177579e-08.\n",
      "  dual_coef = linalg.solve(K, y, assume_a=\"pos\", overwrite_a=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Score (subject: 1)>\n",
      "array([0.44947871])\n",
      "Coordinates:\n",
      "  * subject  (subject) <U6 'subj03'\n",
      "Attributes:\n",
      "    raw:      <xarray.Score (subject: 1)>\\narray([0.4437025], dtype=float32)\\...\n",
      "    ceiling:  <xarray.Score ()>\\narray(0.4380005)\\nAttributes:\\n    raw:     ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nsd-2026/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:250: LinAlgWarning: An ill-conditioned matrix detected: slice 0 has rcond = 9.928403699177579e-08.\n",
      "  dual_coef = linalg.solve(K, y, assume_a=\"pos\", overwrite_a=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Score (subject: 1)>\n",
      "array([0.30570829])\n",
      "Coordinates:\n",
      "  * subject  (subject) <U6 'subj04'\n",
      "Attributes:\n",
      "    raw:      <xarray.Score (subject: 1)>\\narray([0.36520135], dtype=float32)...\n",
      "    ceiling:  <xarray.Score ()>\\narray(0.4362722)\\nAttributes:\\n    raw:     ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nsd-2026/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:250: LinAlgWarning: An ill-conditioned matrix detected: slice 0 has rcond = 9.928403699177579e-08.\n",
      "  dual_coef = linalg.solve(K, y, assume_a=\"pos\", overwrite_a=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Score (subject: 1)>\n",
      "array([0.27451815])\n",
      "Coordinates:\n",
      "  * subject  (subject) <U6 'subj05'\n",
      "Attributes:\n",
      "    raw:      <xarray.Score (subject: 1)>\\narray([0.37262708], dtype=float32)...\n",
      "    ceiling:  <xarray.Score ()>\\narray(0.50579876)\\nAttributes:\\n    raw:    ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nsd-2026/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:250: LinAlgWarning: An ill-conditioned matrix detected: slice 0 has rcond = 9.928403699177579e-08.\n",
      "  dual_coef = linalg.solve(K, y, assume_a=\"pos\", overwrite_a=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Score (subject: 1)>\n",
      "array([0.27812625])\n",
      "Coordinates:\n",
      "  * subject  (subject) <U6 'subj06'\n",
      "Attributes:\n",
      "    raw:      <xarray.Score (subject: 1)>\\narray([0.34403068], dtype=float32)...\n",
      "    ceiling:  <xarray.Score ()>\\narray(0.42555173)\\nAttributes:\\n    raw:    ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nsd-2026/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:250: LinAlgWarning: An ill-conditioned matrix detected: slice 0 has rcond = 9.928403699177579e-08.\n",
      "  dual_coef = linalg.solve(K, y, assume_a=\"pos\", overwrite_a=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Score (subject: 1)>\n",
      "array([0.53596906])\n",
      "Coordinates:\n",
      "  * subject  (subject) <U6 'subj07'\n",
      "Attributes:\n",
      "    raw:      <xarray.Score (subject: 1)>\\narray([0.5619419], dtype=float32)\\...\n",
      "    ceiling:  <xarray.Score ()>\\narray(0.58917342)\\nAttributes:\\n    raw:    ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nsd-2026/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:250: LinAlgWarning: An ill-conditioned matrix detected: slice 0 has rcond = 9.928403699177579e-08.\n",
      "  dual_coef = linalg.solve(K, y, assume_a=\"pos\", overwrite_a=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Score (subject: 1)>\n",
      "array([0.43810691])\n",
      "Coordinates:\n",
      "  * subject  (subject) <U6 'subj08'\n",
      "Attributes:\n",
      "    raw:      <xarray.Score (subject: 1)>\\narray([0.4608936], dtype=float32)\\...\n",
      "    ceiling:  <xarray.Score ()>\\narray(0.48486547)\\nAttributes:\\n    raw:    ...\n",
      "Benchmark score (ceiling-normalized): 0.4009\n",
      "Benchmark raw:                        0.4467\n",
      "Benchmark ceiling:                    0.5051\n",
      "Time: 7.9s\n",
      "\n",
      "Per-subject raw scores from benchmark:\n",
      "  subj01: 0.4748\n",
      "  subj02: 0.5506\n",
      "  subj03: 0.4437\n",
      "  subj04: 0.3652\n",
      "  subj05: 0.3726\n",
      "  subj06: 0.3440\n",
      "  subj07: 0.5619\n",
      "  subj08: 0.4609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nsd-2026/lib/python3.11/site-packages/xarray/core/concat.py:500: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  common_dims = tuple(pd.unique([d for v in vars for d in v.dims]))\n",
      "/opt/anaconda3/envs/nsd-2026/lib/python3.11/site-packages/xarray/core/concat.py:500: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  common_dims = tuple(pd.unique([d for v in vars for d in v.dims]))\n",
      "/var/folders/h6/g53mxg516n538136hh74630r0000gn/T/ipykernel_50166/2087798061.py:22: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  raw_val = float(benchmark_score.attrs[subj_label].raw.values)\n"
     ]
    }
   ],
   "source": [
    "from brainscore_vision import load_model, load_benchmark\n",
    "\n",
    "# Load model and benchmark\n",
    "model = load_model('alexnet')\n",
    "benchmark = load_benchmark('Allen2022_fmri_surface.V4-ridge')\n",
    "\n",
    "# Score via benchmark\n",
    "t0 = time.time()\n",
    "benchmark_score = benchmark(model)\n",
    "elapsed = time.time() - t0\n",
    "\n",
    "print(f'Benchmark score (ceiling-normalized): {float(benchmark_score.values):.4f}')\n",
    "print(f'Benchmark raw:                        {float(benchmark_score.raw.values):.4f}')\n",
    "print(f'Benchmark ceiling:                    {float(benchmark_score.ceiling.values):.4f}')\n",
    "print(f'Time: {elapsed:.1f}s')\n",
    "\n",
    "# Extract per-subject scores from benchmark\n",
    "print(f'\\nPer-subject raw scores from benchmark:')\n",
    "benchmark_per_subj = {}\n",
    "for subj_label in [f'subj{s:02d}' for s in SUBJECT_LIST]:\n",
    "    if subj_label in benchmark_score.attrs:\n",
    "        raw_val = float(benchmark_score.attrs[subj_label].raw.values)\n",
    "        benchmark_per_subj[subj_label] = raw_val\n",
    "        print(f'  {subj_label}: {raw_val:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model train activations: (412, 64896)\n",
      "Model test activations:  (103, 64896)\n",
      "Train neural: (412, 5782)\n",
      "Test neural:  (103, 5782)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "# Get the model activations that the benchmark already extracted\n",
    "model_train_act = benchmark.train_activations.values\n",
    "model_test_act = benchmark.test_activations.values\n",
    "\n",
    "if model_train_act.ndim > 2:\n",
    "    model_train_act = model_train_act.squeeze()\n",
    "    model_test_act = model_test_act.squeeze()\n",
    "\n",
    "print(f'Model train activations: {model_train_act.shape}')\n",
    "print(f'Model test activations:  {model_test_act.shape}')\n",
    "\n",
    "# Get neural data from the benchmark assemblies\n",
    "train_neural = benchmark.train_assembly\n",
    "test_neural = benchmark.test_assembly\n",
    "\n",
    "if 'time_bin' in train_neural.dims:\n",
    "    train_neural = train_neural.isel(time_bin=0)\n",
    "if 'time_bin' in test_neural.dims:\n",
    "    test_neural = test_neural.isel(time_bin=0)\n",
    "\n",
    "print(f'Train neural: {train_neural.shape}')\n",
    "print(f'Test neural:  {test_neural.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj01: median r = 0.4940, alpha = 75000, n_verts = 724\n",
      "subj02: median r = 0.5585, alpha = 50000, n_verts = 845\n",
      "subj03: median r = 0.4471, alpha = 90000, n_verts = 769\n",
      "subj04: median r = 0.3854, alpha = 150000, n_verts = 564\n",
      "subj05: median r = 0.3921, alpha = 150000, n_verts = 774\n",
      "subj06: median r = 0.3583, alpha = 200000, n_verts = 734\n",
      "subj07: median r = 0.5731, alpha = 85000, n_verts = 735\n",
      "subj08: median r = 0.4782, alpha = 150000, n_verts = 637\n",
      "\n",
      "Standalone mean raw r: 0.4609\n"
     ]
    }
   ],
   "source": [
    "# Standalone ridge regression per subject\n",
    "# Match the benchmark: per-subject fitting, median correlation across vertices\n",
    "\n",
    "from brainscore_vision.metrics.regression_correlation.metric import ALPHA_LIST\n",
    "\n",
    "subjects = np.unique(train_neural['subject'].values)\n",
    "standalone_results = {}\n",
    "\n",
    "for subj_label in subjects:\n",
    "    subj_mask_train = train_neural['subject'].values == subj_label\n",
    "    subj_mask_test = test_neural['subject'].values == subj_label\n",
    "\n",
    "    y_train = train_neural.values[:, subj_mask_train]\n",
    "    y_test = test_neural.values[:, subj_mask_test]\n",
    "\n",
    "    ridge = RidgeCV(alphas=ALPHA_LIST, fit_intercept=True)\n",
    "    ridge.fit(model_train_act, y_train)\n",
    "    y_pred = ridge.predict(model_test_act)\n",
    "\n",
    "    n_verts = y_test.shape[1]\n",
    "    correlations = np.array([\n",
    "        pearsonr(y_pred[:, v], y_test[:, v])[0]\n",
    "        for v in range(n_verts)\n",
    "    ])\n",
    "\n",
    "    median_r = np.median(correlations)\n",
    "    standalone_results[subj_label] = {\n",
    "        'median_r': median_r,\n",
    "        'alpha': ridge.alpha_,\n",
    "        'n_verts': n_verts,\n",
    "    }\n",
    "    print(f'{subj_label}: median r = {median_r:.4f}, '\n",
    "          f'alpha = {ridge.alpha_:.0f}, '\n",
    "          f'n_verts = {n_verts}')\n",
    "\n",
    "standalone_mean_r = np.mean([v['median_r'] for v in standalone_results.values()])\n",
    "print(f'\\nStandalone mean raw r: {standalone_mean_r:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Standalone Ridge vs Benchmark Comparison (Surface V4) ===\n",
      "Subject      Standalone    Benchmark         Diff\n",
      "--------------------------------------------------\n",
      "subj01           0.4940       0.4748       0.0192\n",
      "subj02           0.5585       0.5506       0.0079\n",
      "subj03           0.4471       0.4437       0.0034\n",
      "subj04           0.3854       0.3652       0.0202\n",
      "subj05           0.3921       0.3726       0.0194\n",
      "subj06           0.3583       0.3440       0.0142\n",
      "subj07           0.5731       0.5619       0.0112\n",
      "subj08           0.4782       0.4609       0.0174\n",
      "\n",
      "      Mean       0.4609       0.4467       0.0141\n",
      "\n",
      "Note: Small differences are expected because the benchmark uses\n",
      "a cross-validated ridge metric that may handle multi-output fitting\n",
      "differently from sklearn's single RidgeCV.\n"
     ]
    }
   ],
   "source": [
    "# Compare standalone vs benchmark results\n",
    "print('=== Standalone Ridge vs Benchmark Comparison (Surface V4) ===')\n",
    "print(f'{\"Subject\":<10} {\"Standalone\":>12} {\"Benchmark\":>12} {\"Diff\":>12}')\n",
    "print('-' * 50)\n",
    "\n",
    "for subj_label in subjects:\n",
    "    standalone_r = standalone_results[subj_label]['median_r']\n",
    "    bm_r = benchmark_per_subj.get(subj_label, float('nan'))\n",
    "    diff = abs(standalone_r - bm_r) if not np.isnan(bm_r) else float('nan')\n",
    "    print(f'{subj_label:<10} {standalone_r:>12.4f} {bm_r:>12.4f} {diff:>12.4f}')\n",
    "\n",
    "benchmark_raw = float(benchmark_score.raw.values)\n",
    "print(f'\\n{\"Mean\":>10} {standalone_mean_r:>12.4f} {benchmark_raw:>12.4f} '\n",
    "      f'{abs(standalone_mean_r - benchmark_raw):>12.4f}')\n",
    "\n",
    "print(f'\\nNote: Small differences are expected because the benchmark uses')\n",
    "print(f'a cross-validated ridge metric that may handle multi-output fitting')\n",
    "print(f'differently from sklearn\\'s single RidgeCV.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Validation | What it proves |\n",
    "|---|---|\n",
    "| Section 1: NB02 -> filter -> global z-score -> assembly | NB03 packaging step is correct |\n",
    "| Section 1: Vertex spot checks | Individual values trace correctly |\n",
    "| Section 2: Raw MGH -> assembly (subj01, V4) | Full surface preprocessing chain is correct |\n",
    "| Section 2: Vertex/hemisphere ordering | Assembly neuroid ordering matches extraction order |\n",
    "| Section 3: Standalone ridge vs benchmark | Benchmark metric code works on surface data |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Surface Assembly Validation Summary ===\n",
      "\n",
      "Section 1 (Vertex-Level Spot Check):\n",
      "  NB02->assembly train max_diff: 0.00e+00 [PASS]\n",
      "  NB02->assembly test max_diff:  9.54e-07 [PASS]\n",
      "  5/5 spot checks: PASS\n",
      "\n",
      "Section 2 (End-to-End Raw Data Bypass):\n",
      "  Raw MGH->assembly train max_diff: 1.67e-06 [PASS]\n",
      "  Raw MGH->assembly test max_diff:  2.38e-06 [PASS]\n",
      "  Vertex ordering: PASS\n",
      "  Hemisphere ordering: PASS\n",
      "\n",
      "Section 3 (Standalone Ridge):\n",
      "  Standalone mean r: 0.4609\n",
      "  Benchmark mean r:  0.4467\n",
      "  Difference:        0.0141\n",
      "\n",
      "All validations passed.\n"
     ]
    }
   ],
   "source": [
    "print('=== Surface Assembly Validation Summary ===')\n",
    "print()\n",
    "print('Section 1 (Vertex-Level Spot Check):')\n",
    "print(f'  NB02->assembly train max_diff: {max_diff:.2e} [PASS]')\n",
    "print(f'  NB02->assembly test max_diff:  {max_diff_test:.2e} [PASS]')\n",
    "print(f'  5/5 spot checks: PASS')\n",
    "print()\n",
    "print('Section 2 (End-to-End Raw Data Bypass):')\n",
    "print(f'  Raw MGH->assembly train max_diff: {train_max_diff:.2e} [PASS]')\n",
    "print(f'  Raw MGH->assembly test max_diff:  {test_max_diff:.2e} [PASS]')\n",
    "print(f'  Vertex ordering: PASS')\n",
    "print(f'  Hemisphere ordering: PASS')\n",
    "print()\n",
    "print('Section 3 (Standalone Ridge):')\n",
    "print(f'  Standalone mean r: {standalone_mean_r:.4f}')\n",
    "print(f'  Benchmark mean r:  {benchmark_raw:.4f}')\n",
    "print(f'  Difference:        {abs(standalone_mean_r - benchmark_raw):.4f}')\n",
    "print()\n",
    "print('All validations passed.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nsd-2026",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}