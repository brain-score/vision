{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# NSD Data Preparation\n",
    "\n",
    "Extract shared-image betas for all 4 regions (V1, V2, V4, IT) across all 8 subjects,\n",
    "compute per-voxel noise ceilings, and construct a NeuroidAssembly following the\n",
    "Hebart2023 pattern.\n",
    "\n",
    "**Inputs:** Raw NSD data on `/Volumes/Hagibis/nsd`\n",
    "\n",
    "**Outputs:** Per-region NeuroidAssembly `.nc` files ready for Brain-Score benchmark packaging.\n",
    "\n",
    "**Key design decisions:**\n",
    "- Volumetric HDF5 betas (int16 / 300 for % signal change)\n",
    "- Z-score within session (750 trials, per voxel)\n",
    "- Average across 3 repetitions per shared image\n",
    "- Only images with 3 complete reps across ALL 8 subjects (subjects 3/4/6/8 incomplete)\n",
    "- ncsnr-based noise ceiling per voxel (percentage, 0-100)\n",
    "- Single pass per session: extract all 4 regions simultaneously\n",
    "- Train/test split: 80/20, seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport pandas as pd\nimport xarray as xr\nimport h5py\nimport nibabel as nib\nimport scipy.io\nfrom pathlib import Path\nfrom collections import defaultdict\nimport time\nimport gc\n\nNSD_ROOT = Path('/Volumes/Hagibis/nsd')\nOUTPUT_DIR = Path('/Volumes/Hagibis/nsd/assemblies')\nOUTPUT_DIR.mkdir(exist_ok=True)\n\n# --- Subject Configuration ---\n# Use all 8 subjects (515 shared images with 3 reps):\nSUBJECT_LIST = [1, 2, 3, 4, 5, 6, 7, 8]\n# Or use only 4 complete subjects (40 sessions each, ~1000 images):\n# SUBJECT_LIST = [1, 2, 5, 7]\n\nN_SUBJECTS = len(SUBJECT_LIST)\nALL_SESSIONS = {1: 40, 2: 40, 3: 32, 4: 30, 5: 40, 6: 32, 7: 40, 8: 30}\nSESSIONS_PER_SUBJECT = {s: ALL_SESSIONS[s] for s in SUBJECT_LIST}\n\nTRIALS_PER_SESSION = 750\nN_SHARED_IMAGES = 1000\nN_REPS = 3\n\n# Region definitions\n# V1, V2, V4 from prf-visualrois (Kastner2015.mgz.ctab)\n# IT: NSD \"streams\" ventral parcellation (label 5), consistent with Algonauts 2023.\nREGION_TO_PRF_LABELS = {\n    'V1': [1, 2],   # V1v, V1d\n    'V2': [3, 4],   # V2v, V2d\n    'V4': [7],       # hV4\n}\n\nSTREAMS_VENTRAL_LABEL = 5\n\nREGIONS = ['V1', 'V2', 'V4', 'IT']\n\nprint(f'Output directory: {OUTPUT_DIR}')\nprint(f'Subjects: {SUBJECT_LIST}')\nprint(f'Total sessions to process: {sum(SESSIONS_PER_SUBJECT.values())}')"
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Data Loading Utilities\n",
    "\n",
    "Reuse validated functions from notebook 01."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": "def load_roi(subj: int, roi_name: str) -> np.ndarray:\n    \"\"\"Load a volumetric ROI mask, transposed to match HDF5 beta dims.\"\"\"\n    path = NSD_ROOT / f'subj{subj:02d}' / 'rois' / f'{roi_name}.nii.gz'\n    data = nib.load(str(path)).get_fdata()\n    return data.T  # (81, 104, 83) -> (83, 104, 81)\n\n\ndef load_session_betas(subj: int, session: int) -> np.ndarray:\n    \"\"\"Load volumetric betas for one session. Returns float32 in % signal change.\"\"\"\n    path = NSD_ROOT / f'subj{subj:02d}' / 'betas' / f'betas_session{session:02d}.hdf5'\n    with h5py.File(str(path), 'r') as f:\n        betas = f['betas'][:]  # (750, 83, 104, 81) int16\n    return betas.astype(np.float32) / 300.0\n\n\ndef load_ncsnr(subj: int) -> np.ndarray:\n    \"\"\"Load volumetric ncsnr, transposed to match HDF5 beta dims.\"\"\"\n    path = NSD_ROOT / f'subj{subj:02d}' / 'betas' / 'ncsnr.nii.gz'\n    data = nib.load(str(path)).get_fdata()\n    return data.T\n\n\ndef ncsnr_to_nc(ncsnr: np.ndarray, k: int = 3) -> np.ndarray:\n    \"\"\"Convert ncsnr to noise ceiling percentage. NC = 100 * ncsnr^2 / (ncsnr^2 + 1/k)\"\"\"\n    return 100.0 * ncsnr**2 / (ncsnr**2 + 1.0 / k)\n\n\ndef get_roi_masks(subj: int) -> dict[str, np.ndarray]:\n    \"\"\"Build boolean masks for all 4 regions for a subject.\"\"\"\n    prf = load_roi(subj, 'prf-visualrois')\n    \n    masks = {}\n    for region, labels in REGION_TO_PRF_LABELS.items():\n        masks[region] = np.isin(prf, labels)\n    \n    # IT: NSD \"streams\" ventral parcellation (label 5), consistent with Algonauts 2023.\n    lh_streams = load_roi(subj, 'lh.streams')\n    rh_streams = load_roi(subj, 'rh.streams')\n    masks['IT'] = (lh_streams == STREAMS_VENTRAL_LABEL) | (rh_streams == STREAMS_VENTRAL_LABEL)\n    \n    return masks\n\n\n# Verify masks load correctly\ntest_masks = get_roi_masks(1)\nfor region, mask in test_masks.items():\n    print(f'{region}: {mask.sum():>5,} voxels')"
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 2. Trial Mapping\n",
    "\n",
    "Identify which trials correspond to the 1,000 shared images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": "# Load experiment design\nstim_info = pd.read_csv(NSD_ROOT / 'metadata' / 'nsd_stim_info_merged.csv', index_col=0)\nexpdesign = scipy.io.loadmat(NSD_ROOT / 'metadata' / 'nsd_expdesign.mat')\nmasterordering = expdesign['masterordering'].flatten()  # (30000,)\nsubjectim = expdesign['subjectim']  # (8, 10000)\nsharedix = expdesign['sharedix'].flatten()  # (1000,) 1-indexed nsdIds\n\n\ndef get_shared_trial_info(subj: int) -> pd.DataFrame:\n    \"\"\"Find trial indices for shared images for a given subject.\n    \n    Args:\n        subj: 1-indexed subject number\n    \n    Returns:\n        DataFrame with columns: nsd_id, rep, session, trial_in_session, global_trial\n    \"\"\"\n    subj_idx = subj - 1  # 0-indexed for subjectim array\n    n_sessions = SESSIONS_PER_SUBJECT[subj]\n    n_total_trials = n_sessions * TRIALS_PER_SESSION\n    \n    subj_nsdids = subjectim[subj_idx]  # (10000,) 1-indexed\n    nsdid_to_imgidx = {int(nsd_id): img_idx + 1 for img_idx, nsd_id in enumerate(subj_nsdids)}\n    \n    shared_imgidxs = set()\n    for nsd_id in sharedix:\n        if int(nsd_id) in nsdid_to_imgidx:\n            shared_imgidxs.add(nsdid_to_imgidx[int(nsd_id)])\n    \n    records = []\n    rep_counter = {}\n    for trial_idx in range(n_total_trials):\n        img_idx = masterordering[trial_idx]\n        if img_idx in shared_imgidxs:\n            nsd_id = subj_nsdids[img_idx - 1]\n            rep = rep_counter.get(img_idx, 0)\n            rep_counter[img_idx] = rep + 1\n            session = trial_idx // TRIALS_PER_SESSION + 1\n            trial_in_session = trial_idx % TRIALS_PER_SESSION\n            records.append({\n                'nsd_id': int(nsd_id - 1),  # 0-indexed\n                'rep': rep,\n                'session': session,\n                'trial_in_session': trial_in_session,\n                'global_trial': trial_idx,\n            })\n    \n    return pd.DataFrame(records)\n\n\n# Build trial info for all subjects and find images with 3 complete reps\nall_trial_info = {}\nimages_with_3reps = {}  # {subj: set of nsd_ids with 3 reps}\n\nfor subj in SUBJECT_LIST:\n    trial_info = get_shared_trial_info(subj)\n    all_trial_info[subj] = trial_info\n    \n    # Count reps per image\n    reps_per_image = trial_info.groupby('nsd_id')['rep'].count()\n    n_with_3 = (reps_per_image == 3).sum()\n    n_with_2 = (reps_per_image == 2).sum()\n    n_with_1 = (reps_per_image == 1).sum()\n    images_with_3reps[subj] = set(reps_per_image[reps_per_image == 3].index)\n    \n    print(f'subj{subj:02d}: {len(trial_info)} trials, '\n          f'{trial_info[\"nsd_id\"].nunique()} unique images, '\n          f'3-rep={n_with_3}, 2-rep={n_with_2}, 1-rep={n_with_1}')\n\n# Find images with 3 reps across ALL subjects in SUBJECT_LIST\ncommon_3rep_images = images_with_3reps[SUBJECT_LIST[0]]\nfor subj in SUBJECT_LIST[1:]:\n    common_3rep_images = common_3rep_images & images_with_3reps[subj]\n\ncommon_3rep_images = sorted(common_3rep_images)\nprint(f'\\nImages with 3 reps in all {N_SUBJECTS} subjects: {len(common_3rep_images)}')\n\n# Filter trial_info to only include these images\nfor subj in SUBJECT_LIST:\n    all_trial_info[subj] = all_trial_info[subj][\n        all_trial_info[subj]['nsd_id'].isin(common_3rep_images)\n    ].reset_index(drop=True)\n    assert len(all_trial_info[subj]) == len(common_3rep_images) * 3\n\nN_USABLE_IMAGES = len(common_3rep_images)\nprint(f'Using {N_USABLE_IMAGES} images with complete data across all subjects')"
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 3. Extract Betas: All Regions, All Subjects\n",
    "\n",
    "Single pass per session: load betas once, extract all 4 regions simultaneously.\n",
    "Z-score within session per voxel. Store per-rep betas, then average.\n",
    "\n",
    "**Expected output per subject per region:** `(1000, n_voxels)` averaged betas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": "def extract_all_regions_for_subject(\n    subj: int,\n    masks: dict[str, np.ndarray],\n    trial_info: pd.DataFrame,\n    n_images: int,\n) -> dict[str, np.ndarray]:\n    \"\"\"Extract z-scored, rep-averaged betas for all regions in a single pass.\n    \n    Args:\n        subj: 1-indexed subject number\n        masks: dict of region -> boolean mask (83, 104, 81)\n        trial_info: DataFrame from get_shared_trial_info (filtered to usable images)\n        n_images: number of usable images\n    \n    Returns:\n        dict of region -> averaged_betas (n_images, n_voxels)\n    \"\"\"\n    n_sessions = SESSIONS_PER_SUBJECT[subj]\n    nsd_ids_sorted = sorted(trial_info['nsd_id'].unique())\n    nsd_id_to_idx = {nsd_id: idx for idx, nsd_id in enumerate(nsd_ids_sorted)}\n    \n    # Pre-allocate per-rep storage for each region\n    per_rep = {}\n    for region, mask in masks.items():\n        n_voxels = mask.sum()\n        per_rep[region] = np.zeros((n_images, N_REPS, n_voxels), dtype=np.float32)\n    \n    t0 = time.time()\n    for session in range(1, n_sessions + 1):\n        session_trials = trial_info[trial_info['session'] == session]\n        if len(session_trials) == 0:\n            continue\n        \n        # Load session betas ONCE\n        session_betas = load_session_betas(subj, session)  # (750, 83, 104, 81)\n        \n        # Extract and z-score each region\n        for region, mask in masks.items():\n            roi_betas = session_betas[:, mask]  # (750, n_voxels)\n            \n            # Stage 1 of 2: Session z-score (Allen et al. 2022, Extended Data Fig. 8).\n            # Normalize each voxel to mean=0, std=1 within each 750-trial session.\n            # Removes within-session non-stationarities and equalizes units across\n            # voxels. This is the only normalization the NSD paper prescribes.\n            # Stage 2 (global z-score per subject) is applied later in NB03.\n            mean = roi_betas.mean(axis=0, keepdims=True)\n            std = roi_betas.std(axis=0, keepdims=True)\n            std[std == 0] = 1.0\n            roi_betas = (roi_betas - mean) / std\n            \n            # Collect shared-image trials\n            for _, row in session_trials.iterrows():\n                img_idx = nsd_id_to_idx[row['nsd_id']]\n                per_rep[region][img_idx, row['rep']] = roi_betas[row['trial_in_session']]\n        \n        del session_betas\n        \n        if session % 10 == 0:\n            elapsed = time.time() - t0\n            print(f'  subj{subj:02d} session {session}/{n_sessions} ({elapsed:.0f}s)', flush=True)\n    \n    # Average across repetitions\n    averaged = {}\n    for region in masks:\n        averaged[region] = per_rep[region].mean(axis=1)  # (n_images, n_voxels)\n    \n    elapsed = time.time() - t0\n    print(f'  subj{subj:02d} done in {elapsed:.0f}s')\n    \n    return averaged\n\n\nprint('Ready to extract. Will process all 8 subjects.')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": "# Extract all subjects, all regions\n# This is the heavy computation: ~284 sessions, ~2 GB per session load\n\nall_betas = {}  # {subj: {region: (N_USABLE_IMAGES, n_voxels)}}\nall_masks = {}  # {subj: {region: boolean_mask}}\n\ntotal_t0 = time.time()\n\nfor subj in SUBJECT_LIST:\n    print(f'\\nProcessing subj{subj:02d} ({SESSIONS_PER_SUBJECT[subj]} sessions)...')\n    \n    masks = get_roi_masks(subj)\n    all_masks[subj] = masks\n    \n    betas = extract_all_regions_for_subject(\n        subj, masks, all_trial_info[subj], N_USABLE_IMAGES\n    )\n    all_betas[subj] = betas\n    \n    for region in REGIONS:\n        print(f'    {region}: {betas[region].shape}')\n    \n    gc.collect()\n\ntotal_elapsed = time.time() - total_t0\nprint(f'\\nTotal extraction time: {total_elapsed/60:.1f} minutes')"
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 4. Compute Per-Voxel Noise Ceilings\n",
    "\n",
    "Use ncsnr-based noise ceiling (validated to match Allen et al. 2022 at 36.20%).\n",
    "Store as percentage (0-100) following the Hebart2023 convention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": "# Compute per-voxel NC for each subject and region\nall_nc = {}  # {subj: {region: (n_voxels,) NC percentage}}\n\nfor subj in SUBJECT_LIST:\n    ncsnr = load_ncsnr(subj)\n    masks = all_masks[subj]\n    \n    all_nc[subj] = {}\n    for region in REGIONS:\n        ncsnr_roi = ncsnr[masks[region]]\n        nc_pct = ncsnr_to_nc(ncsnr_roi, k=3)\n        # Replace NaN with 0 (voxels with undefined ncsnr)\n        nc_pct = np.nan_to_num(nc_pct, nan=0.0)\n        all_nc[subj][region] = nc_pct\n        \n        print(f'subj{subj:02d} {region}: {len(nc_pct):>5} voxels, '\n              f'median NC={np.median(nc_pct):.1f}%, '\n              f'voxels > 30%: {(nc_pct > 30).sum()}')"
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 5. Construct NeuroidAssembly\n",
    "\n",
    "Following the Hebart2023 pattern:\n",
    "- Dims: `(presentation, neuroid)`\n",
    "- Presentation coords: `stimulus_id`, `repetition`\n",
    "- Neuroid coords: `neuroid_id`, `subject`, `region`, `nc_testset`, `voxel_x`, `voxel_y`, `voxel_z`\n",
    "- NC stored as percentage (0-100)\n",
    "- One assembly per region, all subjects concatenated along neuroid dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stimulus IDs: ['nsd_03049', 'nsd_03077', 'nsd_03157', 'nsd_03164', 'nsd_03171']...['nsd_72605', 'nsd_72719', 'nsd_72948']\n",
      "Total stimuli: 515\n"
     ]
    }
   ],
   "source": [
    "def get_voxel_coordinates(subj: int, mask: np.ndarray) -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"Get voxel indices (i, j, k) for voxels in a mask.\n",
    "    \n",
    "    Returns voxel indices in the func1pt8mm space. These are consistent\n",
    "    across subjects within NSD (same grid).\n",
    "    \"\"\"\n",
    "    indices = np.argwhere(mask)  # (n_voxels, 3)\n",
    "    return indices[:, 0], indices[:, 1], indices[:, 2]\n",
    "\n",
    "\n",
    "# Use the common set of images with 3 reps across all subjects\n",
    "shared_nsd_ids = common_3rep_images  # already sorted\n",
    "stimulus_ids = [f'nsd_{nsd_id:05d}' for nsd_id in shared_nsd_ids]\n",
    "\n",
    "print(f'Stimulus IDs: {stimulus_ids[:5]}...{stimulus_ids[-3:]}')\n",
    "print(f'Total stimuli: {len(stimulus_ids)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": "def build_region_assembly(region: str) -> xr.DataArray:\n    \"\"\"Build a NeuroidAssembly for one region, concatenating all subjects.\n    \n    Dims: (presentation, neuroid)\n    \"\"\"\n    # Collect data and metadata across subjects\n    data_blocks = []       # list of (1000, n_voxels_subj) arrays\n    neuroid_ids = []       # unique neuroid identifiers\n    subjects = []          # subject labels\n    regions_coord = []     # region label (constant per assembly)\n    nc_values = []         # per-voxel NC percentage\n    voxel_xs = []          # voxel i coordinate\n    voxel_ys = []          # voxel j coordinate\n    voxel_zs = []          # voxel k coordinate\n    \n    for subj in SUBJECT_LIST:\n        betas = all_betas[subj][region]  # (1000, n_voxels)\n        nc = all_nc[subj][region]        # (n_voxels,)\n        mask = all_masks[subj][region]   # (83, 104, 81)\n        \n        n_voxels = betas.shape[1]\n        vx, vy, vz = get_voxel_coordinates(subj, mask)\n        \n        data_blocks.append(betas)\n        \n        for v_idx in range(n_voxels):\n            neuroid_ids.append(f'subj{subj:02d}_{region}_v{v_idx:04d}')\n            subjects.append(f'subj{subj:02d}')\n            regions_coord.append(region)\n        \n        nc_values.extend(nc.tolist())\n        voxel_xs.extend(vx.tolist())\n        voxel_ys.extend(vy.tolist())\n        voxel_zs.extend(vz.tolist())\n    \n    # Concatenate across subjects: (1000, total_voxels)\n    data = np.concatenate(data_blocks, axis=1)\n    \n    # Build xarray DataArray\n    assembly = xr.DataArray(\n        data,\n        dims=['presentation', 'neuroid'],\n        coords={\n            # Presentation coords\n            'stimulus_id': ('presentation', stimulus_ids),\n            'nsd_id': ('presentation', shared_nsd_ids),\n            # Neuroid coords\n            'neuroid_id': ('neuroid', neuroid_ids),\n            'subject': ('neuroid', subjects),\n            'region': ('neuroid', regions_coord),\n            'nc_testset': ('neuroid', nc_values),\n            'voxel_x': ('neuroid', voxel_xs),\n            'voxel_y': ('neuroid', voxel_ys),\n            'voxel_z': ('neuroid', voxel_zs),\n        },\n    )\n    \n    return assembly\n\n\n# Build assemblies for all regions\nassemblies = {}\nfor region in REGIONS:\n    assembly = build_region_assembly(region)\n    assemblies[region] = assembly\n    \n    n_subjects = len(set(assembly.subject.values))\n    n_voxels = assembly.sizes['neuroid']\n    median_nc = float(np.median(assembly.nc_testset.values))\n    reliable = (assembly.nc_testset.values > 30).sum()\n    \n    print(f'{region}: shape={assembly.shape}, '\n          f'subjects={n_subjects}, voxels={n_voxels}, '\n          f'median NC={median_nc:.1f}%, reliable(>30%)={reliable}')"
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## 6. Train/Test Split\n",
    "\n",
    "800 train / 200 test images, fixed seed=42. The split is on stimulus_id, consistent\n",
    "across regions and subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cell-15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 412 images\n",
      "Test:  103 images\n",
      "No overlap: True\n",
      "\n",
      "Train stimulus_ids: ['nsd_03049', 'nsd_03157', 'nsd_03164', 'nsd_03171', 'nsd_03434']...\n",
      "Test stimulus_ids:  ['nsd_03077', 'nsd_03847', 'nsd_04690', 'nsd_04786', 'nsd_06444']...\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(42)\n",
    "all_indices = np.arange(N_USABLE_IMAGES)\n",
    "rng.shuffle(all_indices)\n",
    "\n",
    "n_train = int(N_USABLE_IMAGES * 0.8)\n",
    "n_test = N_USABLE_IMAGES - n_train\n",
    "\n",
    "train_indices = np.sort(all_indices[:n_train])\n",
    "test_indices = np.sort(all_indices[n_train:])\n",
    "\n",
    "train_stimulus_ids = [stimulus_ids[i] for i in train_indices]\n",
    "test_stimulus_ids = [stimulus_ids[i] for i in test_indices]\n",
    "\n",
    "print(f'Train: {len(train_indices)} images')\n",
    "print(f'Test:  {len(test_indices)} images')\n",
    "print(f'No overlap: {len(set(train_indices) & set(test_indices)) == 0}')\n",
    "print(f'\\nTrain stimulus_ids: {train_stimulus_ids[:5]}...')\n",
    "print(f'Test stimulus_ids:  {test_stimulus_ids[:5]}...')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## 7. Validation\n",
    "\n",
    "Cross-check against notebook 01 values before saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": "# Validate: per-ROI median NC should match expected values\n# V1, V2, V4 validated against notebook 01 (which uses correct prf-visualrois labels)\n# IT: no prior validated reference (now using streams ventral parcellation)\n\nexpected_nc = {'V1': 37.0, 'V2': 31.1, 'V4': 26.4}\n\nprint('Noise Ceiling Validation')\nprint('=' * 50)\nall_pass = True\n\nfor region in REGIONS:\n    assembly = assemblies[region]\n    \n    # Compute mean-of-medians (median per subject, mean across subjects)\n    per_subj_medians = []\n    for subj_label in [f'subj{s:02d}' for s in SUBJECT_LIST]:\n        subj_nc = assembly.nc_testset.values[assembly.subject.values == subj_label]\n        per_subj_medians.append(np.median(subj_nc))\n    \n    mean_of_medians = np.mean(per_subj_medians)\n    \n    if region in expected_nc:\n        expected = expected_nc[region]\n        diff = abs(mean_of_medians - expected)\n        status = 'PASS' if diff < 0.5 else 'FAIL'\n        if status == 'FAIL':\n            all_pass = False\n        print(f'{region}: mean-of-medians NC = {mean_of_medians:.1f}% '\n              f'(expected {expected:.1f}%, diff={diff:.2f}%) [{status}]')\n    else:\n        print(f'{region}: mean-of-medians NC = {mean_of_medians:.1f}% '\n              f'(no prior reference -- streams ventral parcellation)')\n\nprint(f'\\nOverall: {\"ALL PASS\" if all_pass else \"SOME FAILED\"} (for regions with reference values)')"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cell-18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assembly Shape & Quality Validation\n",
      "============================================================\n",
      "V1:\n",
      "  Shape: (515, 9039)\n",
      "  Subjects: ['subj01', 'subj02', 'subj03', 'subj04', 'subj05', 'subj06', 'subj07', 'subj08']\n",
      "  NaN count: 0\n",
      "  Data mean=-0.0212, std=0.6764\n",
      "  NC range: [0.0, 83.0]%\n",
      "V2:\n",
      "  Shape: (515, 8792)\n",
      "  Subjects: ['subj01', 'subj02', 'subj03', 'subj04', 'subj05', 'subj06', 'subj07', 'subj08']\n",
      "  NaN count: 0\n",
      "  Data mean=-0.0237, std=0.6654\n",
      "  NC range: [0.0, 81.6]%\n",
      "V4:\n",
      "  Shape: (515, 3982)\n",
      "  Subjects: ['subj01', 'subj02', 'subj03', 'subj04', 'subj05', 'subj06', 'subj07', 'subj08']\n",
      "  NaN count: 0\n",
      "  Data mean=-0.0262, std=0.6479\n",
      "  NC range: [0.0, 77.3]%\n",
      "IT:\n",
      "  Shape: (515, 35429)\n",
      "  Subjects: ['subj01', 'subj02', 'subj03', 'subj04', 'subj05', 'subj06', 'subj07', 'subj08']\n",
      "  NaN count: 0\n",
      "  Data mean=-0.0251, std=0.6147\n",
      "  NC range: [0.0, 84.6]%\n"
     ]
    }
   ],
   "source": [
    "# Validate assembly shapes and data quality\n",
    "print('Assembly Shape & Quality Validation')\n",
    "print('=' * 60)\n",
    "\n",
    "for region in REGIONS:\n",
    "    a = assemblies[region]\n",
    "    \n",
    "    # Check dims\n",
    "    assert a.dims == ('presentation', 'neuroid'), f'{region}: unexpected dims {a.dims}'\n",
    "    assert a.sizes['presentation'] == N_USABLE_IMAGES, f'{region}: expected {N_USABLE_IMAGES} presentations'\n",
    "    \n",
    "    # Check no NaN in data\n",
    "    n_nan = np.isnan(a.values).sum()\n",
    "    \n",
    "    # Check subjects present\n",
    "    unique_subjs = sorted(set(a.subject.values))\n",
    "    \n",
    "    # Check data range (z-scored, averaged across 3 reps -> should be moderate)\n",
    "    data_std = float(np.std(a.values))\n",
    "    data_mean = float(np.mean(a.values))\n",
    "    \n",
    "    print(f'{region}:')\n",
    "    print(f'  Shape: {a.shape}')\n",
    "    print(f'  Subjects: {unique_subjs}')\n",
    "    print(f'  NaN count: {n_nan}')\n",
    "    print(f'  Data mean={data_mean:.4f}, std={data_std:.4f}')\n",
    "    print(f'  NC range: [{float(a.nc_testset.min()):.1f}, {float(a.nc_testset.max()):.1f}]%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "r5zgw07mp9",
   "metadata": {},
   "source": [
    "## 8b. Assembly Visualizations\n",
    "\n",
    "Standard representational analysis figures:\n",
    "1. **RDMs (Representational Dissimilarity Matrices):** Pairwise image dissimilarity in each region's neural space, revealing representational geometry\n",
    "2. **Inter-subject RDM consistency:** Validates that stimulus-driven signal dominates noise across subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jkj38kkomv",
   "metadata": {},
   "outputs": [],
   "source": "# Representational Dissimilarity Matrices (RDMs) per region\n# Average per-subject RDMs to reveal stimulus-driven representational structure.\n# Images reordered via hierarchical clustering to expose category/similarity structure.\n\nimport matplotlib.pyplot as plt\nfrom scipy.cluster.hierarchy import linkage, leaves_list\nfrom scipy.spatial.distance import squareform\nfrom matplotlib.gridspec import GridSpec\n\nfig = plt.figure(figsize=(22, 9))\ngs = GridSpec(2, 5, width_ratios=[1, 1, 1, 1, 0.05], wspace=0.25, hspace=0.3)\n\nregion_rdms = {}\nregion_orders = {}\n\nfor idx, region in enumerate(REGIONS):\n    assembly = assemblies[region]\n    \n    # Compute per-subject RDMs, then average\n    subject_rdms = []\n    for subj_label in [f'subj{s:02d}' for s in SUBJECT_LIST]:\n        subj_mask = assembly.subject.values == subj_label\n        data = assembly.values[:, subj_mask]\n        data_c = data - data.mean(axis=1, keepdims=True)\n        norms = np.linalg.norm(data_c, axis=1, keepdims=True)\n        norms[norms == 0] = 1.0\n        data_c = data_c / norms\n        subject_rdms.append(1.0 - data_c @ data_c.T)\n    \n    avg_rdm = np.mean(subject_rdms, axis=0)\n    region_rdms[region] = avg_rdm\n    \n    # Hierarchical clustering to reorder images\n    condensed = squareform(avg_rdm, checks=False)\n    Z = linkage(condensed, method='average')\n    order = leaves_list(Z)\n    region_orders[region] = order\n    sorted_rdm = avg_rdm[np.ix_(order, order)]\n    \n    triu_vals = avg_rdm[np.triu_indices(N_USABLE_IMAGES, k=1)]\n    vmin, vmax = np.percentile(triu_vals, [2, 98])\n    \n    # Top row: original ordering\n    ax = fig.add_subplot(gs[0, idx])\n    ax.imshow(avg_rdm, cmap='viridis', vmin=vmin, vmax=vmax, aspect='equal')\n    ax.set_title(f'{region} (original order)', fontsize=11)\n    ax.set_xlabel('Image')\n    if idx == 0:\n        ax.set_ylabel('Image')\n    \n    # Bottom row: clustered ordering\n    ax = fig.add_subplot(gs[1, idx])\n    im = ax.imshow(sorted_rdm, cmap='viridis', vmin=vmin, vmax=vmax, aspect='equal')\n    ax.set_title(f'{region} (clustered)\\n'\n                 f'mean={triu_vals.mean():.2f}, std={triu_vals.std():.3f}',\n                 fontsize=11)\n    ax.set_xlabel('Image (reordered)')\n    if idx == 0:\n        ax.set_ylabel('Image (reordered)')\n\n# Shared colorbar in dedicated column\ncax = fig.add_subplot(gs[:, 4])\nfig.colorbar(im, cax=cax, label='1 - Pearson r')\n\nfig.suptitle('Subject-Averaged RDMs: Original vs. Hierarchically Clustered',\n             fontsize=14, y=1.01)\nplt.show()\n\n# Cross-region RDM correlation\ntril = np.tril_indices(N_USABLE_IMAGES, k=-1)\nprint('Cross-region RDM correlation (lower triangle of subject-averaged RDMs):')\nfor i, r1 in enumerate(REGIONS):\n    for r2 in REGIONS[i+1:]:\n        r = np.corrcoef(region_rdms[r1][tril], region_rdms[r2][tril])[0, 1]\n        print(f'  {r1} vs {r2}: r = {r:.3f}')"
  },
  {
   "cell_type": "markdown",
   "id": "6a3kxjkvxw5",
   "metadata": {},
   "source": [
    "### RDM Interpretation\n",
    "\n",
    "Each matrix shows the pairwise dissimilarity (1 - Pearson r) between all 515 stimulus images\n",
    "in neural response space, averaged across 8 subjects. The **top row** uses the arbitrary nsd_id\n",
    "ordering; the **bottom row** reorders images via hierarchical clustering (average linkage) to\n",
    "group neurally similar images together.\n",
    "\n",
    "**Key observations:**\n",
    "\n",
    "- **V1/V2 (std ~0.09):** Many small, fragmented clusters along the diagonal. These reflect\n",
    "  low-level feature similarity -- images sharing similar spatial frequency, orientation, or contrast\n",
    "  statistics evoke correlated V1/V2 response patterns regardless of semantic content.\n",
    "- **V4 (std ~0.08):** Intermediate structure with broader clusters than V1/V2, consistent with\n",
    "  mid-level feature selectivity (texture, curvature, shape fragments).\n",
    "- **IT (std ~0.085):** The most prominent block-diagonal structure with a few large, distinct\n",
    "  clusters. The dominant dark block likely corresponds to scenes/places (the largest semantic\n",
    "  category in COCO-derived NSD stimuli), which evoke highly correlated patterns in\n",
    "  parahippocampal and fusiform regions. The clear off-diagonal bands (yellow) show that\n",
    "  IT representations sharply distinguish between semantic categories.\n",
    "\n",
    "**Cross-region RDM correlations** decrease monotonically along the ventral stream\n",
    "(V1-V2: 0.82, V2-V4: 0.66, V4-IT: 0.43, V1-IT: 0.16), confirming a representational\n",
    "transformation from low-level retinotopic to high-level categorical encoding. This gradient\n",
    "is a strong sanity check that our ROI definitions and data extraction are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rnre32b1kg",
   "metadata": {},
   "outputs": [],
   "source": "# Inter-subject representational consistency\n# For each region, compute per-subject RDMs and correlate their lower triangles.\n# High inter-subject RDM correlation validates that stimulus-driven signal dominates noise.\n\nfig, axes = plt.subplots(1, 4, figsize=(20, 4.5))\n\nfor idx, region in enumerate(REGIONS):\n    ax = axes[idx]\n    assembly = assemblies[region]\n    \n    subject_rdm_vectors = {}\n    for subj_label in [f'subj{s:02d}' for s in SUBJECT_LIST]:\n        subj_mask = assembly.subject.values == subj_label\n        data = assembly.values[:, subj_mask]  # (515, n_voxels_subj)\n        \n        # Correlation-distance RDM\n        data_c = data - data.mean(axis=1, keepdims=True)\n        norms = np.linalg.norm(data_c, axis=1, keepdims=True)\n        norms[norms == 0] = 1.0\n        data_c = data_c / norms\n        rdm = 1.0 - data_c @ data_c.T  # (515, 515)\n        \n        tril = np.tril_indices(N_USABLE_IMAGES, k=-1)\n        subject_rdm_vectors[subj_label] = rdm[tril]\n    \n    # Pairwise RDM correlation\n    subj_list = [f'subj{s:02d}' for s in SUBJECT_LIST]\n    corr_mat = np.zeros((N_SUBJECTS, N_SUBJECTS))\n    for i, si in enumerate(subj_list):\n        for j, sj in enumerate(subj_list):\n            corr_mat[i, j] = np.corrcoef(\n                subject_rdm_vectors[si], subject_rdm_vectors[sj]\n            )[0, 1]\n    \n    im = ax.imshow(corr_mat, cmap='RdYlBu_r', vmin=0, vmax=1, aspect='equal')\n    ax.set_xticks(range(N_SUBJECTS))\n    ax.set_yticks(range(N_SUBJECTS))\n    ax.set_xticklabels([f'S{s}' for s in SUBJECT_LIST], fontsize=8)\n    ax.set_yticklabels([f'S{s}' for s in SUBJECT_LIST], fontsize=8)\n    \n    for i in range(N_SUBJECTS):\n        for j in range(N_SUBJECTS):\n            color = 'white' if corr_mat[i, j] < 0.5 else 'black'\n            ax.text(j, i, f'{corr_mat[i, j]:.2f}', ha='center', va='center',\n                    fontsize=7, color=color)\n    \n    off_diag = corr_mat[np.triu_indices(N_SUBJECTS, k=1)]\n    ax.set_title(f'{region}\\n(mean r = {off_diag.mean():.3f})', fontsize=12)\n\nfig.colorbar(im, ax=axes[-1], shrink=0.8, label='RDM Pearson r')\nfig.suptitle('Inter-Subject Representational Consistency (RDM Correlation)',\n             fontsize=13)\nplt.tight_layout()\nplt.show()\n\n# Print summary\nfor region in REGIONS:\n    assembly = assemblies[region]\n    subject_rdm_vectors = {}\n    for subj_label in [f'subj{s:02d}' for s in SUBJECT_LIST]:\n        subj_mask = assembly.subject.values == subj_label\n        data = assembly.values[:, subj_mask]\n        data_c = data - data.mean(axis=1, keepdims=True)\n        norms = np.linalg.norm(data_c, axis=1, keepdims=True)\n        norms[norms == 0] = 1.0\n        data_c = data_c / norms\n        rdm = 1.0 - data_c @ data_c.T\n        tril = np.tril_indices(N_USABLE_IMAGES, k=-1)\n        subject_rdm_vectors[subj_label] = rdm[tril]\n    \n    subj_list = [f'subj{s:02d}' for s in SUBJECT_LIST]\n    pairs = [(subject_rdm_vectors[si], subject_rdm_vectors[sj])\n             for i, si in enumerate(subj_list)\n             for j, sj in enumerate(subj_list) if j > i]\n    mean_r = np.mean([np.corrcoef(a, b)[0, 1] for a, b in pairs])\n    print(f'{region}: mean inter-subject RDM r = {mean_r:.3f}')"
  },
  {
   "cell_type": "markdown",
   "id": "ar116yeq0u4",
   "metadata": {},
   "source": [
    "### Inter-Subject Consistency Interpretation\n",
    "\n",
    "Each heatmap shows the Pearson correlation between every pair of subjects' RDM lower triangles\n",
    "for a given region. High off-diagonal values indicate that two subjects organize the same\n",
    "stimulus set similarly in neural space -- i.e., the representational geometry is driven by\n",
    "stimulus content rather than idiosyncratic noise.\n",
    "\n",
    "**Key observations:**\n",
    "\n",
    "- **IT has the highest consistency (mean r = 0.484).** This is the classic RSA finding:\n",
    "  higher-level categorical/semantic representations in inferotemporal cortex are remarkably\n",
    "  consistent across individuals, because category membership is a shared organizational\n",
    "  principle. All subject pairs exceed r = 0.15, with most above 0.5.\n",
    "- **V1 (0.376) and V2 (0.361) show moderate consistency.** Early visual areas encode\n",
    "  retinotopic features that are inherently stimulus-driven, but the exact voxel placement\n",
    "  and receptive field coverage vary across subjects (different cortical folding), which\n",
    "  lowers RDM agreement despite the underlying functional similarity.\n",
    "- **V4 has the lowest consistency (0.248).** This is the smallest ROI (~500 voxels/subject),\n",
    "  making per-subject RDMs noisier. V4's selectivity for intermediate features (textures,\n",
    "  curvature) is also less categorically organized than IT, yielding weaker cross-subject agreement.\n",
    "- **Subject 8 is consistently the weakest** across all regions (lowest row/column values),\n",
    "  aligning with having the fewest sessions (30) and lowest noise ceiling (NC median 5-21%\n",
    "  depending on region)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 8. Save Assemblies\n",
    "\n",
    "Save per-region assemblies as netCDF files. Also save the train/test split indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cell-20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Allen2022.V1.nc: 20.5 MB\n",
      "Saved Allen2022.V2.nc: 20.0 MB\n",
      "Saved Allen2022.V4.nc: 9.1 MB\n",
      "Saved Allen2022.IT.nc: 80.4 MB\n",
      "\n",
      "Saved train_test_split.csv\n",
      "  Train: 412\n",
      "  Test:  103\n"
     ]
    }
   ],
   "source": [
    "# Save assemblies\n",
    "for region in REGIONS:\n",
    "    path = OUTPUT_DIR / f'Allen2022.{region}.nc'\n",
    "    assemblies[region].to_netcdf(str(path))\n",
    "    size_mb = path.stat().st_size / 1e6\n",
    "    print(f'Saved {path.name}: {size_mb:.1f} MB')\n",
    "\n",
    "# Save train/test split\n",
    "split_df = pd.DataFrame({\n",
    "    'stimulus_id': stimulus_ids,\n",
    "    'nsd_id': shared_nsd_ids,\n",
    "    'split': ['train' if i in set(train_indices) else 'test' for i in range(N_USABLE_IMAGES)],\n",
    "})\n",
    "split_path = OUTPUT_DIR / 'train_test_split.csv'\n",
    "split_df.to_csv(str(split_path), index=False)\n",
    "print(f'\\nSaved {split_path.name}')\n",
    "print(f'  Train: {(split_df[\"split\"] == \"train\").sum()}')\n",
    "print(f'  Test:  {(split_df[\"split\"] == \"test\").sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cell-21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reload verification\n",
      "==================================================\n",
      "V1: reload OK, shape=(515, 9039)\n",
      "V2: reload OK, shape=(515, 8792)\n",
      "V4: reload OK, shape=(515, 3982)\n",
      "IT: reload OK, shape=(515, 35429)\n",
      "\n",
      "All assemblies verified.\n"
     ]
    }
   ],
   "source": [
    "# Verify saved files can be loaded back\n",
    "print('Reload verification')\n",
    "print('=' * 50)\n",
    "\n",
    "for region in REGIONS:\n",
    "    path = OUTPUT_DIR / f'Allen2022.{region}.nc'\n",
    "    loaded = xr.open_dataarray(str(path))\n",
    "    \n",
    "    # Check round-trip fidelity\n",
    "    orig = assemblies[region]\n",
    "    assert loaded.shape == orig.shape, f'{region}: shape mismatch'\n",
    "    assert np.allclose(loaded.values, orig.values, atol=1e-6), f'{region}: data mismatch'\n",
    "    assert list(loaded.coords) == list(orig.coords), f'{region}: coord mismatch'\n",
    "    \n",
    "    print(f'{region}: reload OK, shape={loaded.shape}')\n",
    "    loaded.close()\n",
    "\n",
    "print('\\nAll assemblies verified.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "## 9. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cell-23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "NSD Data Preparation Summary\n",
      "============================================================\n",
      "\n",
      "ASSEMBLIES CREATED:\n",
      "  Allen2022.V1: 515 stimuli x 9039 neuroids, median NC=37.4%, reliable(>30%)=5402\n",
      "  Allen2022.V2: 515 stimuli x 8792 neuroids, median NC=31.2%, reliable(>30%)=4584\n",
      "  Allen2022.V4: 515 stimuli x 3982 neuroids, median NC=25.3%, reliable(>30%)=1660\n",
      "  Allen2022.IT: 515 stimuli x 35429 neuroids, median NC=9.7%, reliable(>30%)=6805\n",
      "\n",
      "SPLIT:\n",
      "  Train: 412 stimuli\n",
      "  Test:  103 stimuli\n",
      "  Seed: 42\n",
      "\n",
      "FILES:\n",
      "  Allen2022.IT.nc: 80.4 MB\n",
      "  Allen2022.V1.nc: 20.5 MB\n",
      "  Allen2022.V2.nc: 20.0 MB\n",
      "  Allen2022.V4.nc: 9.1 MB\n",
      "  train_test_split.csv: 0.0 MB\n",
      "\n",
      "NEXT STEPS:\n",
      "  1. Package StimulusSet from nsd_stimuli.hdf5\n",
      "  2. Write Brain-Score benchmark plugin (Allen2022.V1-ridge, etc.)\n",
      "  3. Upload assemblies to S3 via Brain-Score data packaging\n"
     ]
    }
   ],
   "source": [
    "print('=' * 60)\n",
    "print('NSD Data Preparation Summary')\n",
    "print('=' * 60)\n",
    "print()\n",
    "print('ASSEMBLIES CREATED:')\n",
    "for region in REGIONS:\n",
    "    a = assemblies[region]\n",
    "    nc_med = np.median(a.nc_testset.values)\n",
    "    reliable = (a.nc_testset.values > 30).sum()\n",
    "    print(f'  Allen2022.{region}: {a.shape[0]} stimuli x {a.shape[1]} neuroids, '\n",
    "          f'median NC={nc_med:.1f}%, reliable(>30%)={reliable}')\n",
    "print()\n",
    "print('SPLIT:')\n",
    "print(f'  Train: {len(train_indices)} stimuli')\n",
    "print(f'  Test:  {len(test_indices)} stimuli')\n",
    "print(f'  Seed: 42')\n",
    "print()\n",
    "print('FILES:')\n",
    "for f in sorted(OUTPUT_DIR.iterdir()):\n",
    "    size_mb = f.stat().st_size / 1e6\n",
    "    print(f'  {f.name}: {size_mb:.1f} MB')\n",
    "print()\n",
    "print('NEXT STEPS:')\n",
    "print('  1. Package StimulusSet from nsd_stimuli.hdf5')\n",
    "print('  2. Write Brain-Score benchmark plugin (Allen2022.V1-ridge, etc.)')\n",
    "print('  3. Upload assemblies to S3 via Brain-Score data packaging')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nsd-2026",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}