{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05 - Assembly Validation (Volumetric)\n",
    "\n",
    "Validate that the Brain-Score packaged assemblies contain correct values by tracing\n",
    "the full preprocessing chain from raw NSD HDF5 betas.\n",
    "\n",
    "**Sections:**\n",
    "1. Voxel-level spot check: reproduce global z-score from NB02, compare with assembly\n",
    "2. End-to-end raw data bypass: reproduce V4 from raw HDF5 for subj01\n",
    "3. Standalone ridge regression: compare sklearn RidgeCV with benchmark output\n",
    "\n",
    "**Environment:** `conda activate vision-2026`\n",
    "\n",
    "**Requires:** External drive `/Volumes/Hagibis/nsd` mounted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NSD root: /Volumes/Hagibis/nsd\n",
      "Train: 412, Test: 103\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/kartik/Brain-Score 2026/vision')\n",
    "sys.path.insert(0, '/Users/kartik/Brain-Score 2026/core')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import h5py\n",
    "import nibabel as nib\n",
    "import scipy.io\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "NSD_ROOT = Path('/Volumes/Hagibis/nsd')\n",
    "ASSEMBLY_DIR = NSD_ROOT / 'assemblies'\n",
    "BRAINSCORE_DIR = NSD_ROOT / 'brainscore'\n",
    "\n",
    "REGIONS = ['V1', 'V2', 'V4', 'IT']\n",
    "SUBJECT_LIST = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "SESSIONS_PER_SUBJECT = {1: 40, 2: 40, 3: 32, 4: 30, 5: 40, 6: 32, 7: 40, 8: 30}\n",
    "TRIALS_PER_SESSION = 750\n",
    "VARIANT = '_8subj'\n",
    "\n",
    "# ROI definitions (same as NB02)\n",
    "REGION_TO_PRF_LABELS = {'V1': [1, 2], 'V2': [3, 4], 'V4': [7]}\n",
    "STREAMS_VENTRAL_LABEL = 5\n",
    "\n",
    "# Train/test split\n",
    "split_df = pd.read_csv(ASSEMBLY_DIR / f'train_test_split{VARIANT}.csv')\n",
    "train_ids = set(split_df.loc[split_df['split'] == 'train', 'stimulus_id'])\n",
    "test_ids = set(split_df.loc[split_df['split'] == 'test', 'stimulus_id'])\n",
    "\n",
    "assert NSD_ROOT.exists(), 'External drive not mounted'\n",
    "print(f'NSD root: {NSD_ROOT}')\n",
    "print(f'Train: {len(train_ids)}, Test: {len(test_ids)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Voxel-Level Spot Check\n",
    "\n",
    "Validate the NB03 packaging step by reproducing the global z-score from NB02 data\n",
    "and comparing with the Brain-Score assembly values.\n",
    "\n",
    "**Preprocessing chain being validated:**\n",
    "```\n",
    "NB02 assembly (session z-scored, rep-averaged)\n",
    "  -> global z-score (per subject, per region, stats from all 515 images)\n",
    "  -> split into train/test\n",
    "  -> Brain-Score assembly\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brain-Score train: (412, 84564, 1)\n",
      "Brain-Score test:  (309, 84564, 1)\n",
      "Train coords: ['stimulus_id', 'nsd_id', 'neuroid_id', 'subject', 'region', 'nc_testset', 'voxel_x', 'voxel_y', 'voxel_z', 'time_bin_start', 'time_bin_end']\n",
      "Test coords:  ['stimulus_id', 'nsd_id', 'repetition', 'neuroid_id', 'subject', 'region', 'nc_testset', 'voxel_x', 'voxel_y', 'voxel_z', 'time_bin_start', 'time_bin_end']\n"
     ]
    }
   ],
   "source": [
    "# Load Brain-Score packaged assemblies (NB03 output)\n",
    "bs_train = xr.open_dataarray(str(BRAINSCORE_DIR / f'Allen2022_fmri_train{VARIANT}.nc'))\n",
    "bs_test = xr.open_dataarray(str(BRAINSCORE_DIR / f'Allen2022_fmri_test{VARIANT}.nc'))\n",
    "bs_train.load()\n",
    "bs_test.load()\n",
    "\n",
    "print(f'Brain-Score train: {bs_train.shape}')\n",
    "print(f'Brain-Score test:  {bs_test.shape}')\n",
    "print(f'Train coords: {list(bs_train.coords)}')\n",
    "print(f'Test coords:  {list(bs_test.coords)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB02 V4: (515, 3982)\n",
      "Reproduced train: (412, 3982)\n",
      "Reproduced test: (103, 3982)\n"
     ]
    }
   ],
   "source": [
    "# Load NB02 assembly for V4 and reproduce global z-score\n",
    "nb02_v4 = xr.open_dataarray(str(ASSEMBLY_DIR / f'Allen2022.V4{VARIANT}.nc'))\n",
    "nb02_v4.load()\n",
    "print(f'NB02 V4: {nb02_v4.shape}')\n",
    "\n",
    "# Build train/test masks\n",
    "nb02_stimulus_ids = nb02_v4.coords['stimulus_id'].values\n",
    "train_mask = np.array([sid in train_ids for sid in nb02_stimulus_ids])\n",
    "test_mask = np.array([sid in test_ids for sid in nb02_stimulus_ids])\n",
    "\n",
    "# Reproduce global z-score for each subject (matching NB03)\n",
    "reproduced_train_blocks = []\n",
    "reproduced_test_blocks = []\n",
    "\n",
    "for subj in SUBJECT_LIST:\n",
    "    subj_label = f'subj{subj:02d}'\n",
    "    subj_mask = nb02_v4.coords['subject'].values == subj_label\n",
    "    data = nb02_v4.values[:, subj_mask]\n",
    "\n",
    "    mean = data.mean(axis=0)\n",
    "    std = data.std(axis=0)\n",
    "    std[std == 0] = 1.0\n",
    "    data_z = (data - mean) / std\n",
    "\n",
    "    reproduced_train_blocks.append(data_z[train_mask])\n",
    "    reproduced_test_blocks.append(data_z[test_mask])\n",
    "\n",
    "reproduced_train = np.concatenate(reproduced_train_blocks, axis=1)\n",
    "reproduced_test = np.concatenate(reproduced_test_blocks, axis=1)\n",
    "print(f'Reproduced train: {reproduced_train.shape}')\n",
    "print(f'Reproduced test: {reproduced_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== NB02 -> Global Z-Score -> Brain-Score Train (V4) ===\n",
      "Max absolute difference:  0.00e+00\n",
      "Mean absolute difference: 0.00e+00\n",
      "Correlation:              1.0000000000\n",
      "Match: PASS\n",
      "\n",
      "=== Test (averaged reps, V4) ===\n",
      "Max absolute difference: 9.54e-07\n",
      "Match: PASS\n"
     ]
    }
   ],
   "source": [
    "# Compare reproduced values with Brain-Score train assembly (V4 neuroids only)\n",
    "v4_neuroid_mask = bs_train.coords['region'].values == 'V4'\n",
    "bs_train_v4 = bs_train.values[:, v4_neuroid_mask, 0]\n",
    "\n",
    "max_diff = np.max(np.abs(reproduced_train - bs_train_v4))\n",
    "mean_diff = np.mean(np.abs(reproduced_train - bs_train_v4))\n",
    "r = np.corrcoef(reproduced_train.ravel(), bs_train_v4.ravel())[0, 1]\n",
    "\n",
    "print('=== NB02 -> Global Z-Score -> Brain-Score Train (V4) ===')\n",
    "print(f'Max absolute difference:  {max_diff:.2e}')\n",
    "print(f'Mean absolute difference: {mean_diff:.2e}')\n",
    "print(f'Correlation:              {r:.10f}')\n",
    "print(f'Match: {\"PASS\" if max_diff < 1e-5 else \"FAIL\"}')\n",
    "assert max_diff < 1e-5, f'Train V4 mismatch: max_diff={max_diff}'\n",
    "\n",
    "# Compare test (average the 3 reps in Brain-Score test)\n",
    "bs_test_v4_all = bs_test.values[:, v4_neuroid_mask, 0]\n",
    "n_test = len(test_ids)\n",
    "bs_test_v4_avg = bs_test_v4_all.reshape(n_test, 3, -1).mean(axis=1)\n",
    "\n",
    "max_diff_test = np.max(np.abs(reproduced_test - bs_test_v4_avg))\n",
    "print(f'\\n=== Test (averaged reps, V4) ===')\n",
    "print(f'Max absolute difference: {max_diff_test:.2e}')\n",
    "print(f'Match: {\"PASS\" if max_diff_test < 1e-5 else \"FAIL\"}')\n",
    "assert max_diff_test < 1e-5, f'Test V4 mismatch: max_diff={max_diff_test}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Voxel-Level Spot Check (V4) ===\n",
      "Subject    Stimulus       Voxel      Reproduced     Assembly         Diff Status\n",
      "----------------------------------------------------------------------------------\n",
      "subj01     nsd_03049      0           -1.760644    -1.760644     0.00e+00 PASS\n",
      "subj01     nsd_03049      100         -0.401076    -0.401076     0.00e+00 PASS\n",
      "subj04     nsd_37224      1646         2.987292     2.987292     0.00e+00 PASS\n",
      "subj08     nsd_72719      3981        -0.981733    -0.981733     0.00e+00 PASS\n",
      "subj05     nsd_20738      2271         0.676849     0.676849     0.00e+00 PASS\n",
      "\n",
      "All spot checks: PASS\n"
     ]
    }
   ],
   "source": [
    "# Spot check: trace 5 specific (subject, image, voxel) values\n",
    "print('=== Voxel-Level Spot Check (V4) ===')\n",
    "print(f'{\"Subject\":<10} {\"Stimulus\":<14} {\"Voxel\":<8} '\n",
    "      f'{\"Reproduced\":>12} {\"Assembly\":>12} {\"Diff\":>12} {\"Status\"}')\n",
    "print('-' * 82)\n",
    "\n",
    "v4_subjects = bs_train.coords['subject'].values[v4_neuroid_mask]\n",
    "train_stim_ids = bs_train.coords['stimulus_id'].values\n",
    "\n",
    "spot_checks = [\n",
    "    ('subj01', 0, 0),\n",
    "    ('subj01', 0, 100),\n",
    "    ('subj04', 200, 50),\n",
    "    ('subj08', 411, -1),\n",
    "    ('subj05', 100, 200),\n",
    "]\n",
    "\n",
    "all_pass = True\n",
    "for subj_label, img_idx, vox_idx in spot_checks:\n",
    "    subj_v4_mask = v4_subjects == subj_label\n",
    "    subj_start = np.where(subj_v4_mask)[0][0]\n",
    "    actual_vox_idx = subj_start + (vox_idx % subj_v4_mask.sum())\n",
    "\n",
    "    reproduced_val = reproduced_train[img_idx, actual_vox_idx]\n",
    "    assembly_val = bs_train_v4[img_idx, actual_vox_idx]\n",
    "    diff = abs(reproduced_val - assembly_val)\n",
    "    status = 'PASS' if diff < 1e-6 else 'FAIL'\n",
    "    if status == 'FAIL':\n",
    "        all_pass = False\n",
    "\n",
    "    print(f'{subj_label:<10} {train_stim_ids[img_idx]:<14} {actual_vox_idx:<8} '\n",
    "          f'{reproduced_val:>12.6f} {assembly_val:>12.6f} {diff:>12.2e} {status}')\n",
    "\n",
    "print(f'\\nAll spot checks: {\"PASS\" if all_pass else \"FAIL\"}')\n",
    "assert all_pass, 'Spot check failed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: End-to-End Raw Data Bypass\n",
    "\n",
    "Reproduce V4 betas for subj01 entirely from raw HDF5 files, applying the full\n",
    "preprocessing chain:\n",
    "```\n",
    "Raw HDF5 int16 / 300\n",
    "  -> Z-score within session (750 trials per voxel)\n",
    "  -> Collect shared-image trials, average 3 repetitions\n",
    "  -> Global z-score (stats from all 515 averaged images)\n",
    "  -> Compare with Brain-Score assembly\n",
    "```\n",
    "\n",
    "Then run a standalone ridge regression and compare with the benchmark score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilities loaded.\n"
     ]
    }
   ],
   "source": [
    "# --- Raw data utilities ---\n",
    "\n",
    "def load_roi(subj: int, roi_name: str) -> np.ndarray:\n",
    "    path = NSD_ROOT / f'subj{subj:02d}' / 'rois' / f'{roi_name}.nii.gz'\n",
    "    return nib.load(str(path)).get_fdata().T  # (81,104,83) -> (83,104,81)\n",
    "\n",
    "\n",
    "def load_session_betas(subj: int, session: int) -> np.ndarray:\n",
    "    path = NSD_ROOT / f'subj{subj:02d}' / 'betas' / f'betas_session{session:02d}.hdf5'\n",
    "    with h5py.File(str(path), 'r') as f:\n",
    "        betas = f['betas'][:]\n",
    "    return betas.astype(np.float32) / 300.0\n",
    "\n",
    "\n",
    "def get_v4_mask(subj: int) -> np.ndarray:\n",
    "    prf = load_roi(subj, 'prf-visualrois')\n",
    "    return np.isin(prf, [7])  # hV4\n",
    "\n",
    "\n",
    "# --- Trial mapping ---\n",
    "expdesign = scipy.io.loadmat(NSD_ROOT / 'metadata' / 'nsd_expdesign.mat')\n",
    "masterordering = expdesign['masterordering'].flatten()\n",
    "subjectim = expdesign['subjectim']\n",
    "sharedix = expdesign['sharedix'].flatten()\n",
    "\n",
    "all_nsd_ids = sorted(split_df['nsd_id'].values)\n",
    "nsd_id_to_idx = {nsd_id: idx for idx, nsd_id in enumerate(all_nsd_ids)}\n",
    "N_IMAGES = len(all_nsd_ids)\n",
    "\n",
    "\n",
    "def get_trial_info(subj_idx: int, target_nsd_ids: set) -> pd.DataFrame:\n",
    "    n_sessions = SESSIONS_PER_SUBJECT[subj_idx + 1]\n",
    "    n_total_trials = n_sessions * TRIALS_PER_SESSION\n",
    "    subj_nsdids = subjectim[subj_idx]\n",
    "    nsdid_to_imgidx = {int(nsd_id): img_idx + 1\n",
    "                       for img_idx, nsd_id in enumerate(subj_nsdids)}\n",
    "\n",
    "    shared_imgidxs = set()\n",
    "    for nsd_id in sharedix:\n",
    "        if int(nsd_id) in nsdid_to_imgidx:\n",
    "            shared_imgidxs.add(nsdid_to_imgidx[int(nsd_id)])\n",
    "\n",
    "    records = []\n",
    "    rep_counter = {}\n",
    "    for trial_idx in range(n_total_trials):\n",
    "        img_idx = masterordering[trial_idx]\n",
    "        if img_idx in shared_imgidxs:\n",
    "            nsd_id = int(subj_nsdids[img_idx - 1] - 1)\n",
    "            if nsd_id not in target_nsd_ids:\n",
    "                rep_counter[img_idx] = rep_counter.get(img_idx, 0) + 1\n",
    "                continue\n",
    "            rep = rep_counter.get(img_idx, 0)\n",
    "            rep_counter[img_idx] = rep + 1\n",
    "            session = trial_idx // TRIALS_PER_SESSION + 1\n",
    "            trial_in_session = trial_idx % TRIALS_PER_SESSION\n",
    "            records.append({\n",
    "                'nsd_id': nsd_id, 'rep': rep,\n",
    "                'session': session, 'trial_in_session': trial_in_session,\n",
    "            })\n",
    "    return pd.DataFrame(records)\n",
    "\n",
    "\n",
    "print('Utilities loaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj01 V4: 687 voxels\n",
      "Trials for 515 shared images: 1545 (expected 1545)\n",
      "  Session 10/40 (41s)\n",
      "  Session 20/40 (80s)\n",
      "  Session 30/40 (119s)\n",
      "\n",
      "Done in 119s\n",
      "Bypass output: (515, 687)\n"
     ]
    }
   ],
   "source": [
    "# Reproduce V4 betas for subj01 from raw HDF5\n",
    "SUBJ = 1\n",
    "target_nsd_ids = set(all_nsd_ids)\n",
    "\n",
    "v4_mask = get_v4_mask(SUBJ)\n",
    "n_v4_voxels = v4_mask.sum()\n",
    "print(f'subj{SUBJ:02d} V4: {n_v4_voxels} voxels')\n",
    "\n",
    "trial_info = get_trial_info(SUBJ - 1, target_nsd_ids)\n",
    "print(f'Trials for {N_IMAGES} shared images: {len(trial_info)} (expected {N_IMAGES * 3})')\n",
    "\n",
    "per_rep = np.zeros((N_IMAGES, 3, n_v4_voxels), dtype=np.float32)\n",
    "\n",
    "t0 = time.time()\n",
    "for session in range(1, SESSIONS_PER_SUBJECT[SUBJ] + 1):\n",
    "    session_trials = trial_info[trial_info['session'] == session]\n",
    "    if len(session_trials) == 0:\n",
    "        continue\n",
    "\n",
    "    session_betas = load_session_betas(SUBJ, session)\n",
    "    roi_betas = session_betas[:, v4_mask]\n",
    "\n",
    "    mean = roi_betas.mean(axis=0, keepdims=True)\n",
    "    std = roi_betas.std(axis=0, keepdims=True)\n",
    "    std[std == 0] = 1.0\n",
    "    roi_betas = (roi_betas - mean) / std\n",
    "\n",
    "    for _, row in session_trials.iterrows():\n",
    "        img_idx = nsd_id_to_idx[row['nsd_id']]\n",
    "        per_rep[img_idx, row['rep']] = roi_betas[row['trial_in_session']]\n",
    "\n",
    "    del session_betas\n",
    "    if session % 10 == 0:\n",
    "        print(f'  Session {session}/{SESSIONS_PER_SUBJECT[SUBJ]} ({time.time()-t0:.0f}s)')\n",
    "\n",
    "bypass_averaged = per_rep.mean(axis=1)\n",
    "\n",
    "gz_mean = bypass_averaged.mean(axis=0)\n",
    "gz_std = bypass_averaged.std(axis=0)\n",
    "gz_std[gz_std == 0] = 1.0\n",
    "bypass_final = (bypass_averaged - gz_mean) / gz_std\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "print(f'\\nDone in {elapsed:.0f}s')\n",
    "print(f'Bypass output: {bypass_final.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== End-to-End Bypass: Raw HDF5 -> Brain-Score Assembly (subj01, V4) ===\n",
      "Train: max_diff=1.91e-06 [PASS]\n",
      "Test:  max_diff=1.91e-06 [PASS]\n",
      "\n",
      "Bypass shape:   (412, 687) train, (103, 687) test\n",
      "Assembly shape: (412, 687) train, (103, 687) test\n",
      "\n",
      "Full preprocessing chain validated for subj01 V4.\n"
     ]
    }
   ],
   "source": [
    "# Compare bypass result with Brain-Score assembly for subj01 V4\n",
    "subj01_v4_mask = (bs_train.coords['subject'].values == 'subj01') & \\\n",
    "                 (bs_train.coords['region'].values == 'V4')\n",
    "bs_train_subj01_v4 = bs_train.values[:, subj01_v4_mask, 0]\n",
    "\n",
    "subj01_v4_mask_test = (bs_test.coords['subject'].values == 'subj01') & \\\n",
    "                      (bs_test.coords['region'].values == 'V4')\n",
    "bs_test_subj01_v4 = bs_test.values[:, subj01_v4_mask_test, 0]\n",
    "bs_test_subj01_v4_avg = bs_test_subj01_v4.reshape(len(test_ids), 3, -1).mean(axis=1)\n",
    "\n",
    "bypass_train = bypass_final[train_mask]\n",
    "bypass_test = bypass_final[test_mask]\n",
    "\n",
    "train_max_diff = np.max(np.abs(bypass_train - bs_train_subj01_v4))\n",
    "test_max_diff = np.max(np.abs(bypass_test - bs_test_subj01_v4_avg))\n",
    "\n",
    "print('=== End-to-End Bypass: Raw HDF5 -> Brain-Score Assembly (subj01, V4) ===')\n",
    "print(f'Train: max_diff={train_max_diff:.2e} [{\"PASS\" if train_max_diff < 1e-5 else \"FAIL\"}]')\n",
    "print(f'Test:  max_diff={test_max_diff:.2e} [{\"PASS\" if test_max_diff < 1e-5 else \"FAIL\"}]')\n",
    "assert train_max_diff < 1e-5, f'TRAIN MISMATCH: {train_max_diff}'\n",
    "assert test_max_diff < 1e-5, f'TEST MISMATCH: {test_max_diff}'\n",
    "\n",
    "print(f'\\nBypass shape:   {bypass_train.shape} train, {bypass_test.shape} test')\n",
    "print(f'Assembly shape: {bs_train_subj01_v4.shape} train, {bs_test_subj01_v4_avg.shape} test')\n",
    "print(f'\\nFull preprocessing chain validated for subj01 V4.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subj01: 11,074 neuroids, indices [0..11073], contiguous=PASS\n",
      "subj02: 10,845 neuroids, indices [11074..21918], contiguous=PASS\n",
      "subj03: 10,988 neuroids, indices [21919..32906], contiguous=PASS\n",
      "subj04: 9,860 neuroids, indices [32907..42766], contiguous=PASS\n",
      "subj05: 9,355 neuroids, indices [42767..52121], contiguous=PASS\n",
      "subj06: 12,450 neuroids, indices [52122..64571], contiguous=PASS\n",
      "subj07: 9,040 neuroids, indices [64572..73611], contiguous=PASS\n",
      "subj08: 10,952 neuroids, indices [73612..84563], contiguous=PASS\n",
      "\n",
      "Layout: subject-major (all regions per subject, then next subject)\n",
      "Subject contiguity:         PASS\n",
      "Region order within subject: PASS\n",
      "Subject order within region: PASS\n"
     ]
    }
   ],
   "source": [
    "# Verify neuroid ordering: assembly is subject-major\n",
    "# Layout: [subj01_V1, subj01_V2, subj01_V4, subj01_IT, subj02_V1, ...]\n",
    "assembly_subjects = bs_train.coords['subject'].values\n",
    "assembly_regions = bs_train.coords['region'].values\n",
    "\n",
    "# Check 1: subjects are contiguous (all neuroids for a subject appear together)\n",
    "subj_contiguous = True\n",
    "for subj in SUBJECT_LIST:\n",
    "    subj_label = f'subj{subj:02d}'\n",
    "    indices = np.where(assembly_subjects == subj_label)[0]\n",
    "    expected = np.arange(indices[0], indices[0] + len(indices))\n",
    "    ok = np.array_equal(indices, expected)\n",
    "    if not ok:\n",
    "        subj_contiguous = False\n",
    "    print(f'{subj_label}: {len(indices):,} neuroids, '\n",
    "          f'indices [{indices[0]}..{indices[-1]}], '\n",
    "          f'contiguous={\"PASS\" if ok else \"FAIL\"}')\n",
    "\n",
    "# Check 2: within each subject, regions appear in order (V1, V2, V4, IT)\n",
    "region_order_ok = True\n",
    "for subj in SUBJECT_LIST:\n",
    "    subj_label = f'subj{subj:02d}'\n",
    "    subj_mask = assembly_subjects == subj_label\n",
    "    subj_regions = assembly_regions[subj_mask]\n",
    "    # Extract unique region sequence (drop consecutive duplicates)\n",
    "    unique_seq = []\n",
    "    for r in subj_regions:\n",
    "        if len(unique_seq) == 0 or r != unique_seq[-1]:\n",
    "            unique_seq.append(r)\n",
    "    if unique_seq != REGIONS:\n",
    "        region_order_ok = False\n",
    "        print(f'{subj_label}: region order FAIL: {unique_seq}')\n",
    "\n",
    "# Check 3: within each region, subjects appear in order\n",
    "subj_order_ok = True\n",
    "for region in REGIONS:\n",
    "    region_mask = assembly_regions == region\n",
    "    region_subjects = assembly_subjects[region_mask]\n",
    "    unique_subjs = []\n",
    "    for s in region_subjects:\n",
    "        if len(unique_subjs) == 0 or s != unique_subjs[-1]:\n",
    "            unique_subjs.append(s)\n",
    "    expected_order = [f'subj{s:02d}' for s in SUBJECT_LIST]\n",
    "    if unique_subjs != expected_order:\n",
    "        subj_order_ok = False\n",
    "\n",
    "print(f'\\nLayout: subject-major (all regions per subject, then next subject)')\n",
    "print(f'Subject contiguity:         {\"PASS\" if subj_contiguous else \"FAIL\"}')\n",
    "print(f'Region order within subject: {\"PASS\" if region_order_ok else \"FAIL\"}')\n",
    "print(f'Subject order within region: {\"PASS\" if subj_order_ok else \"FAIL\"}')\n",
    "\n",
    "assert subj_contiguous, 'Subjects are not contiguous'\n",
    "assert region_order_ok, 'Regions not in expected order within subject'\n",
    "assert subj_order_ok, 'Subjects not in expected order within region'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Standalone Ridge Regression\n",
    "\n",
    "Run sklearn RidgeCV on Brain-Score assembly data for V4 and compare per-subject\n",
    "correlations with the benchmark output from NB04.\n",
    "\n",
    "This validates the benchmark metric code: if our standalone ridge gives similar\n",
    "raw correlations as the benchmark, the `ridge_split` metric is working correctly\n",
    "on our assemblies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kartik/Brain-Score 2026/core/brainscore_core/metrics/__init__.py:16: FutureWarning: xarray subclass Score should explicitly define __slots__\n",
      "  class Score(DataAssembly):\n",
      "/opt/anaconda3/envs/nsd-2026/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/nsd-2026/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "/opt/anaconda3/envs/nsd-2026/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:250: LinAlgWarning: An ill-conditioned matrix detected: slice 0 has rcond = 9.928403699177579e-08.\n",
      "  dual_coef = linalg.solve(K, y, assume_a=\"pos\", overwrite_a=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Score (subject: 1)>\n",
      "array([0.37448007])\n",
      "Coordinates:\n",
      "  * subject  (subject) <U6 'subj01'\n",
      "Attributes:\n",
      "    raw:      <xarray.Score (subject: 1)>\\narray([0.39834738], dtype=float32)...\n",
      "    ceiling:  <xarray.Score ()>\\narray(0.42373585)\\nAttributes:\\n    raw:    ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nsd-2026/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:250: LinAlgWarning: An ill-conditioned matrix detected: slice 0 has rcond = 9.928403699177579e-08.\n",
      "  dual_coef = linalg.solve(K, y, assume_a=\"pos\", overwrite_a=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Score (subject: 1)>\n",
      "array([0.47905756])\n",
      "Coordinates:\n",
      "  * subject  (subject) <U6 'subj02'\n",
      "Attributes:\n",
      "    raw:      <xarray.Score (subject: 1)>\\narray([0.50740105], dtype=float32)...\n",
      "    ceiling:  <xarray.Score ()>\\narray(0.53742148)\\nAttributes:\\n    raw:    ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nsd-2026/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:250: LinAlgWarning: An ill-conditioned matrix detected: slice 0 has rcond = 9.928403699177579e-08.\n",
      "  dual_coef = linalg.solve(K, y, assume_a=\"pos\", overwrite_a=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Score (subject: 1)>\n",
      "array([0.33453603])\n",
      "Coordinates:\n",
      "  * subject  (subject) <U6 'subj03'\n",
      "Attributes:\n",
      "    raw:      <xarray.Score (subject: 1)>\\narray([0.33000082], dtype=float32)...\n",
      "    ceiling:  <xarray.Score ()>\\narray(0.32552709)\\nAttributes:\\n    raw:    ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nsd-2026/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:250: LinAlgWarning: An ill-conditioned matrix detected: slice 0 has rcond = 9.928403699177579e-08.\n",
      "  dual_coef = linalg.solve(K, y, assume_a=\"pos\", overwrite_a=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Score (subject: 1)>\n",
      "array([0.23745752])\n",
      "Coordinates:\n",
      "  * subject  (subject) <U6 'subj04'\n",
      "Attributes:\n",
      "    raw:      <xarray.Score (subject: 1)>\\narray([0.2938487], dtype=float32)\\...\n",
      "    ceiling:  <xarray.Score ()>\\narray(0.36363159)\\nAttributes:\\n    raw:    ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nsd-2026/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:250: LinAlgWarning: An ill-conditioned matrix detected: slice 0 has rcond = 9.928403699177579e-08.\n",
      "  dual_coef = linalg.solve(K, y, assume_a=\"pos\", overwrite_a=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Score (subject: 1)>\n",
      "array([0.25326535])\n",
      "Coordinates:\n",
      "  * subject  (subject) <U6 'subj05'\n",
      "Attributes:\n",
      "    raw:      <xarray.Score (subject: 1)>\\narray([0.33371824], dtype=float32)...\n",
      "    ceiling:  <xarray.Score ()>\\narray(0.439728)\\nAttributes:\\n    raw:      ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nsd-2026/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:250: LinAlgWarning: An ill-conditioned matrix detected: slice 0 has rcond = 9.928403699177579e-08.\n",
      "  dual_coef = linalg.solve(K, y, assume_a=\"pos\", overwrite_a=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Score (subject: 1)>\n",
      "array([0.21597222])\n",
      "Coordinates:\n",
      "  * subject  (subject) <U6 'subj06'\n",
      "Attributes:\n",
      "    raw:      <xarray.Score (subject: 1)>\\narray([0.2773865], dtype=float32)\\...\n",
      "    ceiling:  <xarray.Score ()>\\narray(0.35626462)\\nAttributes:\\n    raw:    ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nsd-2026/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:250: LinAlgWarning: An ill-conditioned matrix detected: slice 0 has rcond = 9.928403699177579e-08.\n",
      "  dual_coef = linalg.solve(K, y, assume_a=\"pos\", overwrite_a=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Score (subject: 1)>\n",
      "array([0.49076643])\n",
      "Coordinates:\n",
      "  * subject  (subject) <U6 'subj07'\n",
      "Attributes:\n",
      "    raw:      <xarray.Score (subject: 1)>\\narray([0.47953454], dtype=float32)...\n",
      "    ceiling:  <xarray.Score ()>\\narray(0.4685597)\\nAttributes:\\n    raw:     ...\n",
      "<xarray.Score (subject: 1)>\n",
      "array([0.39992187])\n",
      "Coordinates:\n",
      "  * subject  (subject) <U6 'subj08'\n",
      "Attributes:\n",
      "    raw:      <xarray.Score (subject: 1)>\\narray([0.40743586], dtype=float32)...\n",
      "    ceiling:  <xarray.Score ()>\\narray(0.41509104)\\nAttributes:\\n    raw:    ...\n",
      "Benchmark score (ceiling-normalized): 0.3482\n",
      "Benchmark raw:                        0.3785\n",
      "Benchmark ceiling:                    0.4233\n",
      "Time: 3.4s\n",
      "\n",
      "Per-subject raw scores from benchmark:\n",
      "  subj01: 0.3983\n",
      "  subj02: 0.5074\n",
      "  subj03: 0.3300\n",
      "  subj04: 0.2938\n",
      "  subj05: 0.3337\n",
      "  subj06: 0.2774\n",
      "  subj07: 0.4795\n",
      "  subj08: 0.4074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nsd-2026/lib/python3.11/site-packages/sklearn/linear_model/_ridge.py:250: LinAlgWarning: An ill-conditioned matrix detected: slice 0 has rcond = 9.928403699177579e-08.\n",
      "  dual_coef = linalg.solve(K, y, assume_a=\"pos\", overwrite_a=False)\n",
      "/opt/anaconda3/envs/nsd-2026/lib/python3.11/site-packages/xarray/core/concat.py:500: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  common_dims = tuple(pd.unique([d for v in vars for d in v.dims]))\n",
      "/opt/anaconda3/envs/nsd-2026/lib/python3.11/site-packages/xarray/core/concat.py:500: FutureWarning: unique with argument that is not not a Series, Index, ExtensionArray, or np.ndarray is deprecated and will raise in a future version.\n",
      "  common_dims = tuple(pd.unique([d for v in vars for d in v.dims]))\n",
      "/var/folders/h6/g53mxg516n538136hh74630r0000gn/T/ipykernel_51099/3542678064.py:19: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  raw_val = float(benchmark_score.attrs[subj_label].raw.values)\n"
     ]
    }
   ],
   "source": [
    "from brainscore_vision import load_model, load_benchmark\n",
    "\n",
    "model = load_model('alexnet')\n",
    "benchmark = load_benchmark('Allen2022_fmri.V4-ridge')\n",
    "\n",
    "t0 = time.time()\n",
    "benchmark_score = benchmark(model)\n",
    "elapsed = time.time() - t0\n",
    "\n",
    "print(f'Benchmark score (ceiling-normalized): {float(benchmark_score.values):.4f}')\n",
    "print(f'Benchmark raw:                        {float(benchmark_score.raw.values):.4f}')\n",
    "print(f'Benchmark ceiling:                    {float(benchmark_score.ceiling.values):.4f}')\n",
    "print(f'Time: {elapsed:.1f}s')\n",
    "\n",
    "print(f'\\nPer-subject raw scores from benchmark:')\n",
    "benchmark_per_subj = {}\n",
    "for subj_label in [f'subj{s:02d}' for s in SUBJECT_LIST]:\n",
    "    if subj_label in benchmark_score.attrs:\n",
    "        raw_val = float(benchmark_score.attrs[subj_label].raw.values)\n",
    "        benchmark_per_subj[subj_label] = raw_val\n",
    "        print(f'  {subj_label}: {raw_val:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model activations: (412, 64896) train, (103, 64896) test\n",
      "Neural data:       (412, 1660) train, (103, 1660) test\n",
      "subj01: median r = 0.4239, alpha = 100000, n_neuroids = 325\n",
      "subj02: median r = 0.5202, alpha = 75000, n_neuroids = 311\n",
      "subj03: median r = 0.3390, alpha = 150000, n_neuroids = 184\n",
      "subj04: median r = 0.3132, alpha = 200000, n_neuroids = 140\n",
      "subj05: median r = 0.3531, alpha = 150000, n_neuroids = 275\n",
      "subj06: median r = 0.2850, alpha = 200000, n_neuroids = 163\n",
      "subj07: median r = 0.4835, alpha = 150000, n_neuroids = 119\n",
      "subj08: median r = 0.4275, alpha = 150000, n_neuroids = 143\n",
      "\n",
      "Standalone mean raw r: 0.3932\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from scipy.stats import pearsonr\n",
    "from brainscore_vision.metrics.regression_correlation.metric import ALPHA_LIST\n",
    "\n",
    "# Get model activations and neural data from benchmark internals\n",
    "model_train_act = benchmark.train_activations.values\n",
    "model_test_act = benchmark.test_activations.values\n",
    "if model_train_act.ndim > 2:\n",
    "    model_train_act = model_train_act.squeeze()\n",
    "    model_test_act = model_test_act.squeeze()\n",
    "\n",
    "train_neural = benchmark.train_assembly\n",
    "test_neural = benchmark.test_assembly\n",
    "if 'time_bin' in train_neural.dims:\n",
    "    train_neural = train_neural.isel(time_bin=0)\n",
    "if 'time_bin' in test_neural.dims:\n",
    "    test_neural = test_neural.isel(time_bin=0)\n",
    "\n",
    "print(f'Model activations: {model_train_act.shape} train, {model_test_act.shape} test')\n",
    "print(f'Neural data:       {train_neural.shape} train, {test_neural.shape} test')\n",
    "\n",
    "# Standalone ridge regression per subject\n",
    "subjects = np.unique(train_neural['subject'].values)\n",
    "standalone_results = {}\n",
    "\n",
    "for subj_label in subjects:\n",
    "    subj_mask_train = train_neural['subject'].values == subj_label\n",
    "    subj_mask_test = test_neural['subject'].values == subj_label\n",
    "\n",
    "    y_train = train_neural.values[:, subj_mask_train]\n",
    "    y_test = test_neural.values[:, subj_mask_test]\n",
    "\n",
    "    ridge = RidgeCV(alphas=ALPHA_LIST, fit_intercept=True)\n",
    "    ridge.fit(model_train_act, y_train)\n",
    "    y_pred = ridge.predict(model_test_act)\n",
    "\n",
    "    n_neuroids = y_test.shape[1]\n",
    "    correlations = np.array([\n",
    "        pearsonr(y_pred[:, v], y_test[:, v])[0]\n",
    "        for v in range(n_neuroids)\n",
    "    ])\n",
    "\n",
    "    median_r = np.median(correlations)\n",
    "    standalone_results[subj_label] = {\n",
    "        'median_r': median_r,\n",
    "        'alpha': ridge.alpha_,\n",
    "        'n_neuroids': n_neuroids,\n",
    "    }\n",
    "    print(f'{subj_label}: median r = {median_r:.4f}, '\n",
    "          f'alpha = {ridge.alpha_:.0f}, '\n",
    "          f'n_neuroids = {n_neuroids}')\n",
    "\n",
    "standalone_mean_r = np.mean([v['median_r'] for v in standalone_results.values()])\n",
    "print(f'\\nStandalone mean raw r: {standalone_mean_r:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Standalone Ridge vs Benchmark Comparison (V4) ===\n",
      "Subject      Standalone    Benchmark         Diff\n",
      "--------------------------------------------------\n",
      "subj01           0.4239       0.3983       0.0255\n",
      "subj02           0.5202       0.5074       0.0128\n",
      "subj03           0.3390       0.3300       0.0090\n",
      "subj04           0.3132       0.2938       0.0194\n",
      "subj05           0.3531       0.3337       0.0194\n",
      "subj06           0.2850       0.2774       0.0076\n",
      "subj07           0.4835       0.4795       0.0040\n",
      "subj08           0.4275       0.4074       0.0201\n",
      "\n",
      "      Mean       0.3932       0.3785       0.0147\n",
      "\n",
      "Note: Small differences are expected because the benchmark uses\n",
      "a cross-validated ridge metric that may handle multi-output fitting\n",
      "differently from sklearn's single RidgeCV.\n"
     ]
    }
   ],
   "source": [
    "# Compare standalone vs benchmark results\n",
    "print('=== Standalone Ridge vs Benchmark Comparison (V4) ===')\n",
    "print(f'{\"Subject\":<10} {\"Standalone\":>12} {\"Benchmark\":>12} {\"Diff\":>12}')\n",
    "print('-' * 50)\n",
    "\n",
    "for subj_label in subjects:\n",
    "    standalone_r = standalone_results[subj_label]['median_r']\n",
    "    bm_r = benchmark_per_subj.get(subj_label, float('nan'))\n",
    "    diff = abs(standalone_r - bm_r) if not np.isnan(bm_r) else float('nan')\n",
    "    print(f'{subj_label:<10} {standalone_r:>12.4f} {bm_r:>12.4f} {diff:>12.4f}')\n",
    "\n",
    "benchmark_raw = float(benchmark_score.raw.values)\n",
    "print(f'\\n{\"Mean\":>10} {standalone_mean_r:>12.4f} {benchmark_raw:>12.4f} '\n",
    "      f'{abs(standalone_mean_r - benchmark_raw):>12.4f}')\n",
    "\n",
    "print(f'\\nNote: Small differences are expected because the benchmark uses')\n",
    "print(f'a cross-validated ridge metric that may handle multi-output fitting')\n",
    "print(f'differently from sklearn\\'s single RidgeCV.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| Validation | What it proves |\n",
    "|---|---|\n",
    "| Section 1: NB02 -> global z-score -> assembly | NB03 packaging step is correct |\n",
    "| Section 1: Voxel spot checks | Individual values trace correctly |\n",
    "| Section 2: Raw HDF5 -> assembly (subj01, V4) | Full preprocessing chain is correct |\n",
    "| Section 2: Neuroid ordering | Subject-major layout with correct region/subject order |\n",
    "| Section 3: Standalone ridge vs benchmark | Benchmark metric code works on our data |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Volumetric Assembly Validation Summary ===\n",
      "\n",
      "Section 1 (Voxel-Level Spot Check):\n",
      "  NB02->assembly train max_diff: 0.00e+00 [PASS]\n",
      "  NB02->assembly test max_diff:  9.54e-07 [PASS]\n",
      "  5/5 spot checks: PASS\n",
      "\n",
      "Section 2 (End-to-End Raw Data Bypass):\n",
      "  Raw HDF5->assembly train max_diff: 1.91e-06 [PASS]\n",
      "  Raw HDF5->assembly test max_diff:  1.91e-06 [PASS]\n",
      "  Subject contiguity:          PASS\n",
      "  Region order within subject: PASS\n",
      "  Subject order within region: PASS\n",
      "\n",
      "Section 3 (Standalone Ridge):\n",
      "  Standalone mean r: 0.3932\n",
      "  Benchmark mean r:  0.3785\n",
      "  Difference:        0.0147\n",
      "\n",
      "All validations passed: YES\n"
     ]
    }
   ],
   "source": [
    "print('=== Volumetric Assembly Validation Summary ===')\n",
    "print()\n",
    "print('Section 1 (Voxel-Level Spot Check):')\n",
    "print(f'  NB02->assembly train max_diff: {max_diff:.2e} [PASS]')\n",
    "print(f'  NB02->assembly test max_diff:  {max_diff_test:.2e} [PASS]')\n",
    "print(f'  5/5 spot checks: PASS')\n",
    "print()\n",
    "print('Section 2 (End-to-End Raw Data Bypass):')\n",
    "print(f'  Raw HDF5->assembly train max_diff: {train_max_diff:.2e} [PASS]')\n",
    "print(f'  Raw HDF5->assembly test max_diff:  {test_max_diff:.2e} [PASS]')\n",
    "print(f'  Subject contiguity:          {\"PASS\" if subj_contiguous else \"FAIL\"}')\n",
    "print(f'  Region order within subject: {\"PASS\" if region_order_ok else \"FAIL\"}')\n",
    "print(f'  Subject order within region: {\"PASS\" if subj_order_ok else \"FAIL\"}')\n",
    "print()\n",
    "print('Section 3 (Standalone Ridge):')\n",
    "print(f'  Standalone mean r: {standalone_mean_r:.4f}')\n",
    "print(f'  Benchmark mean r:  {benchmark_raw:.4f}')\n",
    "print(f'  Difference:        {abs(standalone_mean_r - benchmark_raw):.4f}')\n",
    "print()\n",
    "all_passed = (max_diff < 1e-5 and max_diff_test < 1e-5 and all_pass\n",
    "              and train_max_diff < 1e-5 and test_max_diff < 1e-5\n",
    "              and subj_contiguous and region_order_ok and subj_order_ok)\n",
    "print(f'All validations passed: {\"YES\" if all_passed else \"NO\"}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nsd-2026",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}