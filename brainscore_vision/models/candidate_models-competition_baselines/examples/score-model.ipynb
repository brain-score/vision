{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch\n",
    "First, define your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=2, kernel_size=3)\n",
    "        self.relu1 = torch.nn.ReLU()\n",
    "        linear_input_size = np.power((224 - 3 + 2 * 0) / 1 + 1, 2) * 2\n",
    "        self.linear = torch.nn.Linear(int(linear_input_size), 1000)\n",
    "        self.relu2 = torch.nn.ReLU()  # can't get named ReLU output otherwise\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear(x)\n",
    "        x = self.relu2(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can define your own preprocessing to convert filepaths into (normalized) model inputs.\n",
    "We'll use a standardly defined function which normalizes to the ImageNet mean with an image size of 224 x 224."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import functools\n",
    "from model_tools.activations.pytorch import load_preprocess_images\n",
    "\n",
    "preprocessing = functools.partial(load_preprocess_images, image_size=224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, using the PytorchWrapper, convert your model into an activations model.\n",
    "Activations models let us extract activations from any layer in the model in response to inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from model_tools.activations.pytorch import PytorchWrapper\n",
    "\n",
    "activations_model = PytorchWrapper(identifier='my-model', model=MyModel(), preprocessing=preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model candidates in Brain-Score have to follow the [model_interface](https://github.com/brain-score/brain-score/blob/master/brainscore/model_interface.py).\n",
    "This for instance involves deciding what layers map onto cortical regions.\n",
    "If you want to use the standard commitments, use the `ModelCommitment`.\n",
    "To map layers onto regions, `ModelCommitment` determines the best layer empirically by scoring all layers on public benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading lookup from /braintree/home/msch/brainio_collection/brainio_collection/lookup.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cross-validation: 100%|██████████| 10/10 [25:19<00:00, 151.96s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Score (aggregation: 2)>\n",
      "array([0.07126698, 0.00550245])\n",
      "Coordinates:\n",
      "  * aggregation  (aggregation) <U6 'center' 'error'\n",
      "Attributes:\n",
      "    raw:                   <xarray.Score (aggregation: 2)>\\narray([0.21778479...\n",
      "    ceiling:               <xarray.Score (aggregation: 2)>\\narray([0.81579938...\n",
      "    model_identifier:      my-model\n",
      "    benchmark_identifier:  dicarlo.MajajHong2015public.IT-pls\n"
     ]
    }
   ],
   "source": [
    "from brainscore import score_model\n",
    "from model_tools.brain_transformation import ModelCommitment\n",
    "\n",
    "model = ModelCommitment(identifier='my-model', activations_model=activations_model,\n",
    "                        # specify layers to consider\n",
    "                        layers=['conv1', 'relu1', 'relu2'])\n",
    "# The score_model will score the model on the specified benchmark.\n",
    "# When the model is asked to output activations for the IT region, it will first search for the best layer\n",
    "# and then only output this layer's activations.\n",
    "score = score_model(model_identifier=model.identifier, model=model,\n",
    "                    benchmark_identifier='dicarlo.MajajHong2015public.IT-pls')\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow (-Slim)\n",
    "First, define your model (its endpoints) and its preprocessing function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3cb0ea5350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3cb0ea5350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3cb0ea5350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7f3cb0ea5350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3cb0a1f950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3cb0a1f950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3cb0a1f950>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3cb0a1f950>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3cb0ea5350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3cb0ea5350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3cb0ea5350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Pooling2D.call of <tensorflow.python.layers.pooling.MaxPooling2D object at 0x7f3cb0ea5350>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From /braintree/home/msch/miniconda3/envs/candidate-models/lib/python3.7/site-packages/tensorflow/contrib/layers/python/layers/layers.py:1634: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n",
      "WARNING:tensorflow:Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f3cb0ea5350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f3cb0ea5350>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f3cb0ea5350>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Flatten.call of <tensorflow.python.layers.core.Flatten object at 0x7f3cb0ea5350>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3cfb1f7b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3cfb1f7b90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3cfb1f7b90>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f3cfb1f7b90>>: AttributeError: module 'gast' has no attribute 'Index'\n",
      "WARNING:tensorflow:From /braintree/home/msch/miniconda3/envs/candidate-models/lib/python3.7/site-packages/tensorflow/python/util/tf_should_use.py:193: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "from model_tools.activations.tensorflow import load_resize_image\n",
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "tf.reset_default_graph()\n",
    "\n",
    "image_size = 224\n",
    "placeholder = tf.placeholder(dtype=tf.string, shape=[64])\n",
    "preprocess = lambda image_path: load_resize_image(image_path, image_size)\n",
    "preprocess = tf.map_fn(preprocess, placeholder, dtype=tf.float32)\n",
    "\n",
    "with tf.variable_scope('my_model', values=[preprocess]) as sc:\n",
    "    end_points_collection = sc.original_name_scope + '_end_points'\n",
    "    # Collect outputs for conv2d, fully_connected and max_pool2d.\n",
    "    with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d],\n",
    "                        outputs_collections=[end_points_collection]):\n",
    "        net = slim.conv2d(preprocess, 64, [11, 11], 4, padding='VALID', scope='conv1')\n",
    "        net = slim.max_pool2d(net, [5, 5], 5, scope='pool1')\n",
    "        net = slim.max_pool2d(net, [3, 3], 2, scope='pool2')\n",
    "        net = slim.flatten(net, scope='flatten')\n",
    "        net = slim.fully_connected(net, 1000, scope='logits')\n",
    "        endpoints = slim.utils.convert_collection_to_dict(end_points_collection)\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.initialize_all_variables())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, using the TensorflowSlimWrapper, convert your model into an activations model.\n",
    "Activations models let us extract activations from any layer in the model in response to inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from model_tools.activations.tensorflow import TensorflowSlimWrapper\n",
    "\n",
    "activations_model_tf = TensorflowSlimWrapper(identifier='tf-custom', labels_offset=0,\n",
    "                                             endpoints=endpoints, inputs=placeholder, session=session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model candidates in Brain-Score have to follow the [model_interface](https://github.com/brain-score/brain-score/blob/master/brainscore/model_interface.py).\n",
    "This for instance involves deciding what layers map onto cortical regions.\n",
    "If you want to use the standard commitments, use the `ModelCommitment`.\n",
    "To map layers onto regions, `ModelCommitment` determines the best layer empirically by scoring all layers on public benchmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "layers:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8fc95f300c41079172d8285812d68a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='activations', max=3200.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e2ddd0379a4c1d91ead5faeef4d1ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='activations', max=1024.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89c0441a73ad44e893fa4ccce7a84e89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='layer packaging', max=3.0, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "layer principal components:   0%|          | 0/3 [00:00<?, ?it/s]\u001B[A\u001B[A\n",
      "\n",
      "layer principal components:  33%|███▎      | 1/3 [00:00<00:00,  2.56it/s]\u001B[A\u001B[A\n",
      "\n",
      "layer principal components:  67%|██████▋   | 2/3 [00:01<00:00,  1.63it/s]\u001B[A\u001B[A\n",
      "\n",
      "layer principal components: 100%|██████████| 3/3 [00:15<00:00,  5.32s/it]\u001B[A\u001B[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb9d025fd3dd498989d5d6cb26dfc14c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='layer packaging', max=3.0, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "cross-validation:   0%|          | 0/10 [00:00<?, ?it/s]\u001B[A\n",
      "cross-validation:  10%|█         | 1/10 [00:03<00:28,  3.19s/it]\u001B[A\n",
      "cross-validation:  20%|██        | 2/10 [00:06<00:25,  3.13s/it]\u001B[A\n",
      "cross-validation:  30%|███       | 3/10 [00:08<00:20,  2.89s/it]\u001B[A\n",
      "cross-validation:  40%|████      | 4/10 [00:10<00:16,  2.70s/it]\u001B[A\n",
      "cross-validation:  50%|█████     | 5/10 [00:12<00:12,  2.53s/it]\u001B[A\n",
      "cross-validation:  60%|██████    | 6/10 [00:15<00:09,  2.49s/it]\u001B[A\n",
      "cross-validation:  70%|███████   | 7/10 [00:18<00:07,  2.65s/it]\u001B[A\n",
      "cross-validation:  80%|████████  | 8/10 [00:21<00:05,  2.66s/it]\u001B[A\n",
      "cross-validation:  90%|█████████ | 9/10 [00:23<00:02,  2.68s/it]\u001B[A\n",
      "cross-validation: 100%|██████████| 10/10 [00:25<00:00,  2.60s/it]\u001B[A\n",
      "layers:  33%|███▎      | 1/3 [01:16<02:32, 76.31s/it]\n",
      "cross-validation:   0%|          | 0/10 [00:00<?, ?it/s]\u001B[A\n",
      "cross-validation:  10%|█         | 1/10 [00:02<00:22,  2.52s/it]\u001B[A\n",
      "cross-validation:  20%|██        | 2/10 [00:04<00:19,  2.41s/it]\u001B[A\n",
      "cross-validation:  30%|███       | 3/10 [00:06<00:16,  2.37s/it]\u001B[A\n",
      "cross-validation:  40%|████      | 4/10 [00:09<00:14,  2.36s/it]\u001B[A\n",
      "cross-validation:  50%|█████     | 5/10 [00:11<00:12,  2.44s/it]\u001B[A\n",
      "cross-validation:  60%|██████    | 6/10 [00:15<00:10,  2.66s/it]\u001B[A\n",
      "cross-validation:  70%|███████   | 7/10 [00:18<00:09,  3.00s/it]\u001B[A\n",
      "cross-validation:  80%|████████  | 8/10 [00:21<00:05,  2.86s/it]\u001B[A\n",
      "cross-validation:  90%|█████████ | 9/10 [00:23<00:02,  2.73s/it]\u001B[A\n",
      "cross-validation: 100%|██████████| 10/10 [00:26<00:00,  2.62s/it]\u001B[A\n",
      "layers:  67%|██████▋   | 2/3 [01:42<01:01, 61.40s/it]\n",
      "cross-validation:   0%|          | 0/10 [00:00<?, ?it/s]\u001B[A\n",
      "cross-validation:  10%|█         | 1/10 [00:02<00:20,  2.28s/it]\u001B[A\n",
      "cross-validation:  20%|██        | 2/10 [00:04<00:18,  2.35s/it]\u001B[A\n",
      "cross-validation:  30%|███       | 3/10 [00:10<00:22,  3.23s/it]\u001B[A\n",
      "cross-validation:  40%|████      | 4/10 [00:13<00:19,  3.25s/it]\u001B[A\n",
      "cross-validation:  50%|█████     | 5/10 [00:15<00:15,  3.01s/it]\u001B[A\n",
      "cross-validation:  60%|██████    | 6/10 [00:18<00:11,  2.80s/it]\u001B[A\n",
      "cross-validation:  70%|███████   | 7/10 [00:20<00:07,  2.59s/it]\u001B[A\n",
      "cross-validation:  80%|████████  | 8/10 [00:22<00:05,  2.54s/it]\u001B[A\n",
      "cross-validation:  90%|█████████ | 9/10 [00:26<00:03,  3.06s/it]\u001B[A\n",
      "cross-validation: 100%|██████████| 10/10 [00:31<00:00,  3.12s/it]\u001B[A\n",
      "layers: 100%|██████████| 3/3 [02:14<00:00, 44.82s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "232fe1b82da14f79b1d0920099dd3205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='activations', max=3200.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4815c2c733b04f0ebca2ba0bb504de4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='layer packaging', max=1.0, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cross-validation: 100%|██████████| 10/10 [00:24<00:00,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Score (aggregation: 2)>\n",
      "array([0.28334572, 0.00415787])\n",
      "Coordinates:\n",
      "  * aggregation  (aggregation) <U6 'center' 'error'\n",
      "Attributes:\n",
      "    raw:                   <xarray.Score (aggregation: 2)>\\narray([0.43425187...\n",
      "    ceiling:               <xarray.Score (aggregation: 2)>\\narray([0.81579938...\n",
      "    model_identifier:      tf-custom\n",
      "    benchmark_identifier:  dicarlo.MajajHong2015public.IT-pls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from brainscore import score_model\n",
    "from model_tools.brain_transformation import ModelCommitment\n",
    "\n",
    "model = ModelCommitment(identifier='tf-custom', activations_model=activations_model_tf,\n",
    "                        # specify layers to consider\n",
    "                        layers=['my_model/conv1', 'my_model/pool1', 'my_model/pool2'])\n",
    "\n",
    "score = score_model(model_identifier=model.identifier, model=model,\n",
    "                    benchmark_identifier='dicarlo.MajajHong2015public.IT-pls')\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of these steps are sample implementations and as long as your model implements the model_interface,\n",
    "it does not matter how you get there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-defined models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scoring a model on neural data can be done in a single line using the `score_model` method and the `brain_translated_pool`.\n",
    "Pre-defined layers of a model will be used to retrieve the activations.\n",
    "Just like with the model implementations, the result of this method call will be cached \n",
    "so that it only needs to be computed once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "alexnet is accessed again and reloaded\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07557b67956743a9960d08c96d479228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='activations', max=3200.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50714180296f455eae4558cabf89ab50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='layer packaging', max=1.0, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cross-validation: 100%|██████████| 10/10 [03:13<00:00, 19.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Score (aggregation: 2)>\n",
      "array([0.50478986, 0.00269386])\n",
      "Coordinates:\n",
      "  * aggregation  (aggregation) <U6 'center' 'error'\n",
      "Attributes:\n",
      "    raw:                   <xarray.Score (aggregation: 2)>\\narray([0.57961375...\n",
      "    ceiling:               <xarray.Score (aggregation: 2)>\\narray([0.81579938...\n",
      "    model_identifier:      alexnet\n",
      "    benchmark_identifier:  dicarlo.MajajHong2015public.IT-pls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from brainscore import score_model\n",
    "from candidate_models.model_commitments import brain_translated_pool\n",
    "\n",
    "identifier = 'alexnet'\n",
    "model = brain_translated_pool[identifier]\n",
    "score = score_model(model_identifier=identifier, model=model, benchmark_identifier='dicarlo.MajajHong2015public.IT-pls')\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A score typically comes with an estimate of the center (e.g. mean) and error (e.g. standard error of the mean).\n",
    "These values are aggregations over splits and often neuroids, and ceiled by the benchmark ceiling.\n",
    "\n",
    "Check out https://github.com/brain-score/brain-score/blob/master/examples/benchmarks.ipynb for more details.\n",
    "\n",
    "Also note that all these scores were computed on the publicly available data.\n",
    "To test models on the full set of benchmarks (including held-out private data), \n",
    "please submit them on www.Brain-Score.org."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}