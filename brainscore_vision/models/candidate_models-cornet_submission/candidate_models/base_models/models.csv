model,link,bibtex,top1,top5
alexnet,https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks,"@incollection{NIPS2012_4824,
title = {ImageNet Classification with Deep Convolutional Neural Networks},
author = {Alex Krizhevsky and Sutskever, Ilya and Hinton, Geoffrey E},
booktitle = {Advances in Neural Information Processing Systems 25},
editor = {F. Pereira and C. J. C. Burges and L. Bottou and K. Q. Weinberger},
pages = {1097--1105},
year = {2012},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf}
}
",0.577,
CORnet-S,https://papers.nips.cc/paper/9441-brain-like-object-recognition-with-high-performing-shallow-recurrent-anns,"@incollection{Kubilius2018CORnet,
title = {CORnet: Modeling the Neural and Behavioral Mechanisms of Core Object Recognition},
author = {Jonas Kubilius and Martin Schrimpf and Aran Nayebi and Daniel Bear and Daniel L. K. Yamins and James J. DiCarlo},
year = {2018},
month={sep},
url = {https://papers.nips.cc/paper/9441-brain-like-object-recognition-with-high-performing-shallow-recurrent-anns}
}
",0.747,
CORnet-R,https://www.biorxiv.org/content/early/2018/09/04/408385,"@incollection{Kubilius2018CORnet,
title = {CORnet: Modeling the Neural and Behavioral Mechanisms of Core Object Recognition},
author = {Jonas Kubilius and Martin Schrimpf and Aran Nayebi and Daniel Bear and Daniel L. K. Yamins and James J. DiCarlo},
year = {2018},
month={sep},
url = {https://www.biorxiv.org/content/early/2018/09/04/408385}
}
",0.56,
CORnet-Z,https://www.biorxiv.org/content/early/2018/09/04/408385,"@incollection{Kubilius2018CORnet,
title = {CORnet: Modeling the Neural and Behavioral Mechanisms of Core Object Recognition},
author = {Jonas Kubilius and Martin Schrimpf and Aran Nayebi and Daniel Bear and Daniel L. K. Yamins and James J. DiCarlo},
year = {2018},
month={sep},
url = {https://www.biorxiv.org/content/early/2018/09/04/408385},
}
",0.47,
CORnet-R2,https://www.biorxiv.org/content/early/2018/09/04/408385,"@incollection{Kubilius2018CORnet,
title = {CORnet: Modeling the Neural and Behavioral Mechanisms of Core Object Recognition},
author = {Jonas Kubilius and Martin Schrimpf and Aran Nayebi and Daniel Bear and Daniel L. K. Yamins and James J. DiCarlo},
year = {2018},
month={sep},
}
",0.7,
squeezenet1_0,https://arxiv.org/abs/1602.07360,"@article{SqueezeNet,
    Author = {Forrest N. Iandola and Song Han and Matthew W. Moskewicz and Khalid Ashraf and William J. Dally and Kurt Keutzer},
    Title = {SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and $<$0.5MB model size},
    Journal = {arXiv:1602.07360},
    Year = {2016},
    Month = {feb},
    url = {https://arxiv.org/abs/1602.07360}
}",0.575,
squeezenet1_1,https://arxiv.org/abs/1602.07360,"@article{SqueezeNet,
    Author = {Forrest N. Iandola and Song Han and Matthew W. Moskewicz and Khalid Ashraf and William J. Dally and Kurt Keutzer},
    Title = {SqueezeNet: AlexNet-level accuracy with 50x fewer parameters and $<$0.5MB model size},
    Journal = {arXiv:1602.07360},
    Year = {2016},
    Month = {feb},
    url = {https://arxiv.org/abs/1602.07360}
}",0.575,
xception,https://arxiv.org/abs/1610.02357,"@article{DBLP:journals/corr/Chollet16a,
  author    = {Fran{\c{c}}ois Chollet},
  title     = {Xception: Deep Learning with Depthwise Separable Convolutions},
  journal   = {CoRR},
  volume    = {abs/1610.02357},
  year      = {2016},
  month = {oct},
  url       = {http://arxiv.org/abs/1610.02357},
  archivePrefix = {arXiv},
  eprint    = {1610.02357},
  timestamp = {Wed, 07 Jun 2017 14:41:03 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/Chollet16a},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.79,0.945
densenet-121,https://arxiv.org/abs/1608.06993,"@article{DBLP:journals/corr/HuangLW16a,
  author    = {Gao Huang and
               Zhuang Liu and
               Kilian Q. Weinberger},
  title     = {Densely Connected Convolutional Networks},
  journal   = {CoRR},
  volume    = {abs/1608.06993},
  year      = {2016},
  month  = {aug},
  url       = {http://arxiv.org/abs/1608.06993},
  archivePrefix = {arXiv},
  eprint    = {1608.06993},
  timestamp = {Wed, 07 Jun 2017 14:42:40 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HuangLW16a},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.745,0.918
densenet-169,https://arxiv.org/abs/1608.06993,"@article{DBLP:journals/corr/HuangLW16a,
  author    = {Gao Huang and
               Zhuang Liu and
               Kilian Q. Weinberger},
  title     = {Densely Connected Convolutional Networks},
  journal   = {CoRR},
  volume    = {abs/1608.06993},
  year      = {2016},
  month  = {aug},
  url       = {http://arxiv.org/abs/1608.06993},
  archivePrefix = {arXiv},
  eprint    = {1608.06993},
  timestamp = {Wed, 07 Jun 2017 14:42:40 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HuangLW16a},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.759,0.928
densenet-201,https://arxiv.org/abs/1608.06993,"@article{DBLP:journals/corr/HuangLW16a,
  author    = {Gao Huang and
               Zhuang Liu and
               Kilian Q. Weinberger},
  title     = {Densely Connected Convolutional Networks},
  journal   = {CoRR},
  volume    = {abs/1608.06993},
  year      = {2016},
  month  = {aug},
  url       = {http://arxiv.org/abs/1608.06993},
  archivePrefix = {arXiv},
  eprint    = {1608.06993},
  timestamp = {Wed, 07 Jun 2017 14:42:40 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HuangLW16a},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.772,0.933
inception_v1,https://arxiv.org/abs/1409.4842,"@article{DBLP:journals/corr/SzegedyLJSRAEVR14,
  author    = {Christian Szegedy and
               Wei Liu and
               Yangqing Jia and
               Pierre Sermanet and
               Scott E. Reed and
               Dragomir Anguelov and
               Dumitru Erhan and
               Vincent Vanhoucke and
               Andrew Rabinovich},
  title     = {Going Deeper with Convolutions},
  journal   = {CoRR},
  volume    = {abs/1409.4842},
  year      = {2014},
  month = {sep},
  url       = {http://arxiv.org/abs/1409.4842},
  archivePrefix = {arXiv},
  eprint    = {1409.4842},
  timestamp = {Wed, 07 Jun 2017 14:40:42 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/SzegedyLJSRAEVR14},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.698,0.896
inception_v2,https://arxiv.org/abs/1512.00567,"@article{DBLP:journals/corr/SzegedyVISW15,
  author    = {Christian Szegedy and
               Vincent Vanhoucke and
               Sergey Ioffe and
               Jonathon Shlens and
               Zbigniew Wojna},
  title     = {Rethinking the Inception Architecture for Computer Vision},
  journal   = {CoRR},
  volume    = {abs/1512.00567},
  year      = {2015},
  month  = {dec},
  url       = {http://arxiv.org/abs/1512.00567},
  archivePrefix = {arXiv},
  eprint    = {1512.00567},
  timestamp = {Wed, 07 Jun 2017 14:40:22 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/SzegedyVISW15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.739,0.918
inception_v3,https://arxiv.org/abs/1512.00567,"@article{DBLP:journals/corr/SzegedyVISW15,
  author    = {Christian Szegedy and
               Vincent Vanhoucke and
               Sergey Ioffe and
               Jonathon Shlens and
               Zbigniew Wojna},
  title     = {Rethinking the Inception Architecture for Computer Vision},
  journal   = {CoRR},
  volume    = {abs/1512.00567},
  year      = {2015},
  month  = {dec},
  url       = {http://arxiv.org/abs/1512.00567},
  archivePrefix = {arXiv},
  eprint    = {1512.00567},
  timestamp = {Wed, 07 Jun 2017 14:40:22 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/SzegedyVISW15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.78,0.939
inception_v4,https://arxiv.org/abs/1602.07261,"@article{DBLP:journals/corr/SzegedyIV16,
  author    = {Christian Szegedy and
               Sergey Ioffe and
               Vincent Vanhoucke},
  title     = {Inception-v4, Inception-ResNet and the Impact of Residual Connections
               on Learning},
  journal   = {CoRR},
  volume    = {abs/1602.07261},
  year      = {2016},
  month = {feb},
  url       = {http://arxiv.org/abs/1602.07261},
  archivePrefix = {arXiv},
  eprint    = {1602.07261},
  timestamp = {Wed, 07 Jun 2017 14:42:58 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/SzegedyIV16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.802,0.952
inception_resnet_v2,https://arxiv.org/abs/1602.07261,"@article{DBLP:journals/corr/SzegedyIV16,
  author    = {Christian Szegedy and
               Sergey Ioffe and
               Vincent Vanhoucke},
  title     = {Inception-v4, Inception-ResNet and the Impact of Residual Connections
               on Learning},
  journal   = {CoRR},
  volume    = {abs/1602.07261},
  year      = {2016},
  month = {feb},
  url       = {http://arxiv.org/abs/1602.07261},
  archivePrefix = {arXiv},
  eprint    = {1602.07261},
  timestamp = {Wed, 07 Jun 2017 14:42:58 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/SzegedyIV16},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.804,0.953
resnet-18,https://arxiv.org/abs/1512.03385,"@article{DBLP:journals/corr/HeZRS15,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1512.03385},
  year      = {2015},
  month = {dec},
  url       = {http://arxiv.org/abs/1512.03385},
  archivePrefix = {arXiv},
  eprint    = {1512.03385},
  timestamp = {Wed, 07 Jun 2017 14:41:17 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HeZRS15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.6976,0.8908
resnet-34,https://arxiv.org/abs/1512.03385,"@article{DBLP:journals/corr/HeZRS15,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1512.03385},
  year      = {2015},
  month = {dec},
  url       = {http://arxiv.org/abs/1512.03385},
  archivePrefix = {arXiv},
  eprint    = {1512.03385},
  timestamp = {Wed, 07 Jun 2017 14:41:17 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HeZRS15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.733,0.9142
resnet-50-pytorch,https://arxiv.org/abs/1512.03385,"@article{DBLP:journals/corr/HeZRS15,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1512.03385},
  year      = {2015},
  month = {dec},
  url       = {http://arxiv.org/abs/1512.03385},
  archivePrefix = {arXiv},
  eprint    = {1512.03385},
  timestamp = {Wed, 07 Jun 2017 14:41:17 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HeZRS15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.752,0.922
resnet-50_v1,https://arxiv.org/abs/1512.03385,"@article{DBLP:journals/corr/HeZRS15,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1512.03385},
  year      = {2015},
  month = {dec},
  url       = {http://arxiv.org/abs/1512.03385},
  archivePrefix = {arXiv},
  eprint    = {1512.03385},
  timestamp = {Wed, 07 Jun 2017 14:41:17 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HeZRS15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.752,0.922
resnet-101_v1,https://arxiv.org/abs/1512.03385,"@article{DBLP:journals/corr/HeZRS15,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1512.03385},
  year      = {2015},
  month = {dec},
  url       = {http://arxiv.org/abs/1512.03385},
  archivePrefix = {arXiv},
  eprint    = {1512.03385},
  timestamp = {Wed, 07 Jun 2017 14:41:17 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HeZRS15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.764,0.929
resnet-152_v1,https://arxiv.org/abs/1512.03385,"@article{DBLP:journals/corr/HeZRS15,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1512.03385},
  year      = {2015},
  month = {dec},
  url       = {http://arxiv.org/abs/1512.03385},
  archivePrefix = {arXiv},
  eprint    = {1512.03385},
  timestamp = {Wed, 07 Jun 2017 14:41:17 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HeZRS15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.768,0.932
resnet-50_v2,https://arxiv.org/abs/1512.03385,"@article{DBLP:journals/corr/HeZRS15,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1512.03385},
  year      = {2015},
  month = {dec},
  url       = {http://arxiv.org/abs/1512.03385},
  archivePrefix = {arXiv},
  eprint    = {1512.03385},
  timestamp = {Wed, 07 Jun 2017 14:41:17 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HeZRS15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.756,0.928
resnet-101_v2,https://arxiv.org/abs/1512.03385,"@article{DBLP:journals/corr/HeZRS15,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1512.03385},
  year      = {2015},
  month = {dec},
  url       = {http://arxiv.org/abs/1512.03385},
  archivePrefix = {arXiv},
  eprint    = {1512.03385},
  timestamp = {Wed, 07 Jun 2017 14:41:17 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HeZRS15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.7737,0.937
resnet-152_v2,https://arxiv.org/abs/1512.03385,"@article{DBLP:journals/corr/HeZRS15,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1512.03385},
  year      = {2015},
  month = {dec},
  url       = {http://arxiv.org/abs/1512.03385},
  archivePrefix = {arXiv},
  eprint    = {1512.03385},
  timestamp = {Wed, 07 Jun 2017 14:41:17 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HeZRS15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.778,0.941
resnet-50-robust,https://arxiv.org/pdf/1906.09453.pdf,"@inproceedings{santurkar2019computer,
    title={Computer Vision with a Single (Robust) Classifier},
    author={Shibani Santurkar and Dimitris Tsipras and Brandon Tran and Andrew Ilyas and Logan Engstrom and Aleksander Madry},
    booktitle={ArXiv preprint arXiv:1906.09453},
    year={2019}
}",,
vgg-16,https://arxiv.org/abs/1409.1556,"@article{DBLP:journals/corr/SimonyanZ14a,
  author    = {Karen Simonyan and
               Andrew Zisserman},
  title     = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1409.1556},
  year      = {2014},
  month = {sep},
  url       = {http://arxiv.org/abs/1409.1556},
  archivePrefix = {arXiv},
  eprint    = {1409.1556},
  timestamp = {Wed, 07 Jun 2017 14:41:51 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/SimonyanZ14a},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.715,0.898
vgg-19,https://arxiv.org/abs/1409.1556,"@article{DBLP:journals/corr/SimonyanZ14a,
  author    = {Karen Simonyan and
               Andrew Zisserman},
  title     = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1409.1556},
  year      = {2014},
  month = {sep},
  url       = {http://arxiv.org/abs/1409.1556},
  archivePrefix = {arXiv},
  eprint    = {1409.1556},
  timestamp = {Wed, 07 Jun 2017 14:41:51 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/SimonyanZ14a},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.711,0.898
vggface,https://www.robots.ox.ac.uk/~vgg/publications/2015/Parkhi15/parkhi15.pdf,"@inproceedings{parkhi2015deep,
  title={Deep face recognition.},
  author={Parkhi, Omkar M and Vedaldi, Andrea and Zisserman, Andrew and others},
  booktitle={British Machine Vision Conference},
  year={2015},
  month = {sep},
  url = {https://www.robots.ox.ac.uk/~vgg/publications/2015/Parkhi15/parkhi15.pdf}
}",,
bagnet9,https://openreview.net/forum?id=SkfMWhAqYQ,"@inproceedings{
brendel2018approximating,
title={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},
author={Wieland Brendel and Matthias Bethge},
booktitle={International Conference on Learning Representations},
year={2019},
month={mar},
url={https://openreview.net/forum?id=SkfMWhAqYQ},
}",0.26,
bagnet17,https://openreview.net/forum?id=SkfMWhAqYQ,"@inproceedings{
brendel2018approximating,
title={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},
author={Wieland Brendel and Matthias Bethge},
booktitle={International Conference on Learning Representations},
year={2019},
month={mar},
url={https://openreview.net/forum?id=SkfMWhAqYQ},
}",0.46,0.805
bagnet33,https://openreview.net/forum?id=SkfMWhAqYQ,"@inproceedings{
brendel2018approximating,
title={Approximating {CNN}s with Bag-of-local-Features models works surprisingly well on ImageNet},
author={Wieland Brendel and Matthias Bethge},
booktitle={International Conference on Learning Representations},
year={2019},
month={mar},
url={https://openreview.net/forum?id=SkfMWhAqYQ},
}",0.59,0.876
nasnet_mobile,https://arxiv.org/abs/1707.07012,"@article{DBLP:journals/corr/ZophVSL17,
  author    = {Barret Zoph and
               Vijay Vasudevan and
               Jonathon Shlens and
               Quoc V. Le},
  title     = {Learning Transferable Architectures for Scalable Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1707.07012},
  year      = {2017},
  month = {jul},
  url       = {http://arxiv.org/abs/1707.07012},
  archivePrefix = {arXiv},
  eprint    = {1707.07012},
  timestamp = {Sat, 05 Aug 2017 14:56:05 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/ZophVSL17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.74,0.916
nasnet_large,https://arxiv.org/abs/1707.07012,"@article{DBLP:journals/corr/ZophVSL17,
  author    = {Barret Zoph and
               Vijay Vasudevan and
               Jonathon Shlens and
               Quoc V. Le},
  title     = {Learning Transferable Architectures for Scalable Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1707.07012},
  year      = {2017},
  month = {jul},
  url       = {http://arxiv.org/abs/1707.07012},
  archivePrefix = {arXiv},
  eprint    = {1707.07012},
  timestamp = {Sat, 05 Aug 2017 14:56:05 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/ZophVSL17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.827,0.962
pnasnet_large,https://arxiv.org/abs/1712.00559,"@article{DBLP:journals/corr/abs-1712-00559,
  author    = {Chenxi Liu and
               Barret Zoph and
               Jonathon Shlens and
               Wei Hua and
               Li{-}Jia Li and
               Li Fei{-}Fei and
               Alan L. Yuille and
               Jonathan Huang and
               Kevin Murphy},
  title     = {Progressive Neural Architecture Search},
  journal   = {CoRR},
  volume    = {abs/1712.00559},
  year      = {2017},
  month = {dec},
  url       = {http://arxiv.org/abs/1712.00559},
  archivePrefix = {arXiv},
  eprint    = {1712.00559},
  timestamp = {Wed, 03 Jan 2018 12:33:17 +0100},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1712-00559},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.829,0.962
mobilenet_v1_1.0_224,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.709,0.899
mobilenet_v1_1.0_192,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.7,0.892
mobilenet_v1_1.0_160,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.68,0.877
mobilenet_v1_1.0_128,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.652,0.858
mobilenet_v1_0.75_224,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.684,0.882
mobilenet_v1_0.75_192,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.672,0.873
mobilenet_v1_0.75_160,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.653,0.86
mobilenet_v1_0.75_128,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.621,0.839
mobilenet_v1_0.5_224,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.633,0.849
mobilenet_v1_0.5_192,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.617,0.836
mobilenet_v1_0.5_160,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.591,0.819
mobilenet_v1_0.5_128,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.563,0.794
mobilenet_v1_0.25_224,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.498,0.742
mobilenet_v1_0.25_192,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.477,0.723
mobilenet_v1_0.25_160,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.455,0.703
mobilenet_v1_0.25_128,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.415,0.663
mobilenet_v2_1.4_224,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.75,0.925
mobilenet_v2_1.3_224,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.744,0.921
mobilenet_v2_1.0_224,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.718,0.91
mobilenet_v2_1.0_192,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.707,0.901
mobilenet_v2_1.0_160,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.688,0.89
mobilenet_v2_1.0_128,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.653,0.869
mobilenet_v2_1.0_96,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.603,0.832
mobilenet_v2_0.75_224,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.698,0.896
mobilenet_v2_0.75_192,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.687,0.889
mobilenet_v2_0.75_160,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.664,0.873
mobilenet_v2_0.75_128,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.632,0.853
mobilenet_v2_0.75_96,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.588,0.816
mobilenet_v2_0.5_224,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.654,0.864
mobilenet_v2_0.5_192,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.639,0.854
mobilenet_v2_0.5_160,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.61,0.832
mobilenet_v2_0.5_128,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.577,0.808
mobilenet_v2_0.5_96,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.512,0.758
mobilenet_v2_0.35_224,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.603,0.829
mobilenet_v2_0.35_192,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.582,0.812
mobilenet_v2_0.35_160,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.557,0.791
mobilenet_v2_0.35_128,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.508,0.75
mobilenet_v2_0.35_96,https://arxiv.org/abs/1704.04861,"@article{DBLP:journals/corr/HowardZCKWWAA17,
  author    = {Andrew G. Howard and
               Menglong Zhu and
               Bo Chen and
               Dmitry Kalenichenko and
               Weijun Wang and
               Tobias Weyand and
               Marco Andreetto and
               Hartwig Adam},
  title     = {MobileNets: Efficient Convolutional Neural Networks for Mobile Vision
               Applications},
  journal   = {CoRR},
  volume    = {abs/1704.04861},
  year      = {2017},
  month = {apr},
  url       = {http://arxiv.org/abs/1704.04861},
  archivePrefix = {arXiv},
  eprint    = {1704.04861},
  timestamp = {Wed, 07 Jun 2017 14:40:11 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HowardZCKWWAA17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",0.455,0.704
resnet50-SIN,https://openreview.net/forum?id=Bygh9j09KX,"@inproceedings{
geirhos2018imagenettrained,
title={ImageNet-trained {CNN}s are biased towards texture; increasing shape bias improves accuracy and robustness.},
author={Robert Geirhos and Patricia Rubisch and Claudio Michaelis and Matthias Bethge and Felix A. Wichmann and Wieland Brendel},
booktitle={International Conference on Learning Representations},
year={2019},
month={feb},
url={https://openreview.net/forum?id=Bygh9j09KX},
}",0.6018,0.8262
resnet50-SIN_IN,https://openreview.net/forum?id=Bygh9j09KX,"@inproceedings{
geirhos2018imagenettrained,
title={ImageNet-trained {CNN}s are biased towards texture; increasing shape bias improves accuracy and robustness.},
author={Robert Geirhos and Patricia Rubisch and Claudio Michaelis and Matthias Bethge and Felix A. Wichmann and Wieland Brendel},
booktitle={International Conference on Learning Representations},
year={2019},
month={feb},
url={https://openreview.net/forum?id=Bygh9j09KX},
}",0.7459,0.9214
resnet50-SIN_IN_IN,https://openreview.net/forum?id=Bygh9j09KX,"@inproceedings{
geirhos2018imagenettrained,
title={ImageNet-trained {CNN}s are biased towards texture; increasing shape bias improves accuracy and robustness.},
author={Robert Geirhos and Patricia Rubisch and Claudio Michaelis and Matthias Bethge and Felix A. Wichmann and Wieland Brendel},
booktitle={International Conference on Learning Representations},
year={2019},
month={feb},
url={https://openreview.net/forum?id=Bygh9j09KX},
}",0.7672,0.9328
resnext101_32x48d_wsl,https://arxiv.org/pdf/1906.06423.pdf,"@InProceedings{Mahajan2018ECCV,
author = {Mahajan, Dhruv and Girshick, Ross and Ramanathan, Vignesh and He, Kaiming and Paluri, Manohar and Li, Yixuan and Bharambe, Ashwin and van der Maaten, Laurens},
title = {Exploring the Limits of Weakly Supervised Pretraining},
booktitle = {The European Conference on Computer Vision (ECCV)},
month = {sep},
year = {2018},
url = {https://arxiv.org/pdf/1906.06423.pdf}
} ",0.822,0.964
resnext101_32x8d_wsl,http://openaccess.thecvf.com/content_ECCV_2018/html/Dhruv_Mahajan_Exploring_the_Limits_ECCV_2018_paper.html,"@InProceedings{Mahajan2018ECCV,
author = {Mahajan, Dhruv and Girshick, Ross and Ramanathan, Vignesh and He, Kaiming and Paluri, Manohar and Li, Yixuan and Bharambe, Ashwin and van der Maaten, Laurens},
title = {Exploring the Limits of Weakly Supervised Pretraining},
booktitle = {The European Conference on Computer Vision (ECCV)},
month = {sep},
year = {2018},
url = {https://arxiv.org/pdf/1906.06423.pdf},
} ",0.842,0.972
resnext101_32x16d_wsl,http://openaccess.thecvf.com/content_ECCV_2018/html/Dhruv_Mahajan_Exploring_the_Limits_ECCV_2018_paper.html,"@InProceedings{Mahajan2018ECCV,
author = {Mahajan, Dhruv and Girshick, Ross and Ramanathan, Vignesh and He, Kaiming and Paluri, Manohar and Li, Yixuan and Bharambe, Ashwin and van der Maaten, Laurens},
title = {Exploring the Limits of Weakly Supervised Pretraining},
booktitle = {The European Conference on Computer Vision (ECCV)},
month = {sep},
year = {2018},
url = {http://openaccess.thecvf.com/content_ECCV_2018/html/Dhruv_Mahajan_Exploring_the_Limits_ECCV_2018_paper.html}
} ",0.851,0.975
resnext101_32x32d_wsl,http://openaccess.thecvf.com/content_ECCV_2018/html/Dhruv_Mahajan_Exploring_the_Limits_ECCV_2018_paper.html,"@InProceedings{Mahajan2018ECCV,
author = {Mahajan, Dhruv and Girshick, Ross and Ramanathan, Vignesh and He, Kaiming and Paluri, Manohar and Li, Yixuan and Bharambe, Ashwin and van der Maaten, Laurens},
title = {Exploring the Limits of Weakly Supervised Pretraining},
booktitle = {The European Conference on Computer Vision (ECCV)},
month = {sep},
year = {2018},
url = {http://openaccess.thecvf.com/content_ECCV_2018/html/Dhruv_Mahajan_Exploring_the_Limits_ECCV_2018_paper.html}
} ",0.854,0.976
fixres_resnext101_32x48d_wsl,http://papers.nips.cc/paper/9035-fixing-the-train-test-resolution-discrepancy,"@incollection{NIPS2019_9035,
title = {Fixing the train-test resolution discrepancy},
author = {Touvron, Hugo and Vedaldi, Andrea and Douze, Matthijs and Jegou, Herve},
booktitle = {Advances in Neural Information Processing Systems 32},
editor = {H. Wallach and H. Larochelle and A. Beygelzimer and F. d\textquotesingle Alch\'{e}-Buc and E. Fox and R. Garnett},
pages = {8252--8262},
year = {2019},
publisher = {Curran Associates, Inc.},
url = {http://papers.nips.cc/paper/9035-fixing-the-train-test-resolution-discrepancy.pdf}
}",0.863,
resnet18-supervised,https://arxiv.org/abs/1512.03385,"@article{DBLP:journals/corr/HeZRS15,
  author    = {Kaiming He and
               Xiangyu Zhang and
               Shaoqing Ren and
               Jian Sun},
  title     = {Deep Residual Learning for Image Recognition},
  journal   = {CoRR},
  volume    = {abs/1512.03385},
  year      = {2015},
  month = {dec},
  url       = {http://arxiv.org/abs/1512.03385},
  archivePrefix = {arXiv},
  eprint    = {1512.03385},
  timestamp = {Wed, 07 Jun 2017 14:41:17 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/HeZRS15},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}",,
resnet18-local_aggregation,https://openaccess.thecvf.com/content_ICCV_2019/html/Zhuang_Local_Aggregation_for_Unsupervised_Learning_of_Visual_Embeddings_ICCV_2019_paper.html,"@InProceedings{Zhuang_2019_ICCV,
author = {Zhuang, Chengxu and Zhai, Alex Lin and Yamins, Daniel},
title = {Local Aggregation for Unsupervised Learning of Visual Embeddings},
booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
month = {October},
year = {2019},
url = {https://openaccess.thecvf.com/content_ICCV_2019/html/Zhuang_Local_Aggregation_for_Unsupervised_Learning_of_Visual_Embeddings_ICCV_2019_paper}
}",,
resnet18-instance_recognition,https://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Unsupervised_Feature_Learning_CVPR_2018_paper.html,"@InProceedings{Wu_2018_CVPR,
author = {Wu, Zhirong and Xiong, Yuanjun and Yu, Stella X. and Lin, Dahua},
title = {Unsupervised Feature Learning via Non-Parametric Instance Discrimination},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2018},
url = {https://openaccess.thecvf.com/content_cvpr_2018/html/Wu_Unsupervised_Feature_Learning_CVPR_2018_paper}
}",,
resnet18-autoencoder,https://www.biorxiv.org/content/10.1101/2020.06.16.155556v1,"@article {Zhuang2020.06.16.155556,
	author = {Zhuang, Chengxu and Yan, Siming and Nayebi, Aran and Schrimpf, Martin and Frank, Michael C. and DiCarlo, James J. and Yamins, Daniel L. K.},
	title = {Unsupervised Neural Network Models of the Ventral Visual Stream},
	elocation-id = {2020.06.16.155556},
	year = {2020},
	doi = {10.1101/2020.06.16.155556},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Deep neural networks currently provide the best quantitative models of the response patterns of neurons throughout the primate ventral visual stream. However, such networks have remained implausible as a model of the development of the ventral stream, in part because they are trained with supervised methods requiring many more labels than are accessible to infants during development. Here, we report that recent rapid progress in unsupervised learning has largely closed this gap. We find that neural network models learned with deep unsupervised contrastive embedding methods achieve neural prediction accuracy in multiple ventral visual cortical areas that equals or exceeds that of models derived using today{\textquoteright}s best supervised methods, and that the mapping of these neural network models{\textquoteright} hidden layers is neuroanatomically consistent across the ventral stream. Moreover, we find that these methods produce brain-like representations even when trained on noisy and limited data measured from real children{\textquoteright}s developmental experience. We also find that semi-supervised deep contrastive embeddings can leverage small numbers of labelled examples to produce representations with substantially improved error-pattern consistency to human behavior. Taken together, these results suggest that deep contrastive embedding objectives may be a biologically-plausible computational theory of primate visual development.Competing Interest StatementThe authors have declared no competing interest.},
	URL = {https://www.biorxiv.org/content/early/2020/06/18/2020.06.16.155556},
	eprint = {https://www.biorxiv.org/content/early/2020/06/18/2020.06.16.155556.full.pdf},
	journal = {bioRxiv}
}",,
resnet18-contrastive_predictive,https://www.biorxiv.org/content/10.1101/2020.06.16.155556v1,"@article {Zhuang2020.06.16.155556,
	author = {Zhuang, Chengxu and Yan, Siming and Nayebi, Aran and Schrimpf, Martin and Frank, Michael C. and DiCarlo, James J. and Yamins, Daniel L. K.},
	title = {Unsupervised Neural Network Models of the Ventral Visual Stream},
	elocation-id = {2020.06.16.155556},
	year = {2020},
	doi = {10.1101/2020.06.16.155556},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Deep neural networks currently provide the best quantitative models of the response patterns of neurons throughout the primate ventral visual stream. However, such networks have remained implausible as a model of the development of the ventral stream, in part because they are trained with supervised methods requiring many more labels than are accessible to infants during development. Here, we report that recent rapid progress in unsupervised learning has largely closed this gap. We find that neural network models learned with deep unsupervised contrastive embedding methods achieve neural prediction accuracy in multiple ventral visual cortical areas that equals or exceeds that of models derived using today{\textquoteright}s best supervised methods, and that the mapping of these neural network models{\textquoteright} hidden layers is neuroanatomically consistent across the ventral stream. Moreover, we find that these methods produce brain-like representations even when trained on noisy and limited data measured from real children{\textquoteright}s developmental experience. We also find that semi-supervised deep contrastive embeddings can leverage small numbers of labelled examples to produce representations with substantially improved error-pattern consistency to human behavior. Taken together, these results suggest that deep contrastive embedding objectives may be a biologically-plausible computational theory of primate visual development.Competing Interest StatementThe authors have declared no competing interest.},
	URL = {https://www.biorxiv.org/content/early/2020/06/18/2020.06.16.155556},
	eprint = {https://www.biorxiv.org/content/early/2020/06/18/2020.06.16.155556.full.pdf},
	journal = {bioRxiv}
}",,
resnet18-colorization,https://www.biorxiv.org/content/10.1101/2020.06.16.155556v1,"@article {Zhuang2020.06.16.155556,
	author = {Zhuang, Chengxu and Yan, Siming and Nayebi, Aran and Schrimpf, Martin and Frank, Michael C. and DiCarlo, James J. and Yamins, Daniel L. K.},
	title = {Unsupervised Neural Network Models of the Ventral Visual Stream},
	elocation-id = {2020.06.16.155556},
	year = {2020},
	doi = {10.1101/2020.06.16.155556},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Deep neural networks currently provide the best quantitative models of the response patterns of neurons throughout the primate ventral visual stream. However, such networks have remained implausible as a model of the development of the ventral stream, in part because they are trained with supervised methods requiring many more labels than are accessible to infants during development. Here, we report that recent rapid progress in unsupervised learning has largely closed this gap. We find that neural network models learned with deep unsupervised contrastive embedding methods achieve neural prediction accuracy in multiple ventral visual cortical areas that equals or exceeds that of models derived using today{\textquoteright}s best supervised methods, and that the mapping of these neural network models{\textquoteright} hidden layers is neuroanatomically consistent across the ventral stream. Moreover, we find that these methods produce brain-like representations even when trained on noisy and limited data measured from real children{\textquoteright}s developmental experience. We also find that semi-supervised deep contrastive embeddings can leverage small numbers of labelled examples to produce representations with substantially improved error-pattern consistency to human behavior. Taken together, these results suggest that deep contrastive embedding objectives may be a biologically-plausible computational theory of primate visual development.Competing Interest StatementThe authors have declared no competing interest.},
	URL = {https://www.biorxiv.org/content/early/2020/06/18/2020.06.16.155556},
	eprint = {https://www.biorxiv.org/content/early/2020/06/18/2020.06.16.155556.full.pdf},
	journal = {bioRxiv}
}",,
resnet18-relative_position,https://www.biorxiv.org/content/10.1101/2020.06.16.155556v1,"@article {Zhuang2020.06.16.155556,
	author = {Zhuang, Chengxu and Yan, Siming and Nayebi, Aran and Schrimpf, Martin and Frank, Michael C. and DiCarlo, James J. and Yamins, Daniel L. K.},
	title = {Unsupervised Neural Network Models of the Ventral Visual Stream},
	elocation-id = {2020.06.16.155556},
	year = {2020},
	doi = {10.1101/2020.06.16.155556},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Deep neural networks currently provide the best quantitative models of the response patterns of neurons throughout the primate ventral visual stream. However, such networks have remained implausible as a model of the development of the ventral stream, in part because they are trained with supervised methods requiring many more labels than are accessible to infants during development. Here, we report that recent rapid progress in unsupervised learning has largely closed this gap. We find that neural network models learned with deep unsupervised contrastive embedding methods achieve neural prediction accuracy in multiple ventral visual cortical areas that equals or exceeds that of models derived using today{\textquoteright}s best supervised methods, and that the mapping of these neural network models{\textquoteright} hidden layers is neuroanatomically consistent across the ventral stream. Moreover, we find that these methods produce brain-like representations even when trained on noisy and limited data measured from real children{\textquoteright}s developmental experience. We also find that semi-supervised deep contrastive embeddings can leverage small numbers of labelled examples to produce representations with substantially improved error-pattern consistency to human behavior. Taken together, these results suggest that deep contrastive embedding objectives may be a biologically-plausible computational theory of primate visual development.Competing Interest StatementThe authors have declared no competing interest.},
	URL = {https://www.biorxiv.org/content/early/2020/06/18/2020.06.16.155556},
	eprint = {https://www.biorxiv.org/content/early/2020/06/18/2020.06.16.155556.full.pdf},
	journal = {bioRxiv}
}",,
resnet18-depth_prediction,https://www.biorxiv.org/content/10.1101/2020.06.16.155556v1,"@article {Zhuang2020.06.16.155556,
	author = {Zhuang, Chengxu and Yan, Siming and Nayebi, Aran and Schrimpf, Martin and Frank, Michael C. and DiCarlo, James J. and Yamins, Daniel L. K.},
	title = {Unsupervised Neural Network Models of the Ventral Visual Stream},
	elocation-id = {2020.06.16.155556},
	year = {2020},
	doi = {10.1101/2020.06.16.155556},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Deep neural networks currently provide the best quantitative models of the response patterns of neurons throughout the primate ventral visual stream. However, such networks have remained implausible as a model of the development of the ventral stream, in part because they are trained with supervised methods requiring many more labels than are accessible to infants during development. Here, we report that recent rapid progress in unsupervised learning has largely closed this gap. We find that neural network models learned with deep unsupervised contrastive embedding methods achieve neural prediction accuracy in multiple ventral visual cortical areas that equals or exceeds that of models derived using today{\textquoteright}s best supervised methods, and that the mapping of these neural network models{\textquoteright} hidden layers is neuroanatomically consistent across the ventral stream. Moreover, we find that these methods produce brain-like representations even when trained on noisy and limited data measured from real children{\textquoteright}s developmental experience. We also find that semi-supervised deep contrastive embeddings can leverage small numbers of labelled examples to produce representations with substantially improved error-pattern consistency to human behavior. Taken together, these results suggest that deep contrastive embedding objectives may be a biologically-plausible computational theory of primate visual development.Competing Interest StatementThe authors have declared no competing interest.},
	URL = {https://www.biorxiv.org/content/early/2020/06/18/2020.06.16.155556},
	eprint = {https://www.biorxiv.org/content/early/2020/06/18/2020.06.16.155556.full.pdf},
	journal = {bioRxiv}
}",,
prednet,https://www.biorxiv.org/content/10.1101/2020.06.16.155556v1,"@article {Zhuang2020.06.16.155556,
	author = {Zhuang, Chengxu and Yan, Siming and Nayebi, Aran and Schrimpf, Martin and Frank, Michael C. and DiCarlo, James J. and Yamins, Daniel L. K.},
	title = {Unsupervised Neural Network Models of the Ventral Visual Stream},
	elocation-id = {2020.06.16.155556},
	year = {2020},
	doi = {10.1101/2020.06.16.155556},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Deep neural networks currently provide the best quantitative models of the response patterns of neurons throughout the primate ventral visual stream. However, such networks have remained implausible as a model of the development of the ventral stream, in part because they are trained with supervised methods requiring many more labels than are accessible to infants during development. Here, we report that recent rapid progress in unsupervised learning has largely closed this gap. We find that neural network models learned with deep unsupervised contrastive embedding methods achieve neural prediction accuracy in multiple ventral visual cortical areas that equals or exceeds that of models derived using today{\textquoteright}s best supervised methods, and that the mapping of these neural network models{\textquoteright} hidden layers is neuroanatomically consistent across the ventral stream. Moreover, we find that these methods produce brain-like representations even when trained on noisy and limited data measured from real children{\textquoteright}s developmental experience. We also find that semi-supervised deep contrastive embeddings can leverage small numbers of labelled examples to produce representations with substantially improved error-pattern consistency to human behavior. Taken together, these results suggest that deep contrastive embedding objectives may be a biologically-plausible computational theory of primate visual development.Competing Interest StatementThe authors have declared no competing interest.},
	URL = {https://www.biorxiv.org/content/early/2020/06/18/2020.06.16.155556},
	eprint = {https://www.biorxiv.org/content/early/2020/06/18/2020.06.16.155556.full.pdf},
	journal = {bioRxiv}
}",,
resnet18-simclr,https://www.biorxiv.org/content/10.1101/2020.06.16.155556v1,"@article {Zhuang2020.06.16.155556,
	author = {Zhuang, Chengxu and Yan, Siming and Nayebi, Aran and Schrimpf, Martin and Frank, Michael C. and DiCarlo, James J. and Yamins, Daniel L. K.},
	title = {Unsupervised Neural Network Models of the Ventral Visual Stream},
	elocation-id = {2020.06.16.155556},
	year = {2020},
	doi = {10.1101/2020.06.16.155556},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Deep neural networks currently provide the best quantitative models of the response patterns of neurons throughout the primate ventral visual stream. However, such networks have remained implausible as a model of the development of the ventral stream, in part because they are trained with supervised methods requiring many more labels than are accessible to infants during development. Here, we report that recent rapid progress in unsupervised learning has largely closed this gap. We find that neural network models learned with deep unsupervised contrastive embedding methods achieve neural prediction accuracy in multiple ventral visual cortical areas that equals or exceeds that of models derived using today{\textquoteright}s best supervised methods, and that the mapping of these neural network models{\textquoteright} hidden layers is neuroanatomically consistent across the ventral stream. Moreover, we find that these methods produce brain-like representations even when trained on noisy and limited data measured from real children{\textquoteright}s developmental experience. We also find that semi-supervised deep contrastive embeddings can leverage small numbers of labelled examples to produce representations with substantially improved error-pattern consistency to human behavior. Taken together, these results suggest that deep contrastive embedding objectives may be a biologically-plausible computational theory of primate visual development.Competing Interest StatementThe authors have declared no competing interest.},
	URL = {https://www.biorxiv.org/content/early/2020/06/18/2020.06.16.155556},
	eprint = {https://www.biorxiv.org/content/early/2020/06/18/2020.06.16.155556.full.pdf},
	journal = {bioRxiv}
}",,
resnet18-deepcluster,https://www.biorxiv.org/content/10.1101/2020.06.16.155556v1,"@article {Zhuang2020.06.16.155556,
	author = {Zhuang, Chengxu and Yan, Siming and Nayebi, Aran and Schrimpf, Martin and Frank, Michael C. and DiCarlo, James J. and Yamins, Daniel L. K.},
	title = {Unsupervised Neural Network Models of the Ventral Visual Stream},
	elocation-id = {2020.06.16.155556},
	year = {2020},
	doi = {10.1101/2020.06.16.155556},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Deep neural networks currently provide the best quantitative models of the response patterns of neurons throughout the primate ventral visual stream. However, such networks have remained implausible as a model of the development of the ventral stream, in part because they are trained with supervised methods requiring many more labels than are accessible to infants during development. Here, we report that recent rapid progress in unsupervised learning has largely closed this gap. We find that neural network models learned with deep unsupervised contrastive embedding methods achieve neural prediction accuracy in multiple ventral visual cortical areas that equals or exceeds that of models derived using today{\textquoteright}s best supervised methods, and that the mapping of these neural network models{\textquoteright} hidden layers is neuroanatomically consistent across the ventral stream. Moreover, we find that these methods produce brain-like representations even when trained on noisy and limited data measured from real children{\textquoteright}s developmental experience. We also find that semi-supervised deep contrastive embeddings can leverage small numbers of labelled examples to produce representations with substantially improved error-pattern consistency to human behavior. Taken together, these results suggest that deep contrastive embedding objectives may be a biologically-plausible computational theory of primate visual development.Competing Interest StatementThe authors have declared no competing interest.},
	URL = {https://www.biorxiv.org/content/early/2020/06/18/2020.06.16.155556},
	eprint = {https://www.biorxiv.org/content/early/2020/06/18/2020.06.16.155556.full.pdf},
	journal = {bioRxiv}
}",,
resnet18-contrastive_multiview,https://www.biorxiv.org/content/10.1101/2020.06.16.155556v1,"@article {Zhuang2020.06.16.155556,
	author = {Zhuang, Chengxu and Yan, Siming and Nayebi, Aran and Schrimpf, Martin and Frank, Michael C. and DiCarlo, James J. and Yamins, Daniel L. K.},
	title = {Unsupervised Neural Network Models of the Ventral Visual Stream},
	elocation-id = {2020.06.16.155556},
	year = {2020},
	doi = {10.1101/2020.06.16.155556},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Deep neural networks currently provide the best quantitative models of the response patterns of neurons throughout the primate ventral visual stream. However, such networks have remained implausible as a model of the development of the ventral stream, in part because they are trained with supervised methods requiring many more labels than are accessible to infants during development. Here, we report that recent rapid progress in unsupervised learning has largely closed this gap. We find that neural network models learned with deep unsupervised contrastive embedding methods achieve neural prediction accuracy in multiple ventral visual cortical areas that equals or exceeds that of models derived using today{\textquoteright}s best supervised methods, and that the mapping of these neural network models{\textquoteright} hidden layers is neuroanatomically consistent across the ventral stream. Moreover, we find that these methods produce brain-like representations even when trained on noisy and limited data measured from real children{\textquoteright}s developmental experience. We also find that semi-supervised deep contrastive embeddings can leverage small numbers of labelled examples to produce representations with substantially improved error-pattern consistency to human behavior. Taken together, these results suggest that deep contrastive embedding objectives may be a biologically-plausible computational theory of primate visual development.Competing Interest StatementThe authors have declared no competing interest.},
	URL = {https://www.biorxiv.org/content/early/2020/06/18/2020.06.16.155556},
	eprint = {https://www.biorxiv.org/content/early/2020/06/18/2020.06.16.155556.full.pdf},
	journal = {bioRxiv}
}",,
