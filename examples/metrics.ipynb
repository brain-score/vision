{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This framework is concerned with comparing two sets of data, for instance source brain and target brain.\n",
    "It does not take care of trying multiple combinations of source data (such as multiple layers in models), but only makes direct comparisons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A metric tells us how similar to assemblies (sets of data) are to each other.\n",
    "For comparison, they might be re-mapped (neural predictivity) or compared in sub-spaces (RDMs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-defined metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brain-Score comes with many standard metrics used in the field.\n",
    "For instance, we can easily use regression methods to compare two assemblies based on how well one predicts the neural firing rates in the other:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural (PLS) Predictivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rcross-validation:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rcross-validation:  10%|█         | 1/10 [00:00<00:02,  3.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rcross-validation:  20%|██        | 2/10 [00:00<00:02,  3.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rcross-validation:  30%|███       | 3/10 [00:00<00:02,  3.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rcross-validation:  40%|████      | 4/10 [00:01<00:01,  3.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rcross-validation:  50%|█████     | 5/10 [00:01<00:01,  3.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rcross-validation:  60%|██████    | 6/10 [00:01<00:01,  3.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rcross-validation:  70%|███████   | 7/10 [00:02<00:00,  3.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rcross-validation:  80%|████████  | 8/10 [00:02<00:00,  3.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rcross-validation:  90%|█████████ | 9/10 [00:02<00:00,  3.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rcross-validation: 100%|██████████| 10/10 [00:03<00:00,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n Score(_variable=<xarray.Variable (aggregation: 2)>\narray([1., 0.])\nAttributes:\n    raw:      <xarray.DataAssembly (split: 10, neuroid: 25)>\\narray([[1., 1.,...,_coords=OrderedDict([('aggregation', <xarray.IndexVariable 'aggregation' (aggregation: 2)>\narray(['center', 'error'], dtype='<U6'))]),_name=None,_file_obj=None,_initialized=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from brainscore.assemblies import NeuroidAssembly\n",
    "from brainscore.metrics.neural_predictivity import PlsPredictivity\n",
    "\n",
    "assembly = NeuroidAssembly((np.arange(30 * 25) + np.random.standard_normal(30 * 25)).reshape((30, 25)),\n",
    "                           coords={'image_id': ('presentation', np.arange(30)),\n",
    "                                   'object_name': ('presentation', ['a', 'b', 'c'] * 10),\n",
    "                                   'neuroid_id': ('neuroid', np.arange(25)),\n",
    "                                   'region': ('neuroid', [0] * 25)},\n",
    "                           dims=['presentation', 'neuroid'])\n",
    "metric = PlsPredictivity()\n",
    "score = metric(source=assembly, target=assembly)\n",
    "print(\"\\n\", score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rcross-validation:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rcross-validation:  30%|███       | 3/10 [00:00<00:00, 25.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rcross-validation:  70%|███████   | 7/10 [00:00<00:00, 27.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rcross-validation: 100%|██████████| 10/10 [00:00<00:00, 31.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n Score(_variable=<xarray.Variable (aggregation: 2)>\narray([1.000000e+00, 2.482534e-17])\nAttributes:\n    raw:      <xarray.DataAssembly (split: 10)>\\narray([1., 1., 1., 1., 1., 1...,_coords=OrderedDict([('aggregation', <xarray.IndexVariable 'aggregation' (aggregation: 2)>\narray(['center', 'error'], dtype='<U6'))]),_name=None,_file_obj=None,_initialized=True)\n"
     ]
    }
   ],
   "source": [
    "from brainscore.metrics.rdm import RDMCrossValidated\n",
    "\n",
    "metric = RDMCrossValidated()\n",
    "rdm_score = metric(assembly1=assembly, assembly2=assembly)\n",
    "print(\"\\n\", rdm_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Raw values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above values are aggregate values over splits and neuroids.\n",
    "We can also check the raw values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.DataAssembly (split: 10, neuroid: 25)>\narray([[1., 1., 1., ..., 1., 1., 1.],\n       [1., 1., 1., ..., 1., 1., 1.],\n       [1., 1., 1., ..., 1., 1., 1.],\n       ...,\n       [1., 1., 1., ..., 1., 1., 1.],\n       [1., 1., 1., ..., 1., 1., 1.],\n       [1., 1., 1., ..., 1., 1., 1.]])\nCoordinates:\n  * split       (split) int64 0 1 2 3 4 5 6 7 8 9\n  * neuroid     (neuroid) MultiIndex\n  - neuroid_id  (neuroid) int64 0 1 2 3 4 5 6 7 8 ... 16 17 18 19 20 21 22 23 24\n  - region      (neuroid) int64 0 0 0 0 0 0 0 0 0 0 0 ... 0 0 0 0 0 0 0 0 0 0 0\n"
     ]
    }
   ],
   "source": [
    "print(score.attrs['raw'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A metric simply returns a Score for the similarity of two assemblies.\n",
    "For instance, the following computes the Euclidean distance of regressed and target neuroids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rcross-validation:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rcross-validation:  20%|██        | 2/10 [00:00<00:00, 15.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rcross-validation:  50%|█████     | 5/10 [00:00<00:00, 16.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rcross-validation:  70%|███████   | 7/10 [00:00<00:00, 16.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rcross-validation:  90%|█████████ | 9/10 [00:00<00:00, 13.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\rcross-validation: 100%|██████████| 10/10 [00:00<00:00, 14.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n Score(_variable=<xarray.Variable (aggregation: 2)>\narray([1.017260e-13, 9.840511e-15])\nAttributes:\n    raw:      <xarray.DataAssembly (split: 10, presentation: 19, neuroid: 25)...,_coords=OrderedDict([('aggregation', <xarray.IndexVariable 'aggregation' (aggregation: 2)>\narray(['center', 'error'], dtype='<U6'))]),_name=None,_file_obj=None,_initialized=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n/home/martin/miniconda3/envs/brainscore/lib/python3.7/site-packages/numpy/lib/function_base.py:3250: RuntimeWarning: All-NaN slice encountered\n  r = func(a, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from brainscore.assemblies import DataAssembly\n",
    "from brainscore.metrics.transformations import CrossValidation\n",
    "from brainscore.metrics.xarray_utils import XarrayRegression\n",
    "from brainscore.metrics.neural_predictivity import LinearRegression\n",
    "\n",
    "\n",
    "class DistanceMetric:\n",
    "    def __init__(self):\n",
    "        regression = LinearRegression()\n",
    "        self._regression = XarrayRegression(regression=regression)\n",
    "        self._cross_validation = CrossValidation()\n",
    "\n",
    "    def __call__(self, source, target):\n",
    "        return self._cross_validation(source, target, apply=self._apply, aggregate=self._aggregate)\n",
    "        \n",
    "    def _apply(self, source_train, target_train, source_test, target_test):\n",
    "        self._regression.fit(source_train, target_train)\n",
    "        prediction = self._regression.predict(source_test)\n",
    "        score = self._compare(prediction, target_test)\n",
    "        return score\n",
    "    \n",
    "    def _compare(self, prediction, target):\n",
    "        prediction, target = prediction.sortby('image_id').sortby('neuroid_id'), target.sortby('image_id').sortby('neuroid_id')\n",
    "        assert all(prediction['image_id'].values == target['image_id'].values)\n",
    "        assert all(prediction['neuroid_id'].values == target['neuroid_id'].values)\n",
    "        difference = np.abs(target.values - prediction.values)  # lower is better\n",
    "        return DataAssembly(difference, coords=target.coords, dims=target.dims)\n",
    "    \n",
    "    def _aggregate(self, scores):\n",
    "        return scores.median('neuroid').mean('presentation')\n",
    "    \n",
    "\n",
    "metric = DistanceMetric()\n",
    "score = metric(assembly, assembly)\n",
    "print(\"\\n\", score)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "mkgu"
  },
  "kernelspec": {
   "display_name": "mkgu",
   "language": "python",
   "name": "mkgu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "nteract": {
   "version": "0.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
