{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO:\n",
    "1. Work on Assembly in \"# get activations\" part instead of the StimulusSet\n",
    "2. Translate to ``behavior.py`` and the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import brainscore_vision\n",
    "from brainio.assemblies import DataAssembly, BehavioralAssembly, walk_coords\n",
    "from brainscore_vision.benchmark_helpers.screen import place_on_screen\n",
    "from brainscore_vision.model_helpers.activations import PytorchWrapper\n",
    "from brainscore_vision.model_helpers.brain_transformation import ModelCommitment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytorch_custom():\n",
    "    import torch\n",
    "    from torch import nn\n",
    "    from brainscore_vision.model_helpers.activations.pytorch import load_preprocess_images\n",
    "\n",
    "    class MyModel(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(MyModel, self).__init__()\n",
    "            np.random.seed(0)\n",
    "            torch.random.manual_seed(0)\n",
    "            self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=2, kernel_size=3)\n",
    "            self.relu1 = torch.nn.ReLU()\n",
    "            linear_input_size = np.power((224 - 3 + 2 * 0) / 1 + 1, 2) * 2\n",
    "            self.linear = torch.nn.Linear(int(linear_input_size), 1000)\n",
    "            self.relu2 = torch.nn.ReLU()\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = self.relu1(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.linear(x)\n",
    "            x = self.relu2(x)\n",
    "            return x\n",
    "\n",
    "    preprocessing = functools.partial(load_preprocess_images, image_size=224)\n",
    "    return PytorchWrapper(model=MyModel(), preprocessing=preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "activations_model = pytorch_custom()\n",
    "layers = [\"relu2\"]\n",
    "\n",
    "# create brain model\n",
    "brain_model = ModelCommitment(\n",
    "    identifier=activations_model.identifier, \n",
    "    activations_model=activations_model, \n",
    "    layers=[None], \n",
    "    behavioral_readout_layer='relu2')\n",
    "\n",
    "# get activations\n",
    "assy = brainscore_vision.load_dataset(f'Hebart2023')\n",
    "stimuli = place_on_screen(\n",
    "    stimulus_set=assy.stimulus_set,\n",
    "    target_visual_degrees=brain_model.visual_degrees(),\n",
    "    source_visual_degrees=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity_matrix(features, similarity_measure='dot'):\n",
    "   print(features, type(features))\n",
    "   features = features.transpose('presentation', 'neuroid')\n",
    "   values = features.values\n",
    "   if similarity_measure == 'dot':\n",
    "      similarity_matrix = np.dot(values, np.transpose(values))\n",
    "   elif similarity_measure == 'cosine':\n",
    "      row_norms = np.linalg.norm(values, axis=1).reshape(-1, 1)\n",
    "      norm_product = np.dot(row_norms, row_norms.T)\n",
    "      dot_product = np.dot(values, np.transpose(values))\n",
    "      similarity_matrix = dot_product / norm_product\n",
    "   else:\n",
    "      raise ValueError(\n",
    "      f\"Unknown similarity_measure {similarity_measure} -- expected one of 'dot' or 'cosine'\")\n",
    "\n",
    "   similarity_matrix = DataAssembly(similarity_matrix, coords={\n",
    "        **{f\"{coord}_left\": ('presentation_left', values) for coord, _, values in\n",
    "           walk_coords(features['presentation'])},\n",
    "        **{f\"{coord}_right\": ('presentation_right', values) for coord, _, values in\n",
    "           walk_coords(features['presentation'])}\n",
    "   }, dims=['presentation_left', 'presentation_right'])\n",
    "   return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_choices(similarity_matrix, triplets):\n",
    "    triplets = np.array(triplets).reshape(-1, 3)\n",
    "    choice_predictions = []\n",
    "    for triplet in triplets:\n",
    "        i, j, k = triplet\n",
    "        sims = similarity_matrix[i, j], similarity_matrix[i, k],  similarity_matrix[j, k]\n",
    "        idx = triplet[2 - np.argmax(sims)]\n",
    "        choice_predictions.append(idx)\n",
    "    # TODO return as DataAssembly\n",
    "    return choice_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: This should become look_at(), Make sure to drop duplicates where necessary!\n",
    "features = activations_model(stimuli, layers=layers)\n",
    "features = features.transpose('presentation', 'neuroid')\n",
    "assy = brainscore_vision.load_dataset(f'Hebart2023')\n",
    "triplets = np.array([assy['image_1'], assy['image_2'], assy['image_3']]).T\n",
    "triplets = triplets.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.NeuroidAssembly (presentation: 1854, neuroid: 1000)>\n",
      "array([[0.01105666, 0.05785533, 0.        , ..., 0.1394486 , 0.        ,\n",
      "        0.03779155],\n",
      "       [0.        , 0.        , 0.        , ..., 0.01137817, 0.        ,\n",
      "        0.13863228],\n",
      "       [0.3239666 , 0.30983254, 0.        , ..., 0.2911486 , 0.        ,\n",
      "        0.1254089 ],\n",
      "       ...,\n",
      "       [0.01853104, 0.22858877, 0.        , ..., 0.04627881, 0.14518598,\n",
      "        0.        ],\n",
      "       [0.1675643 , 0.03827018, 0.        , ..., 0.20744947, 0.        ,\n",
      "        0.        ],\n",
      "       [0.        , 0.        , 0.        , ..., 0.22435561, 0.02024   ,\n",
      "        0.34257683]], dtype=float32)\n",
      "Coordinates:\n",
      "  * neuroid           (neuroid) MultiIndex\n",
      "  - neuroid_num       (neuroid) int64 0 1 2 3 4 5 6 ... 994 995 996 997 998 999\n",
      "  - model             (neuroid) object 'MyModel' 'MyModel' ... 'MyModel'\n",
      "  - layer             (neuroid) object 'relu2' 'relu2' ... 'relu2' 'relu2'\n",
      "  - channel           (neuroid) int64 0 1 2 3 4 5 6 ... 994 995 996 997 998 999\n",
      "  - channel_x         (neuroid) float64 nan nan nan nan nan ... nan nan nan nan\n",
      "  - channel_y         (neuroid) float64 nan nan nan nan nan ... nan nan nan nan\n",
      "  - neuroid_id        (neuroid) object 'MyModel.relu2.0' ... 'MyModel.relu2.999'\n",
      "    top_down_1        (presentation) object 'animal' nan ... nan 'vegetable'\n",
      "    rank              (presentation) float64 5.151e+04 3.458e+04 ... 1.067e+04\n",
      "    Wordnet_ID4       (presentation) object 'aardvark.n.01' ... 'zucchini.n.02'\n",
      "    unique_id         (presentation) object 'aardvark' 'abacus' ... 'zucchini'\n",
      "    example_image     (presentation) object 'https://imgur.com/LAJGlN0' ... '...\n",
      "    top_down_2        (presentation) object 'animal' ... 'food, vegetable'\n",
      "    filename          (presentation) object '0.jpg' '1.jpg' ... '1853.jpg'\n",
      "    Wordnet_ID2       (presentation) object 'aardvark%1:05:00::' ... 'zucchin...\n",
      "    dispersion        (presentation) float64 0.78 0.86 0.9 ... 0.87 0.88 0.87\n",
      "    bottom_up         (presentation) object 'animal' nan ... nan 'vegetable'\n",
      "    word_freq         (presentation) float64 28.0 97.0 ... 1.452e+03 1.471e+03\n",
      "    dominant_part     (presentation) object 'Noun' 'Noun' ... 'Noun' 'Noun'\n",
      "    freq_1            (presentation) float64 nan nan nan ... 224.0 62.0 nan\n",
      "    WordNet_synonyms  (presentation) object 'aardvark, ant_bear, anteater, Or...\n",
      "    freq_2            (presentation) float64 21.0 12.0 67.0 ... 128.0 144.0 49.0\n",
      "    WordNet_ID        (presentation) object 'n02082791' ... 'n07716358'\n",
      "    Wordnet_ID3       (presentation) object 'aardvark#1' ... 'zucchini#2'\n",
      "    word_freq_online  (presentation) int64 53 188 816 1289 ... 1066 1478 2098\n",
      "  * presentation      (presentation) MultiIndex\n",
      "  - stimulus_id       (presentation) int64 0 1 2 3 4 ... 1850 1851 1852 1853 <class 'brainio.assemblies.NeuroidAssembly'>\n"
     ]
    }
   ],
   "source": [
    "sample = triplets[:10*3]\n",
    "sim = calculate_similarity_matrix(features, similarity_measure='cosine')\n",
    "choices = calculate_choices(similarity_matrix=sim, triplets=sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: this needs to be fixed\n",
    "#stimulus_ids = assy['stimulus_id'][:10]\n",
    "#choices = BehavioralAssembly(choices, coords={\n",
    "#    'triplet_index': ('presentation', [i for i in range(0, len(stimulus_ids), 3)]),\n",
    "#    'triplet_stimulus_id0': ('presentation', [{stimulus_ids[i]} for i in range(0, len(stimulus_ids), 3)]),\n",
    "#    'triplet_stimulus_id1': ('presentation', [{stimulus_ids[i+1]} for i in range(0, len(stimulus_ids), 3)]),\n",
    "#    'triplet_stimulus_id2': ('presentation', [{stimulus_ids[i+2]} for i in range(0, len(stimulus_ids), 3)]),\n",
    "#    'stimulus_id': ('presentation', [f\"{stimulus_ids[i]}__{stimulus_ids[i+1]}__{stimulus_ids[i+2]}\" for i in range(0, len(stimulus_ids), 3)])\n",
    "#    }, dims=['presentation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 112 1459  632 1278 1561  792  796 1660  413   27  671  320 1448 1531\n",
      "  324 1594  280 1825 1381 1522   14 1528  526  208 1491 1336 1850 1494\n",
      "  171 1113]\n",
      "[1459, 1278, 1660, 320, 1531, 1825, 14, 1528, 1850, 1113]\n"
     ]
    }
   ],
   "source": [
    "print(sample)\n",
    "print(choices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bs_old",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
