{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO:\n",
    "1. Work on Assembly in \"# get activations\" part instead of the StimulusSet\n",
    "2. Translate to ``behavior.py`` and the test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import brainscore_vision\n",
    "from brainio.assemblies import DataAssembly, BehavioralAssembly, walk_coords\n",
    "from brainscore_vision.benchmark_helpers.screen import place_on_screen\n",
    "from brainscore_vision.model_helpers.activations import PytorchWrapper\n",
    "from brainscore_vision.model_helpers.brain_transformation import ModelCommitment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pytorch_custom():\n",
    "    import torch\n",
    "    from torch import nn\n",
    "    from brainscore_vision.model_helpers.activations.pytorch import load_preprocess_images\n",
    "\n",
    "    class MyModel(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(MyModel, self).__init__()\n",
    "            np.random.seed(0)\n",
    "            torch.random.manual_seed(0)\n",
    "            self.conv1 = torch.nn.Conv2d(in_channels=3, out_channels=2, kernel_size=3)\n",
    "            self.relu1 = torch.nn.ReLU()\n",
    "            linear_input_size = np.power((224 - 3 + 2 * 0) / 1 + 1, 2) * 2\n",
    "            self.linear = torch.nn.Linear(int(linear_input_size), 1000)\n",
    "            self.relu2 = torch.nn.ReLU()\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.conv1(x)\n",
    "            x = self.relu1(x)\n",
    "            x = x.view(x.size(0), -1)\n",
    "            x = self.linear(x)\n",
    "            x = self.relu2(x)\n",
    "            return x\n",
    "\n",
    "    preprocessing = functools.partial(load_preprocess_images, image_size=224)\n",
    "    return PytorchWrapper(model=MyModel(), preprocessing=preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "activations_model = pytorch_custom()\n",
    "layers = [\"relu2\"]\n",
    "\n",
    "# create brain model\n",
    "brain_model = ModelCommitment(\n",
    "    identifier=activations_model.identifier, \n",
    "    activations_model=activations_model, \n",
    "    layers=[None], \n",
    "    behavioral_readout_layer='relu2')\n",
    "\n",
    "# get activations\n",
    "assy = brainscore_vision.load_dataset(f'Hebart2023')\n",
    "stimuli = place_on_screen(\n",
    "    stimulus_set=assy.stimulus_set,\n",
    "    target_visual_degrees=brain_model.visual_degrees(),\n",
    "    source_visual_degrees=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_similarity_matrix(features, similarity_measure='dot'):\n",
    "   features = features.transpose('presentation', 'neuroid')\n",
    "   values = features.values\n",
    "   if similarity_measure == 'dot':\n",
    "      similarity_matrix = np.dot(values, np.transpose(values))\n",
    "   elif similarity_measure == 'cosine':\n",
    "      row_norms = np.linalg.norm(values, axis=1).reshape(-1, 1)\n",
    "      norm_product = np.dot(row_norms, row_norms.T)\n",
    "      dot_product = np.dot(values, np.transpose(values))\n",
    "      similarity_matrix = dot_product / norm_product\n",
    "   else:\n",
    "      raise ValueError(\n",
    "      f\"Unknown similarity_measure {similarity_measure} -- expected one of 'dot' or 'cosine'\")\n",
    "\n",
    "   similarity_matrix = DataAssembly(similarity_matrix, coords={\n",
    "        **{f\"{coord}_left\": ('presentation_left', values) for coord, _, values in\n",
    "           walk_coords(features['presentation'])},\n",
    "        **{f\"{coord}_right\": ('presentation_right', values) for coord, _, values in\n",
    "           walk_coords(features['presentation'])}\n",
    "   }, dims=['presentation_left', 'presentation_right'])\n",
    "   return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_choices(similarity_matrix, triplets):\n",
    "    triplets = np.array(triplets).reshape(-1, 3)\n",
    "    choice_predictions = []\n",
    "    for triplet in triplets:\n",
    "        i, j, k = triplet\n",
    "        sims = similarity_matrix[i, j], similarity_matrix[i, k],  similarity_matrix[j, k]\n",
    "        idx = triplet[2 - np.argmax(sims)]\n",
    "        choice_predictions.append(idx)\n",
    "    # TODO return as DataAssembly\n",
    "    return choice_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: This should become look_at(), Make sure to drop duplicates where necessary!\n",
    "features = activations_model(stimuli, layers=layers)\n",
    "features = features.transpose('presentation', 'neuroid')\n",
    "triplets = brainscore_vision.load_dataset(f'Hebart2023')\n",
    "triplets = np.array([triplets['image_1'], triplets['image_2'], triplets['image_3']]).T\n",
    "triplets = triplets.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = triplets[:10*3]\n",
    "sim = calculate_similarity_matrix(features, similarity_measure='cosine')\n",
    "choices = calculate_choices(similarity_matrix=sim, triplets=sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/xr/8j65lqqn09q37xqx59yx9v480000gn/T/ipykernel_33659/3136307439.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstimulus_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtriplets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stimulus_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m choices = BehavioralAssembly(choices, coords={\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m'triplet_index'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'presentation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstimulus_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m'triplet_stimulus_id0'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'presentation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mstimulus_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstimulus_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'triplet_stimulus_id1'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'presentation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mstimulus_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstimulus_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "stimulus_ids = triplets['stimulus_id']\n",
    "choices = BehavioralAssembly(choices, coords={\n",
    "    'triplet_index': ('presentation', [i for i in range(0, len(stimulus_ids), 3)]),\n",
    "    'triplet_stimulus_id0': ('presentation', [{stimulus_ids[i]} for i in range(0, len(stimulus_ids), 3)]),\n",
    "    'triplet_stimulus_id1': ('presentation', [{stimulus_ids[i+1]} for i in range(0, len(stimulus_ids), 3)]),\n",
    "    'triplet_stimulus_id2': ('presentation', [{stimulus_ids[i+2]} for i in range(0, len(stimulus_ids), 3)]),\n",
    "    'stimulus_id': ('presentation', [f\"{stimulus_ids[i]}__{stimulus_ids[i+1]}__{stimulus_ids[i+2]}\" for i in range(0, len(stimulus_ids), 3)])\n",
    "    }, dims=['presentation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 112 1459  632 1278 1561  792  796 1660  413   27  671  320 1448 1531\n",
      "  324 1594  280 1825 1381 1522   14 1528  526  208 1491 1336 1850 1494\n",
      "  171 1113]\n",
      "[1459, 1278, 1660, 320, 1531, 1825, 14, 1528, 1850, 1113]\n"
     ]
    }
   ],
   "source": [
    "print(sample)\n",
    "print(choices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 112 1459  632]\n",
      " [1278 1561  792]\n",
      " [ 796 1660  413]\n",
      " [  27  671  320]\n",
      " [1448 1531  324]\n",
      " [1594  280 1825]\n",
      " [1381 1522   14]\n",
      " [1528  526  208]\n",
      " [1491 1336 1850]\n",
      " [1494  171 1113]]\n",
      "[1459, 1278, 1660, 320, 1531, 1825, 14, 1528, 1850, 1113]\n"
     ]
    }
   ],
   "source": [
    "print(sample)\n",
    "print(choices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bs_old",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
